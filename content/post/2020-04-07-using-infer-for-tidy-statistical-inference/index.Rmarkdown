---
title: Using {infer} for Tidy Statistical Inference
author: Qiushi Yan
date: '2020-04-07'
categories:
  - R
  - Statistics
summary: 'A note to self on conducting statistical inference using the {infer} package'
lastmod: '2020-04-07T15:48:14+08:00'
featured: no
bibliography: ../bib/infer.bib
biblio-style: apalike
link-citations: yes
image:
  caption: 'Photo by [Tim Mossholder](https://www.pexels.com/@timmossholder)'
  focal_point: ''
  preview_only: no
draft: true
---


```{r, include = FALSE}
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE,
                      comment = "#>", 
                      collapse = TRUE,
                      fig.align = "center")
```


```{r}
library(tidyverse)
library(infer) 
theme_set(theme_light())
```

```{r}
titanic <- Titanic %>% 
  as_tibble() %>% 
  uncount(n) %>% 
  janitor::clean_names()

titanic
```

## Confidence interval


## Difference in proportions  
```{r}
obs_stat <- titanic %>% 
  specify(survived ~ sex, success = "Yes") %>%
  calculate(stat = "diff in props", order = c("Female", "Male")) 

null_distribution <- titanic %>% 
  specify(survived ~ sex, success = "Yes") %>% 
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "diff in props", order = c("Female", "Male"))

ci <- null_distribution %>% 
 get_ci(level = 0.95, type = "percentile")

null_distribution %>% 
  visualise() +
  shade_ci(endpoints = ci) + 
  shade_p_value(obs_stat = obs_stat, direction = "greater")  
```

## t-test  


### One sample t test  

The data I used this t test section comes from `moderndive` package and book [@moderndive], which actually first introduced to the `infer` package.
```{r}
library(moderndive)
movies_sample
```

Since we are conducting a one-sample t test, the hypothesis is quite simple. We want to test if the average rating of all movies equals to 4, that is 

$$
H_0: \mu = 5.5 \\
H_1: \mu \not= 5.5
$$

```{r}
obs_stat <- movies_sample %>% 
  specify(response = rating) %>% 
  calculate("mean")

null_distribution <- movies_sample %>% 
  specify(response = rating) %>%
  hypothesize(null = "point", mu = 5.5) %>%
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean")


null_distribution %>% 
  visualize() +
  shade_p_value(obs_stat = obs_stat, direction = "both")

null_distribution %>% 
  get_p_value(obs_stat = obs_stat, direction = "both")
```



### Two sample t test  

Continue with the `movies_sample` data. Now we are interested in whether `Action` or `Romance` movies got a higher rating on average. Denote the the true mean of Action and Roamnce movies by $\mu_1$ and $\mu_2$ respectively, that is 

$$
H_0: \mu_1 = \mu_2 \\
H_1: \mu_1 > \mu_2
$$

Two sample t test assumes that scores in both genre are normally distributed and each sample is taken independently:  

```{r}
ggplot(movies_sample, aes(rating)) + 
  geom_histogram() + 
  facet_wrap(~ genre)
```


If we We have t-statistic with *rough* dof tunder the null hypothesis:  

$$
\frac{\mu_1 - \mu_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \sim t_{n_1 + n_2 - 3} 
$$


```{r, message = TRUE}
obs_stat <- movies_sample %>% 
  specify(rating ~ genre) %>% 
  calculate(stat = "t", order = c("Action", "Romance"))

null_distribution <- movies_sample %>% 
  specify(rating ~ genre) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "t", order = c("Action", "Romance"))

null_distribution %>% 
  visualize() + 
  shade_p_value(obs_stat = obs_stat, direction = "greater")

null_distribution %>% 
  get_p_value(obs_stat = obs_stat, direction = "greater")
```

Without relying on t-statistic:  


```{r}
obs_stat <- movies_sample %>% 
  specify(rating ~ genre) %>% 
  calculate(stat = "diff in means", order = c("Action", "Romance"))

null_distribution <- movies_sample %>% 
  specify(rating ~ genre) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "diff in means", order = c("Action", "Romance"))


null_distribution %>% 
  visualize() + 
  shade_p_value(obs_stat = obs_stat, direction = "greater") 

null_distribution %>% 
  get_p_value(obs_stat = obs_stat, direction = "greater")
```



## Chi-square test  

Is sex correlated with class?               

```{r}
ggplot(titanic) + 
  geom_bar(aes(class, fill = sex))
```


```{r}
obs_stat <- titanic %>% 
    specify(class ~ sex) %>% # alternative: response = class, explanatory = sex
    calculate(stat = "Chisq")
```


```{r}
chisq_null_permutation <- titanic %>%
  specify(class ~ sex) %>% 
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "Chisq")

chisq_null_permutation %>% 
  visualize() + 
  shade_p_value(obs_stat = obs_stat, direction = "greater")
```




## Conclusion  

As it is, I do not think `infer` somehow has a significant advantage over its counterparts in base R, say `t.test()`, `anova()`, and `boot()`, or other "non-tidy" packages in terms of common statistical inference procedure. While functions like `specify`, `hypothesize`, `generate`, `visualize` adhere nicely to the tidyverse principles of "providing English-like verbs that do one job at a time", it is, in many cases, prone to verbosity. This is not to say that the idea of a unified interface in classical inference is bad, but that the sheer volumn of statistical tests and its variants have made impossible a complete framework. Perhaps it is more that R, as a programming language designed originally for statisticians, has long since been equipped with powerful inference tookits implemented separately to which many of us are exposed in our first R lesson. And I think one of the reasons that ggplot2 has gained such popularity is that plotting in base R is rather an arduous task, at any rate for me at first. 

That said, I have to confess that I have only done one or two tests after finishing my introductory statistics class, and it seems classical inference is in decline particularly when p-value has been vehemently criticized and the big data meme shifted the interests of many statisticians elsewhere. It's still good to see this type of friendly syntax in doing simple inferential statistics.  













