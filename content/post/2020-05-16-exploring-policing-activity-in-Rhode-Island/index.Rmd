---
title: Exploring policing activity in Rhode Island
author: Qiushi Yan
date: '2020-05-17'
lastmod: '2020-05-18'
slug: rhode-policing-activity
categories:
  - Python
  - Data Analysis
subtitle: 'Use pandas to answer data questions about traffic stops in Rhode Island.'
summary: 'Use pandas to answer data questions about traffic stops in Rhode Island.'
image:
  caption: ''
  focal_point: ''
  preview_only: yes
---

This post is about completing an exploratory data analysis project using the `pandas` library in Python. The data comes from the [Stanford Open Policing Project](https://openpolicing.stanford.edu), which releases cleaned data about vehicle and pedestrian stops from the police across over 30 states in the USA. I focus only on traffic stops by police officers in the state of Rhode Island here. 

Some questions include:

- The relationship between search rate, types of search, types of violation, gender and race.
- How do the number of drug related stops and search rate change during the past few years?
- Is there a pattern in violations across different zones of Rhode Island?
- Does weather affect arrest rate?



```{r, include = FALSE}
knitr::opts_chunk$set(comment = "#>", collapse = TRUE,
                      message = FALSE, warning = FALSE)
```

# Data preprocessing

```{python, include = FALSE}
# fix plotting error when making matplotlib graphics inside RStudio
import os as os
path = 'C:/Users/Lenovo/AppData/Local/r-miniconda/envs/r-reticulate/Library/plugins/platforms'
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = path

```


Let's begin by loading the library and data:
```{python}
import pandas as pd 
```

```{python}
ri = pd.read_csv("D:/RProjects/data/stanford-open-policing/rhode_traffic_stops.csv")
print(ri.head())
print(ri.columns)
```


To save future efforts, we have some preprocessing jobs to do:

- drop columns and rows
- make sure that relevant columnns are in the right data type.
- make use of pandas's datetime index


A glance at missing values will show that `county_name` are all missing. Also, those observations with missing `driver_gender` and `driver_race` is of little value for our purposes. And the `state` column is redundant.

```{python}
ri.isnull().mean()
```

As to data types, `is_arrested` is now recognized as objects, but should be boolean values instead. 

```{python}
ri.dtypes
```


```{python}
ri["is_arrested"].head()
```

Lastly, `stop_date` and `stop_time` will be turned into best advantage as a datetime index.

```{python}
ri[["stop_date", "stop_time"]].head()
```

Combine these steps yields a relatively clean version of this dataset.
```{python}
ri["is_arrested"] = ri.is_arrested.astype("bool")
dt_index = ri.stop_date.str.cat(ri.stop_time, sep = " ")
ri["stop_datetime"] = pd.to_datetime(dt_index)

ri_clean = (ri.
  drop(["county_name", "state"], axis = "columns").
  dropna(subset = ["driver_gender", "driver_race"]).
  set_index("stop_datetime")
)
```


```{python}
ri_clean.head()
```


# Exploring the relationship between gender, race and policing 

The `search_conducted` column indicates whether or not a vehicle were searched by an officer:  
```{python}
ri_clean.search_conducted.head()
```

We can break the average search rate by gender 

```{python}
# search rate for men and women
ri_clean.groupby("driver_gender").search_conducted.mean()
```

This is a marked difference considering the base volume. This could be misleading due to the existance of some confounding variables. For exmaple, the difference in search rate between males and females could be explained by the fact that they tend to commit different violations. For this reason I'll divide the result by types of violation to see if there is a universal rise in the possibility of being searched from women to men. 

```{python}
ri_clean.groupby(["violation", "driver_gender"]).search_conducted.mean()
```

For all types of violation, the search rate is higher for males than for females, disproving our hypothesis related to confounding variables, by and large.  

The `search_type` column contains information about categories of searching on the part of the police. I investigate the relative proportion of the most common search types for 4 races. 

```{python}
condition = ri_clean.driver_race.isin(["White", "Black", "Hispanic", "Asian"]) & ri_clean.search_type.isin(["Incident to Arrest", 'Probable Cause', 'Inventory'])

search_type_by_race = (ri_clean[condition].
  groupby("driver_race").
  search_type.
  value_counts(normalize = True).
  unstack()
)
```




```{python}
import matplotlib.pyplot as plt
search_type_by_race.plot(kind = "bar")
plt.title("Proportion of common search types across 4 races")
plt.show()
```


Now we come to the question that if race played a role in whether or not someone is frisked during a search (coded in `search_type` by "Protective Frisk"). Since a search instance can be of multiple types, such as "Protective Frisk and Reasonable Suspicion", I create a new column indicating if `search_type` contains protective frisk, and calculate its rate across races. 

```{python}
ri_clean["frisk"] = ri_clean.search_type.str.contains("Protective Frisk").astype("bool")

(ri_clean[ri_clean.search_conducted == True].
  groupby("driver_race").
  frisk.
  mean())
```

It looks like white people has a slightly higher frisk rate. But there is no conclusion to be made without more detailed background information.



# Temporal pattern of drug related stops and search rates
The `drugs_related_stop` shows if a traffic stop eneded in the spotting of drugs in the vehicle. Resampling the column annually gives the drug rate over years, and annual search rate is calculated as a reference. 

```{python}
annual_drug_rate = ri_clean.drugs_related_stop.resample("A").mean()
annual_search_rate = ri_clean.search_conducted.resample("A").mean()
annual = pd.concat([annual_drug_rate, annual_search_rate], axis="columns")
annual.plot(subplots = True)
plt.show()
```

The rate of drug-related stops increased even though the search rate decreased. 


# Distribution of violation across zones 

Speeding is the most common violation in all districts. 
```{python}
all_zones = pd.crosstab(ri_clean.district, ri_clean.violation)
all_zones.plot(kind = 'bar')
plt.show()
```

# Weather Impact on policing behaviour 

This section uses a second dataset to explore the impact of weather conditions on police behavior during traffic stops.  

```{python}
weather = pd.read_csv("D:/RProjects/data/stanford-open-policing/rhode_weather.csv")
weather.head()
```


The `weather` data is collected by the national centers for environmental information. Because `ri` lacks spatial information like latitude / longitutde, we use only the data observed by a weather station in the center of Rhode Island. Columns in `weather` that starts with `WT` represents a bad weather condition, and take value at either 1 (present) or 0 (present).  

To measure overall weather conditions on a single day, I tally all the `WT` columns. 

```{python}
weather["bad_conditions"] = (weather.loc[:,'WT01':'WT22'].
  fillna(0).
  sum(axis = "columns").
  astype("int"))
  
weather.bad_conditions.plot(kind = "hist", bins = 10)
plt.show()
```


Next, I split the daily weather into a categorical variable with 3 categories based on `bad_conditions`.


```{python}
from pandas.api.types import CategoricalDtype
mapping = {0:'good', 1:'bad', 2:'bad', 3: "bad", 4: "bad",
    5: "worse", 6: "worse", 7: "worse", 8: "worse", 9: "worse"
}

weather['rating'] = (weather.bad_conditions.
  map(mapping).
  astype(CategoricalDtype(categories = ['good', 'bad', "worse"], ordered = True)))

# Count the unique values in 'rating'
print(weather.rating.value_counts())
```


```{python}
weather.head()
```


Now `rating` turn to be a easy indicator of weather condition, I'll join two dataframes, `ri_clean` and `weather`, to finalize the analysis. 

```{python}
ri_clean = ri_clean.reset_index()

weather_rating = weather[["DATE", "rating"]].rename(columns = {"DATE": "stop_date"})
ri_weather = pd.merge(ri_clean, weather_rating, how = "left").set_index("stop_datetime")
ri_weather.head()
```


Let's compare the arrest rate, divided by weather condition and types of violation.

```{python}
arrest_rate = ri_weather.groupby(["violation", "rating"]).is_arrested.mean()
arrest_rate

arrest_rate.unstack().plot(kind = "bar")
plt.show()
```



Generally, the arrest rate is higher when weather condition gets worse. This doesn't prove a causal link, but it's quite an interesting result! Also, this plot can be illustrated via a pivot table. 

```{python}
ri_weather.pivot_table(index = "violation", columns = "rating", values = "is_arrested")
```

