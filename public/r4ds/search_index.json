[
["index.html", "R for data science: tidyverse and beyond 前言", " R for data science: tidyverse and beyond Maxine 2020-01-07 前言 这份笔记最初源自于对 R for Data Science(Wickham and Grolemund 2016)的学习,其中第 2 章和第 9 章还包含了许多 Advanced R 中相应章节的内容。 限于篇幅， R for Data Sciecne 的内容聚焦于对 tidyverse 核心包的讲解，难免遗漏了一些同样很实用的 tidyverse 包，如 rvest、 DBI等。一些 tidyverse 包在本书出版后的重大更新，如 tidyr 1.0.0，自然也没有被收录。 另一方面，当下的 R 社区发展迅猛，一大批更为好用、高效的 R 包也在不断涌现，既有 Rstudio 旗下 tidyverse 的衍生系列(如 tidymodels), 也有 “民间” 的贡献（如 data.table）。虽然学海无涯，作为学习者总还是希望能够多掌握一些，多明白一些。于是便希望这份笔记不限于原书，而是能记录一些其他自学 R 与数据科学实践的内容。最大的受益者自然是未来的自己，但若能为他人对 R 的学习提供些许帮助，自然也十分高兴。 鉴于笔者没有经历过统计、计算机等专业的系统学习，似乎连“才疏学浅”这样的谦辞也成为一种过誉。无论如何，若发现了任何错误或有任何方面的意见，欢迎在 https://github.com/enixam/rfordatascience/issues 提交 issue 或者通过邮箱 565702994@qq.com 与我联系。 第 1 ~ 9 章的文字表述借鉴了中文译本。目前对原书中内容的再现和扩展（第一部分）已经基本完成(除了 ggplot2 相关部分)，随缘更新。 绝大部分代码需要首先加载 tidyverse, 其中包含的 R 包默认已经被加载好 : library(tidyverse) "],
["dplyr.html", "1 dplyr 1.1 5个数据转换核心函数 1.2 filter()筛选行 1.3 arrange() 排列行 1.4 使用select()选择列 1.5 mutate() 创建变量 1.6 使用summarize()进行分组摘要 1.7 group_by() 结合其他函数 1.8 练习 1.9 作用域", " 1 dplyr dplyr 承担了 tidyverse 中最基本也最重要的数据处理、转换、分析功能(to my mind)。它的设计思想是发展处一套简洁、统一的数据操作语法(a grammar of data manipulation)，用英语中常见的动词命名操作数据的函数，并充分利用管道符 %&gt;% 和更“现代”的数据框格式 tibble 增加代码可读性。1 为了介绍 dplyr 中的基本数据操作。可以使用 nycflights::flights，这个数据集包含了 2013 年从纽约市处罚的所有 336776 次航班的信息。该数据来自于美国交通统计局。 library(nycflights13) flights #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 这里的数据输出和我们之前用过的 data.frame 形式有一些差别：只显示了前几行和适合屏幕宽度的几列。这样的差别是因为 flights 数据集被存储在 tibble 当中，它是一种更简单的数据框，但更加适合在 tidyverse 中使用。相对于普通的数据框，它在打印和取子集两个方面进行了优化，更详细的内容会在后面的章节谈到。 同时，输出结果列名下面有一行 3 个或 4 个字母的缩写。它们描述了每个变量的类型。 int 表示整数型变量 dbl 表示双精度浮点型变量 chr 表示字符串 dttm 表示日期时间（日期+时间）型变量 还有另外三种常见的变量类型，虽然没有在本数据中出现，但很快就会用到： lgl 表示逻辑型变量（即布尔变量） fct 表示因子 date 表示日期型变量 另外，还有一种专门为tibble数据格式编写的函数 glimpse()，它的功能和 str() 类似，但输出更为整洁，显示的数据也更多一些: glimpse(flights) #&gt; Observations: 336,776 #&gt; Variables: 19 #&gt; $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, … #&gt; $ month &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #&gt; $ day &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #&gt; $ dep_time &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558,… #&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600,… #&gt; $ dep_delay &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -… #&gt; $ arr_time &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849… #&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851… #&gt; $ arr_delay &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -… #&gt; $ carrier &lt;chr&gt; &quot;UA&quot;, &quot;UA&quot;, &quot;AA&quot;, &quot;B6&quot;, &quot;DL&quot;, &quot;UA&quot;, &quot;B6&quot;, &quot;EV&quot;, &quot;B6&quot;, … #&gt; $ flight &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, … #&gt; $ tailnum &lt;chr&gt; &quot;N14228&quot;, &quot;N24211&quot;, &quot;N619AA&quot;, &quot;N804JB&quot;, &quot;N668DN&quot;, &quot;N39… #&gt; $ origin &lt;chr&gt; &quot;EWR&quot;, &quot;LGA&quot;, &quot;JFK&quot;, &quot;JFK&quot;, &quot;LGA&quot;, &quot;EWR&quot;, &quot;EWR&quot;, &quot;LGA&quot;… #&gt; $ dest &lt;chr&gt; &quot;IAH&quot;, &quot;IAH&quot;, &quot;MIA&quot;, &quot;BQN&quot;, &quot;ATL&quot;, &quot;ORD&quot;, &quot;FLL&quot;, &quot;IAD&quot;… #&gt; $ air_time &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, … #&gt; $ distance &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733,… #&gt; $ hour &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, … #&gt; $ minute &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, … #&gt; $ time_hour &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 … str(flights) #&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 336776 obs. of 19 variables: #&gt; $ year : int 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... #&gt; $ month : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ day : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ dep_time : int 517 533 542 544 554 554 555 557 557 558 ... #&gt; $ sched_dep_time: int 515 529 540 545 600 558 600 600 600 600 ... #&gt; $ dep_delay : num 2 4 2 -1 -6 -4 -5 -3 -3 -2 ... #&gt; $ arr_time : int 830 850 923 1004 812 740 913 709 838 753 ... #&gt; $ sched_arr_time: int 819 830 850 1022 837 728 854 723 846 745 ... #&gt; $ arr_delay : num 11 20 33 -18 -25 12 19 -14 -8 8 ... #&gt; $ carrier : chr &quot;UA&quot; &quot;UA&quot; &quot;AA&quot; &quot;B6&quot; ... #&gt; $ flight : int 1545 1714 1141 725 461 1696 507 5708 79 301 ... #&gt; $ tailnum : chr &quot;N14228&quot; &quot;N24211&quot; &quot;N619AA&quot; &quot;N804JB&quot; ... #&gt; $ origin : chr &quot;EWR&quot; &quot;LGA&quot; &quot;JFK&quot; &quot;JFK&quot; ... #&gt; $ dest : chr &quot;IAH&quot; &quot;IAH&quot; &quot;MIA&quot; &quot;BQN&quot; ... #&gt; $ air_time : num 227 227 160 183 116 150 158 53 140 138 ... #&gt; $ distance : num 1400 1416 1089 1576 762 ... #&gt; $ hour : num 5 5 5 5 6 5 6 6 6 6 ... #&gt; $ minute : num 15 29 40 45 0 58 0 0 0 0 ... #&gt; $ time_hour : POSIXct, format: &quot;2013-01-01 05:00:00&quot; &quot;2013-01-01 05:00:00&quot; ... 1.1 5个数据转换核心函数 五个 dplyr 核心函数能解决数据转换中的绝大多数问题： 使用 filter() 筛选行 使用 arrange() 排列行 使用 select 选取列 用现有的变量创建新变量 mutate() 聚合并计算摘要统计量 summarize() 上面的所有函数都可以和 group_by() 函数联合起来使用，group_by() 函数可以改变以上每个函数的作用范围，让其从在整个数据集上操作变为在每个变量的水平上分别操作。这 6 个函数构成了数据处理的基本工具。 这些函数有完全相同的参数结构和工作方式： 第一个参数是数据集，表明我们想对什么数据进行处理 随后的参数是变量名称（不带引号）描述了在数据上进行什么处理，不同的变量之间用逗号分隔 它们不会改变原数据，而是生成一个新的数据框 1.2 filter()筛选行 filter()函数可以基于观测值筛选行，符合条件的行留下，不符合条件的被剔除，最终得到一个观测子集。第一个参数是数据集的名称，第二个参数以及随后的参数是用来筛选行的条件。例如，我们可以使用以下代码筛选出一月一日的所有航班（条件：月 = 1 且 日=1） flights %&gt;% filter(month == 1, day == 1) #&gt; # A tibble: 842 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 836 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, #&gt; # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, #&gt; # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; filter()函数的内部执行原理： 以行为单位，如果该行满足所指定的条件，则被筛选出 ； 若不满足，则被剔除。使用filter()时，总应该从每一行的角度来思考问题。 因为dplyr中的函数从不改变原数据，如果想储存filter()得出的结果，那么需要把它赋值给一个变量。 jan = flights %&gt;% filter(month == 1, day == 1) R 要么输出结果，要么将结果保存在变量中。如果想要在存储的同时显示结果，可以用括号将赋值语句括起来： (jan = flights %&gt;% filter(month == 1, day == 1)) #&gt; # A tibble: 842 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 836 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, #&gt; # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, #&gt; # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 1.2.1 运算符 为了有效地进行筛选，R 提供了一套标准的运算符，包括比较运算符和逻辑运算符。 比较运算符： ==、！= 、 &gt; 、 &gt;= 、 &lt; 、 &lt;= 当开始编写条件时，最容易犯的错误就是用=而不是==来测试是否相等。R 对于这种错误会提供一条启发性的错误信息： flights %&gt;% filter(month = 1) #&gt; Error: `month` (`month = 1`) must not be named, do you need `==`? 在判断是否相等时，还有另一个常见问题：浮点数。例如，下面的结果可能出人意料： sqrt(2)^2 == 2 #&gt; [1] FALSE 1 /49 * 49 == 1 #&gt; [1] FALSE 计算机使用的是有限位运算，不能存储无限位的数。因此我们看到的每个数都是一个近似值。比较浮点数是否相等时，不能用==,而应该用near(),它用于比较两个数值向量是否相等，且带有一定容忍度(tolerence): near(sqrt(2) ^ 2, 2) #&gt; [1] TRUE near(1 /49 * 49, 1) #&gt; [1] TRUE **逻辑运算符* filter()中的多个参数是“与”的关系，如data %&gt;% filter(condition_1,condition_2,···,condition_n)表示的是“我希望同时筛选出满足这n个条件的行。如果要实现其他类型的组合，需要使用逻辑（布尔）运算符。&amp;表示与，|表示或，!表示非。下图给出了布尔运算的完整集合： 例如，想要找出11月或12月出发的所有航班： flights %&gt;% filter(month == 11 | month == 12) #&gt; # A tibble: 55,403 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 11 1 5 2359 6 352 345 #&gt; 2 2013 11 1 35 2250 105 123 2356 #&gt; 3 2013 11 1 455 500 -5 641 651 #&gt; 4 2013 11 1 539 545 -6 856 827 #&gt; 5 2013 11 1 542 545 -3 831 855 #&gt; 6 2013 11 1 549 600 -11 912 923 #&gt; # … with 5.54e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 表达式中的运算顺序和正常语言中的是不一样的。你不能写成flights %&gt;% filter(month == 11 | 12)，这种形式的文字翻译确实是“找出11月或12月的所有航班”，但在代码中不是这个意思。代码中的含义是找出所有月份为11|12的航班，这个表达式的逻辑值为TRUE，在数字语境中R会将它解读为1，所以这段代码实际上找出的 1 月出发的所有航班。 这种问题有一个有用的简写形式：x %in% y，这个表达式在x被包含于y的时候返回TRUE，我们可以这样改写上面的代码： flights %&gt;% filter(month %in% c(11, 12)) ## 找出所有月份值包含在该向量里的行 #&gt; # A tibble: 55,403 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 11 1 5 2359 6 352 345 #&gt; 2 2013 11 1 35 2250 105 123 2356 #&gt; 3 2013 11 1 455 500 -5 641 651 #&gt; 4 2013 11 1 539 545 -6 856 827 #&gt; 5 2013 11 1 542 545 -3 831 855 #&gt; 6 2013 11 1 549 600 -11 912 923 #&gt; # … with 5.54e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 有时可以使用德摩根律来将筛选条件简化：!(x &amp; y)等价于!x | !y，而!(x | y)等价于!x &amp; !y。例如，如果想要找出延误时间（到达和出发)都不多于两个小时的航班，以下两种方式均可： flights %&gt;% filter(arr_delay &lt;= 120 &amp; dep_dealy &lt;= 120 ) flights %&gt;% filter(!(arr_delay &gt; 120| dep_delay &gt; 120 )) dplyr中另外一个对筛选有帮助的函数是between(x,left,right)，它用于判断x是否落在left和right两个值确定的闭区间里。 例如找出所有在11月和12月出发的航班也可以这样表达： flights %&gt;% filter(between(month, 11, 12)) #&gt; # A tibble: 55,403 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 11 1 5 2359 6 352 345 #&gt; 2 2013 11 1 35 2250 105 123 2356 #&gt; 3 2013 11 1 455 500 -5 641 651 #&gt; 4 2013 11 1 539 545 -6 856 827 #&gt; 5 2013 11 1 542 545 -3 831 855 #&gt; 6 2013 11 1 549 600 -11 912 923 #&gt; # … with 5.54e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 有些时候，filter()函数中用来筛选的条件可能比较复杂，需要书写令人费解的逻辑表达式，这时候可以考虑创建一个新变量代表逻辑判断的结果。这样检查代码会容易很多。我们很快就会介绍如何创建新变量。 &amp; and &amp;&amp; indicate logical AND and | and || indicate logical OR. The shorter form performs elementwise comparisons in much the same way as arithmetic operators. The longer form evaluates left to right examining only the first element of each vector. Evaluation proceeds only until the result is determined. The longer form is appropriate for programming control-flow and typically preferred in if clauses. 1.2.2 缺失值 NA(not available)表示未知的值、缺失值，缺失值一个很重要的特点是它是“可传染的”。如果运算中包含了缺失值，那么运算结果一般来说也会是缺失值。 NA &gt; 5 #&gt; [1] NA NA == 10 #&gt; [1] NA NA + 2 #&gt; [1] NA NA / 2 #&gt; [1] NA 以上的表达式的结果都是NA，这很好理解，如果R不知道表达式其中的一个量究竟是什么值，自然表达式的结果也就不可知。 还要注意一件事： NA == NA #&gt; [1] NA 我们可以这么理解这个结果： 令x为Mary的年龄，我们不知道她有多大：x &lt;- NA 令y为John的年龄，我们同样不知道他又多大：x &lt;- NA Mary和John的年龄相同吗？： x == y 不知道！ 鉴于此，使用NA == x来判断x是否是缺失值不可行。我们用函数is.na()进行判断： x = NA is.na(x) #&gt; [1] TRUE 前面说过，filter() 实际上是在提问：某行的某个 \\ 某些变量满足给定的条件吗？如果为 TRUE，则筛选出该行。如果该行在涉及变量上的取值是 NA，那么逻辑表达式也会返回 NA，这些行将被返回结果为 FALSE 的行一并被排除。如果想保留缺失值，同样可以利用逻辑表达式指出： df &lt;- tibble(x = c(1, NA, 3)) df %&gt;% filter(is.na(x) | x &gt; 1) #&gt; # A tibble: 2 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 NA #&gt; 2 3 1.2.3 练习 Exercise 1.1 找出满足以下条件的所有航班: 到达时间延误两小时或更多的航班 flights %&gt;% filter(arr_delay &gt;= 120) #&gt; # A tibble: 10,200 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 811 630 101 1047 830 #&gt; 2 2013 1 1 848 1835 853 1001 1950 #&gt; 3 2013 1 1 957 733 144 1056 853 #&gt; 4 2013 1 1 1114 900 134 1447 1222 #&gt; 5 2013 1 1 1505 1310 115 1638 1431 #&gt; 6 2013 1 1 1525 1340 105 1831 1626 #&gt; # … with 1.019e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 飞往休斯顿（IAH机场或者HOU机场）的航班 flights %&gt;% filter(dest == &quot;IAH&quot; | dest == &quot;HOU&quot;) #&gt; # A tibble: 9,313 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 623 627 -4 933 932 #&gt; 4 2013 1 1 728 732 -4 1041 1038 #&gt; 5 2013 1 1 739 739 0 1104 1038 #&gt; 6 2013 1 1 908 908 0 1228 1219 #&gt; # … with 9,307 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 也可以写成filter(flights, dest %in% c(\"HOU\",\"IAH\")) 由联合航空（United）、美利坚航空（American）或者三角洲航空（Delat）运营的航班 carrier列代表了航空公司，但是用两个字母缩写表示： flights[&quot;carrier&quot;] #&gt; # A tibble: 336,776 x 1 #&gt; carrier #&gt; &lt;chr&gt; #&gt; 1 UA #&gt; 2 UA #&gt; 3 AA #&gt; 4 B6 #&gt; 5 DL #&gt; 6 UA #&gt; # … with 3.368e+05 more rows 我们可以在airlines数据集中找到这些缩写的含义： airlines #&gt; # A tibble: 16 x 2 #&gt; carrier name #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 9E Endeavor Air Inc. #&gt; 2 AA American Airlines Inc. #&gt; 3 AS Alaska Airlines Inc. #&gt; 4 B6 JetBlue Airways #&gt; 5 DL Delta Air Lines Inc. #&gt; 6 EV ExpressJet Airlines Inc. #&gt; # … with 10 more rows 三角洲航空对应 “DL”，“UA” 代表联合航空，“AA”代表美利坚航空 flights %&gt;% filter(carrier %in% c(&quot;DL&quot;, &quot;UA&quot;, &quot;AA&quot;)) #&gt; # A tibble: 139,504 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 554 600 -6 812 837 #&gt; 5 2013 1 1 554 558 -4 740 728 #&gt; 6 2013 1 1 558 600 -2 753 745 #&gt; # … with 1.395e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 夏季(7月、8月、9月)出发的航班 flights %&gt;% filter(month %in% c(7, 8, 9)) #&gt; # A tibble: 86,326 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 7 1 1 2029 212 236 2359 #&gt; 2 2013 7 1 2 2359 3 344 344 #&gt; 3 2013 7 1 29 2245 104 151 1 #&gt; 4 2013 7 1 43 2130 193 322 14 #&gt; 5 2013 7 1 44 2150 174 300 100 #&gt; 6 2013 7 1 46 2051 235 304 2358 #&gt; # … with 8.632e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 另一种写法：filter(flgihts,month &gt;= 7, month &lt;= 9) 用between()函数的写法： flights %&gt;% filter(between(month,7,9)) #&gt; # A tibble: 86,326 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 7 1 1 2029 212 236 2359 #&gt; 2 2013 7 1 2 2359 3 344 344 #&gt; 3 2013 7 1 29 2245 104 151 1 #&gt; 4 2013 7 1 43 2130 193 322 14 #&gt; 5 2013 7 1 44 2150 174 300 100 #&gt; 6 2013 7 1 46 2051 235 304 2358 #&gt; # … with 8.632e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 到达时间延误超过两小时，但出发时间没有延误的航班 flights %&gt;% filter(dep_delay &gt; 120 , arr_delay &lt;= 120) #&gt; # A tibble: 1,262 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 1540 1338 122 2020 1825 #&gt; 2 2013 1 2 2334 2129 125 33 2242 #&gt; 3 2013 1 3 1321 1115 126 1450 1257 #&gt; 4 2013 1 3 1758 1550 128 2240 2050 #&gt; 5 2013 1 3 1933 1730 123 2131 1953 #&gt; 6 2013 1 4 1602 1359 123 1715 1517 #&gt; # … with 1,256 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 延误至少一小时，但飞行过程弥补回30分钟的航班 flights %&gt;% filter(dep_delay - arr_delay &gt; 30) #&gt; # A tibble: 17,950 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 701 700 1 1123 1154 #&gt; 2 2013 1 1 820 820 0 1249 1329 #&gt; 3 2013 1 1 840 845 -5 1311 1350 #&gt; 4 2013 1 1 857 851 6 1157 1222 #&gt; 5 2013 1 1 909 810 59 1331 1315 #&gt; 6 2013 1 1 1025 951 34 1258 1302 #&gt; # … with 1.794e+04 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 出发时间在午夜和早上6点之间（包括0点和6点）的航班 在变量dep_time中，0 点用数值 2400 代表： summary(flights$dep_time) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 1 907 1401 1349 1744 2400 8255 出于这点，不能简单写成dep_time &lt;= 600，而是如下： flights %&gt;% filter(dep_time &lt;= 600 | dep_time == 2400) #&gt; # A tibble: 9,373 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 9,367 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Exercise 1.2 dep_time`有缺失值的航班有多少？其他变量的缺失值情况如何？ sum(is.na(flights$dep_time)) #&gt; [1] 8255 flights %&gt;% filter(is.na(dep_time)) #&gt; # A tibble: 8,255 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 NA 1630 NA NA 1815 #&gt; 2 2013 1 1 NA 1935 NA NA 2240 #&gt; 3 2013 1 1 NA 1500 NA NA 1825 #&gt; 4 2013 1 1 NA 600 NA NA 901 #&gt; 5 2013 1 2 NA 1540 NA NA 1747 #&gt; 6 2013 1 2 NA 1620 NA NA 1746 #&gt; # … with 8,249 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 注意到，所有dep_time为 NA 的航班在有关实际到达、出发情况的变量上取值皆为 NA，这些很可能是被取消的航班。 # 其他变量中的缺失值 flights %&gt;% summarize_all( ~ sum(is.na(.))) #&gt; # A tibble: 1 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 0 0 0 8255 0 8255 8713 0 #&gt; # … with 11 more variables: arr_delay &lt;int&gt;, carrier &lt;int&gt;, flight &lt;int&gt;, #&gt; # tailnum &lt;int&gt;, origin &lt;int&gt;, dest &lt;int&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, #&gt; # hour &lt;int&gt;, minute &lt;int&gt;, time_hour &lt;int&gt; 为什么NA ^ 0的值不是NA，而NA * 0的值是NA ？为什么NA | TRUE 的值不是NA？为什么FALSE &amp; NA的值不是NA，能找出一般规律吗？ 只要表达式的值被NA背后的未知量所决定，就返回NA 对于所有x的取值，都有\\(x ^ 0 = 1\\)，NA ^ 0不取决于 NA 到底可能是什么值。 但对于\\(x * 0\\)，如果x趋近于正负无穷（ R 用-inf 和 inf代表），则R会返回 NaN 错误（not a number），只要知道 NA 究竟是什么，才能知道该表达式的结果 NA ^ 0 #&gt; [1] 1 NA * 0 #&gt; [1] NA c(Inf,-Inf) * 0 #&gt; [1] NaN NaN 同样，对于 NA | TRUE，不论 NA 是什么，该表达式总为真 ； 对于NA &amp; FALSE，不论 NA 是什么，该表达式总为假。 NA | TRUE #&gt; [1] TRUE NA &amp; FALSE #&gt; [1] FALSE 而 NA &amp; TRUE和NA | FALSE则会返回 NA： NA &amp; TRUE #&gt; [1] NA NA | FALSE #&gt; [1] NA 1.3 arrange() 排列行 arrange()函数的工作方式与filter()函数非常相似，但它不是筛选行，而是改变行的顺序。它接受一个数据集和一组作为排序依据的列名（或者更复杂的表达式）作为参数，如果列名不止一个，那么就是用后面的列在前面排序的基础上继续排序： flights %&gt;% arrange(year, month, day) ## 依次按照year/month/day三个变量按升序排序 #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 如果想要按某列降序排列行，可以对该列名使用函数desc()： flights %&gt;% arrange(desc(arr_delay)) ## 按照到达延误时间从大到小排序 #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 9 641 900 1301 1242 1530 #&gt; 2 2013 6 15 1432 1935 1137 1607 2120 #&gt; 3 2013 1 10 1121 1635 1126 1239 1810 #&gt; 4 2013 9 20 1139 1845 1014 1457 2210 #&gt; 5 2013 7 22 845 1600 1005 1044 1815 #&gt; 6 2013 4 10 1100 1900 960 1342 2211 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 缺失值总是排在最后： df &lt;- tibble(x = c(5, 2, NA)) df %&gt;% arrange(x) #&gt; # A tibble: 3 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 2 #&gt; 2 5 #&gt; 3 NA 如果参数是一个关于某些列的表达式expression(variable_n)，它的意思是告诉arrange()：“按照各行在这个表达式上的取值的从小到大的顺序，排列原来的数据集。 flights %&gt;% arrange((dep_delay ** 2)) ## dep_delay的绝对值小的行被排在前面 #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 559 559 0 702 706 #&gt; 2 2013 1 1 600 600 0 851 858 #&gt; 3 2013 1 1 600 600 0 837 825 #&gt; 4 2013 1 1 607 607 0 858 915 #&gt; 5 2013 1 1 615 615 0 1039 1100 #&gt; 6 2013 1 1 615 615 0 833 842 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 例如，我们希望找到总延误时间(dep_delay + arr_delay)最长的航班 ## 延误时间最长的航班 flights %&gt;% arrange(desc(arr_delay + dep_delay)) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 9 641 900 1301 1242 1530 #&gt; 2 2013 6 15 1432 1935 1137 1607 2120 #&gt; 3 2013 1 10 1121 1635 1126 1239 1810 #&gt; 4 2013 9 20 1139 1845 1014 1457 2210 #&gt; 5 2013 7 22 845 1600 1005 1044 1815 #&gt; 6 2013 4 10 1100 1900 960 1342 2211 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 如果A行在两个量上的取值是(2,5)，B行是(1,10)，B会出现在A后面，因为arrange()按照这个表达式来进行排列。 1.3.1 slice() slice()函数按照索引选择指定的观测行，与传统的 “[” 选择方法相比，它与 dplyr 函数的配合更好，支持管道操作： ## 选择前5行 mtcars %&gt;% slice(1:5) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 选择最后一行,类似于tail(mtcars,1) mtcars %&gt;% slice(1L) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 # Rows can be dropped with negative indices: slice(mtcars, -5:-n()) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 # In this case, the result will be equivalent to: slice(mtcars, 1:4) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 # Equivalent code using filter that will also work with databases, # but won&#39;t be as fast for in-memory data. For many databases, you&#39;ll # need to supply an explicit variable to use to compute the row number. filter(mtcars, row_number() == 1L) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 filter(mtcars, row_number() == n()) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21.4 4 121 109 4.11 2.78 18.6 1 1 4 2 filter(mtcars, between(row_number(), 5, n())) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; 2 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; 3 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; 4 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; 5 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; 6 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; 7 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; 8 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; 9 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; 10 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; 11 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; 12 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; 13 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; 14 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; 15 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; 16 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; 17 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; 18 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; 19 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; 20 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; 21 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; 22 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; 23 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; 24 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; 25 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; 26 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; 27 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; 28 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 当要求依据某种排序选出前/后n个观测时，arrange()配合slice()会很方便。例如，下面的代码都选出出发时间最早的10架航班，但是第一种方法更简单一些： ## arrange + slice flights %&gt;% arrange(dep_time) %&gt;% slice(1:10) #&gt; # A tibble: 10 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 13 1 2249 72 108 2357 #&gt; 2 2013 1 31 1 2100 181 124 2225 #&gt; 3 2013 11 13 1 2359 2 442 440 #&gt; 4 2013 12 16 1 2359 2 447 437 #&gt; 5 2013 12 20 1 2359 2 430 440 #&gt; 6 2013 12 26 1 2359 2 437 440 #&gt; # … with 4 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, #&gt; # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, #&gt; # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; ## filter flights %&gt;% filter(min_rank(dep_time)&lt;=10) #&gt; # A tibble: 25 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 13 1 2249 72 108 2357 #&gt; 2 2013 1 31 1 2100 181 124 2225 #&gt; 3 2013 11 13 1 2359 2 442 440 #&gt; 4 2013 12 16 1 2359 2 447 437 #&gt; 5 2013 12 20 1 2359 2 430 440 #&gt; 6 2013 12 26 1 2359 2 437 440 #&gt; # … with 19 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, #&gt; # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, #&gt; # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 1.3.2 练习 Exercise 1.3 如何使用arrange()将缺失值排在最前面？（提示：使用is.na()) 例：把 flights 数据集中dep_time上的 NA 值排在最前面( to sort the data frame by departure time (dep_time) in ascending order but NA values first) 首先is.na(dep_time)将把所有NA变为TRUE（1），其他数值变成FALSE（0），所以desc(is.na(dep_time))是一个排序依据,它告诉arrange()，把那些经过运算is.na(dep_time)后值大的行排在前面，即原先的NA值 ； 之后，我们还要处理那些不是NA的值的排列，所以添加一个参数dep_time： flights %&gt;% arrange(desc(is.na(dep_time)), dep_time) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 NA 1630 NA NA 1815 #&gt; 2 2013 1 1 NA 1935 NA NA 2240 #&gt; 3 2013 1 1 NA 1500 NA NA 1825 #&gt; 4 2013 1 1 NA 600 NA NA 901 #&gt; 5 2013 1 2 NA 1540 NA NA 1747 #&gt; 6 2013 1 2 NA 1620 NA NA 1746 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Exercise 1.4 对flights排序以找出延误时间最长的航班。找出出发时间最早的航班。 ## 延误时间最长的航班 flights %&gt;% arrange(desc(dep_delay)) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 9 641 900 1301 1242 1530 #&gt; 2 2013 6 15 1432 1935 1137 1607 2120 #&gt; 3 2013 1 10 1121 1635 1126 1239 1810 #&gt; 4 2013 9 20 1139 1845 1014 1457 2210 #&gt; 5 2013 7 22 845 1600 1005 1044 1815 #&gt; 6 2013 4 10 1100 1900 960 1342 2211 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; ## 出发时间最早的航班 flights %&gt;% arrange(dep_time) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 13 1 2249 72 108 2357 #&gt; 2 2013 1 31 1 2100 181 124 2225 #&gt; 3 2013 11 13 1 2359 2 442 440 #&gt; 4 2013 12 16 1 2359 2 447 437 #&gt; 5 2013 12 20 1 2359 2 430 440 #&gt; 6 2013 12 26 1 2359 2 437 440 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Exercise 1.5 对flights排序以找出速度最快的航班 这个排序条件需要用到表达式，速度 = distance / air_time flights %&gt;% arrange(distance / air_time) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 28 1917 1825 52 2118 1935 #&gt; 2 2013 6 29 755 800 -5 1035 909 #&gt; 3 2013 8 28 932 940 -8 1116 1051 #&gt; 4 2013 1 30 1037 955 42 1221 1100 #&gt; 5 2013 11 27 556 600 -4 727 658 #&gt; 6 2013 5 21 558 600 -2 721 657 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 1.4 使用select()选择列 如今，数据集有几百个甚至几千个变量已经司空见惯。这种情况下，如何找出真正感兴趣的变量经常是一个挑战。通过基于变量名的操作，select()函数可以让我们快速生成一个有用的变量子集。 虽然航班数据只有 19 个变量，但还是可以用来了解一下select()函数的大致用法： ## 只选择year,month,day 三个变量 flights %&gt;% select(year, month, day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; # … with 3.368e+05 more rows 顺便说一句，如果把变量名变成字符串或者它在所有变量中的顺序也可以正常工作,如flights %&gt;% select(\"year\", \"month\", \"day\")和flights %&gt;% select(1, 2, 3)和上面代码会返回一样结果，但是这两种方法都不值得推荐。 当希望选择的列比较多时，可以先用一个向量储存，但用向量储存的必须是字符串形式的列名： vars = c(&quot;arr_delay&quot;, &quot;dep_delay&quot;) flights %&gt;% select(vars) #&gt; # A tibble: 336,776 x 2 #&gt; arr_delay dep_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 11 2 #&gt; 2 20 4 #&gt; 3 33 2 #&gt; 4 -18 -1 #&gt; 5 -25 -6 #&gt; 6 12 -4 #&gt; # … with 3.368e+05 more rows 另一个问题是，如果vars本身就是一个变量名，select()函数将会只选择出vars这一类，而不会读取其中的值，在前面加上操作符!!!将会使select()按照我们希望的那样工作。 df &lt;- tibble(vars = c(1, 2, 3), number_1 = c(4, 5, 6), number_2 = c(7, 8, 9)) vars = c(&quot;number_1&quot;,&quot;number_2&quot;) ## 希望选取number_1和number_2两列的错误做法 df %&gt;% select(vars) #&gt; # A tibble: 3 x 1 #&gt; vars #&gt; &lt;dbl&gt; #&gt; 1 1 #&gt; 2 2 #&gt; 3 3 ## 正确做法 df %&gt;% select(!!!vars) #&gt; # A tibble: 3 x 2 #&gt; number_1 number_2 #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 7 #&gt; 2 5 8 #&gt; 3 6 9 select() 还可以重命名变量，但我们很少这样使用它，因为这样会丢掉所有未明确提及的变量。我们应该使用select() 函数的变体 rename() 函数来重命名变量，它会把未提及的那些变量按照原名字放到生成的数据框里： ## 将tail_num 重命名为tailnum rename(flights, tail_num = tailnum) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; # … with 3.368e+05 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tail_num &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 其他常见的select()函数用法如下所示： ## 选择“year”和“day”之间的所有变量，使用冒号 flights %&gt;% select(year:day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; # … with 3.368e+05 more rows ## 选择不在“year”和“day”之间的所有列，使用减号 flights %&gt;% select(-(year:day)) #&gt; # A tibble: 336,776 x 16 #&gt; dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 517 515 2 830 819 11 UA #&gt; 2 533 529 4 850 830 20 UA #&gt; 3 542 540 2 923 850 33 AA #&gt; 4 544 545 -1 1004 1022 -18 B6 #&gt; 5 554 600 -6 812 837 -25 DL #&gt; 6 554 558 -4 740 728 12 UA #&gt; # … with 3.368e+05 more rows, and 9 more variables: flight &lt;int&gt;, #&gt; # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, #&gt; # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 还可以在select()函数中使用一些辅助函数： * starts_with(\"abc\")：匹配以名字以“abc”开头的列 flights %&gt;% select(starts_with(&quot;arr&quot;)) ## 所有以arr开头的列 #&gt; # A tibble: 336,776 x 2 #&gt; arr_time arr_delay #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 830 11 #&gt; 2 850 20 #&gt; 3 923 33 #&gt; 4 1004 -18 #&gt; 5 812 -25 #&gt; 6 740 12 #&gt; # … with 3.368e+05 more rows ends_with(\"xyz\"): 匹配名字以“xyz”结尾的列 ## 所有以&quot;delay&quot;结尾的列 flights %&gt;% select(ends_with(&quot;delay&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; dep_delay arr_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 #&gt; 2 4 20 #&gt; 3 2 33 #&gt; 4 -1 -18 #&gt; 5 -6 -25 #&gt; 6 -4 12 #&gt; # … with 3.368e+05 more rows contains(\"ijk\")，匹配名字包含“ijk”的列 ## 所有包含&quot;time&quot;的列 flights %&gt;% select(contains(&quot;time&quot;)) #&gt; # A tibble: 336,776 x 6 #&gt; dep_time sched_dep_time arr_time sched_arr_time air_time time_hour #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dttm&gt; #&gt; 1 517 515 830 819 227 2013-01-01 05:00:00 #&gt; 2 533 529 850 830 227 2013-01-01 05:00:00 #&gt; 3 542 540 923 850 160 2013-01-01 05:00:00 #&gt; 4 544 545 1004 1022 183 2013-01-01 05:00:00 #&gt; 5 554 600 812 837 116 2013-01-01 06:00:00 #&gt; 6 554 558 740 728 150 2013-01-01 05:00:00 #&gt; # … with 3.368e+05 more rows matches(\"(.)\\\\1\")：选择名字符合正则表达式要求的列，后面将具体讲述正则表达式 num_range(\"x\",c(1,2,3))，选择名字为“x1”、“x2”、“x3”的列 df &lt;- tibble(x1 = 1,x2 = 2,x3 = 3) df %&gt;% select(num_range(&quot;X&quot;, 1:3)) #&gt; # A tibble: 1 x 0 one_of(character_1,···,character_n):如果某个列的名字出现在序列里，则选出它 flights %&gt;% select(one_of(&quot;arr_delay&quot;, &quot;dep_delay&quot;, &quot;xyz&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; arr_delay dep_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 11 2 #&gt; 2 20 4 #&gt; 3 33 2 #&gt; 4 -18 -1 #&gt; 5 -25 -6 #&gt; 6 12 -4 #&gt; # … with 3.368e+05 more rows everything()：匹配所有(剩余)变量，当想要将几个变量移到数据集开头时，这种方法很有用 ## 将time_hour和air_time两个变量移到flights数据的开头 flights %&gt;% select(time_hour,air_time, everything()) #&gt; # A tibble: 336,776 x 19 #&gt; time_hour air_time year month day dep_time sched_dep_time #&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013-01-01 05:00:00 227 2013 1 1 517 515 #&gt; 2 2013-01-01 05:00:00 227 2013 1 1 533 529 #&gt; 3 2013-01-01 05:00:00 160 2013 1 1 542 540 #&gt; 4 2013-01-01 05:00:00 183 2013 1 1 544 545 #&gt; 5 2013-01-01 06:00:00 116 2013 1 1 554 600 #&gt; 6 2013-01-01 05:00:00 150 2013 1 1 554 558 #&gt; # … with 3.368e+05 more rows, and 12 more variables: dep_delay &lt;dbl&gt;, #&gt; # arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, #&gt; # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, distance &lt;dbl&gt;, #&gt; # hour &lt;dbl&gt;, minute &lt;dbl&gt; last_col(offset = n)：选择倒数第n列，不设置offset时，默认选择最后一列 flights %&gt;% select(last_col()) #&gt; # A tibble: 336,776 x 1 #&gt; time_hour #&gt; &lt;dttm&gt; #&gt; 1 2013-01-01 05:00:00 #&gt; 2 2013-01-01 05:00:00 #&gt; 3 2013-01-01 05:00:00 #&gt; 4 2013-01-01 05:00:00 #&gt; 5 2013-01-01 06:00:00 #&gt; 6 2013-01-01 05:00:00 #&gt; # … with 3.368e+05 more rows 利用这些帮助函数，我们可以为选择列设置任意数目的条件，select()中以逗号分隔的列表示“或” 关系，如： ## 找出以“arr”开头或者以“time”结尾的列 flights %&gt;% select(starts_with(&quot;arr&quot;), ends_with(&quot;time&quot;)) #&gt; # A tibble: 336,776 x 6 #&gt; arr_time arr_delay dep_time sched_dep_time sched_arr_time air_time #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 830 11 517 515 819 227 #&gt; 2 850 20 533 529 830 227 #&gt; 3 923 33 542 540 850 160 #&gt; 4 1004 -18 544 545 1022 183 #&gt; 5 812 -25 554 600 837 116 #&gt; 6 740 12 554 558 728 150 #&gt; # … with 3.368e+05 more rows 注意 所有帮助函数都忽略大小写，如下所示 flights %&gt;% select(ends_with(&quot;DELAY&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; dep_delay arr_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 #&gt; 2 4 20 #&gt; 3 2 33 #&gt; 4 -1 -18 #&gt; 5 -6 -25 #&gt; 6 -4 12 #&gt; # … with 3.368e+05 more rows 如果要区分大小写，可以设置任意帮助函数的参数ignore.case = FALSE flights %&gt;% select(ends_with(&quot;DELAY&quot;,ignore.case = F)) ## 将不会选择出任何列 #&gt; # A tibble: 336,776 x 0 1.4.1 练习 Exercise 1.6 从flights数据集中选择dep_time、dep_delay、arr_time、arr_delay，找出尽可能多的方法 先查看这些变量的位置： glimpse(flights) #&gt; Observations: 336,776 #&gt; Variables: 19 #&gt; $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, … #&gt; $ month &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #&gt; $ day &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … #&gt; $ dep_time &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558,… #&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600,… #&gt; $ dep_delay &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -… #&gt; $ arr_time &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849… #&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851… #&gt; $ arr_delay &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -… #&gt; $ carrier &lt;chr&gt; &quot;UA&quot;, &quot;UA&quot;, &quot;AA&quot;, &quot;B6&quot;, &quot;DL&quot;, &quot;UA&quot;, &quot;B6&quot;, &quot;EV&quot;, &quot;B6&quot;, … #&gt; $ flight &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, … #&gt; $ tailnum &lt;chr&gt; &quot;N14228&quot;, &quot;N24211&quot;, &quot;N619AA&quot;, &quot;N804JB&quot;, &quot;N668DN&quot;, &quot;N39… #&gt; $ origin &lt;chr&gt; &quot;EWR&quot;, &quot;LGA&quot;, &quot;JFK&quot;, &quot;JFK&quot;, &quot;LGA&quot;, &quot;EWR&quot;, &quot;EWR&quot;, &quot;LGA&quot;… #&gt; $ dest &lt;chr&gt; &quot;IAH&quot;, &quot;IAH&quot;, &quot;MIA&quot;, &quot;BQN&quot;, &quot;ATL&quot;, &quot;ORD&quot;, &quot;FLL&quot;, &quot;IAD&quot;… #&gt; $ air_time &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, … #&gt; $ distance &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733,… #&gt; $ hour &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, … #&gt; $ minute &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, … #&gt; $ time_hour &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 … # 常规方法 flights %&gt;% select(dep_time, dep_delay, arr_time, arr_delay) #&gt; # A tibble: 336,776 x 4 #&gt; dep_time dep_delay arr_time arr_delay #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 517 2 830 11 #&gt; 2 533 4 850 20 #&gt; 3 542 2 923 33 #&gt; 4 544 -1 1004 -18 #&gt; 5 554 -6 812 -25 #&gt; 6 554 -4 740 12 #&gt; # … with 3.368e+05 more rows # 用one_of() vars = c(&quot;dep_time&quot;, &quot;dep_delay&quot;, &quot;arr_time&quot;, &quot;arr_delay&quot;) flights %&gt;% select(one_of(vars)) #&gt; # A tibble: 336,776 x 4 #&gt; dep_time dep_delay arr_time arr_delay #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 517 2 830 11 #&gt; 2 533 4 850 20 #&gt; 3 542 2 923 33 #&gt; 4 544 -1 1004 -18 #&gt; 5 554 -6 812 -25 #&gt; 6 554 -4 740 12 #&gt; # … with 3.368e+05 more rows # 多个条件 flights %&gt;% select(starts_with(&quot;arr_&quot;), starts_with(&quot;dep_&quot;)) #&gt; # A tibble: 336,776 x 4 #&gt; arr_time arr_delay dep_time dep_delay #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 830 11 517 2 #&gt; 2 850 20 533 4 #&gt; 3 923 33 542 2 #&gt; 4 1004 -18 544 -1 #&gt; 5 812 -25 554 -6 #&gt; 6 740 12 554 -4 #&gt; # … with 3.368e+05 more rows Exercise 1.7 如果在select()中多次计入一个变量名，会发生什么情况？ select()函数将会忽略重复出现的变量，只选出一列，同时也不会报错： flights %&gt;% select(year, month, day, year, month, day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; # … with 3.368e+05 more rows 1.5 mutate() 创建变量 除了选择现有的列，经常还需要添加新列。新列是现有列的函数，这就 mutate() 函数的作用。 mutate() 总是将新列添加在最后,格式为新列名= 表达式。为了便于观察它的效果，我们需要先创建一个更狭窄的数据集，以便能看到新变量。 例如，我们希望创建两个新列gain和hours，分别表示飞机在飞行过程中弥补的延误时间 (gain = arr_dealy - dep_delay)，然后把飞行时间换算成小时 hours = air_time / 60 (flights_gain &lt;- flights %&gt;% select(ends_with(&quot;delay&quot;),air_time) %&gt;% mutate(gain = arr_delay - dep_delay, hours = air_time / 60)) #&gt; # A tibble: 336,776 x 5 #&gt; dep_delay arr_delay air_time gain hours #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 227 9 3.78 #&gt; 2 4 20 227 16 3.78 #&gt; 3 2 33 160 31 2.67 #&gt; 4 -1 -18 183 -17 3.05 #&gt; 5 -6 -25 116 -19 1.93 #&gt; 6 -4 12 150 16 2.5 #&gt; # … with 3.368e+05 more rows 一旦新列被创建，就可以立即使用。例如，可能想知道对gain做时间上的平均： flights_gain %&gt;% mutate(gain_per_hour = gain / hours) #&gt; # A tibble: 336,776 x 6 #&gt; dep_delay arr_delay air_time gain hours gain_per_hour #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 227 9 3.78 2.38 #&gt; 2 4 20 227 16 3.78 4.23 #&gt; 3 2 33 160 31 2.67 11.6 #&gt; 4 -1 -18 183 -17 3.05 -5.57 #&gt; 5 -6 -25 116 -19 1.93 -9.83 #&gt; 6 -4 12 150 16 2.5 6.4 #&gt; # … with 3.368e+05 more rows 以上的数据转换也可以通过mutate()一次完成： flights %&gt;% select(ends_with(&quot;delay&quot;),air_time) %&gt;% mutate( gain = arr_delay - dep_delay, hours = air_time / 60, gain_per_hour = gain/hours) #&gt; # A tibble: 336,776 x 6 #&gt; dep_delay arr_delay air_time gain hours gain_per_hour #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 227 9 3.78 2.38 #&gt; 2 4 20 227 16 3.78 4.23 #&gt; 3 2 33 160 31 2.67 11.6 #&gt; 4 -1 -18 183 -17 3.05 -5.57 #&gt; 5 -6 -25 116 -19 1.93 -9.83 #&gt; 6 -4 12 150 16 2.5 6.4 #&gt; # … with 3.368e+05 more rows 如果只想在保留新变量，可以使用transmute()： flights %&gt;% select(ends_with(&quot;delay&quot;),air_time) %&gt;% transmute( gain = arr_delay - dep_delay, hours = air_time / 60, gain_per_hour = gain/hours) #&gt; # A tibble: 336,776 x 3 #&gt; gain hours gain_per_hour #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 9 3.78 2.38 #&gt; 2 16 3.78 4.23 #&gt; 3 31 2.67 11.6 #&gt; 4 -17 3.05 -5.57 #&gt; 5 -19 1.93 -9.83 #&gt; 6 16 2.5 6.4 #&gt; # … with 3.368e+05 more rows 1.5.1 常用创建函数（Using creation functions） 有多种函数可以帮助mutate()创建新变量。比较重要的一点是，这些函数必须是向量化的：它能接受一个向量作为输入，并返回一个向量作为输出，而且输入和输出向量长度相等。下面介绍一些比较常用的函数。 **算术运算符 +、-、*、/、^** 它们都是向量化的，使用所谓的“循环法则(recycling rules)”。如果一个参数比另一个参数短，那么前者会自动扩展到相同的长度，但某个参数是单个数值时，这种方式是最有效的，如air_time * 60 或者 hours * 60 + minute等。 算术运算符的另一个用途是与我们后面将很快学到的聚集函数结合起来使用。例如,x / sum(x)可以计算出x的各个分量在总数中的比例，y - mean(y)计算出y的各个分量与均值之间的差异。 模运算符 %/% 和 % %/%（整除）和%%（求余）满足x == y * (x %/% y) + （x %% y, 这两个运算符在Python中分别是// 和 % 。 模运算非常好用，因为它可以拆分整数。例如，在flights数据集中，可以根据dep_time计算出hour和minute： ## air_time中表示时间的方式是“xyz”表示x点yz分 flights %&gt;% transmute(hour = air_time %/% 100, minute = air_time %% 100) #&gt; # A tibble: 336,776 x 2 #&gt; hour minute #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 27 #&gt; 2 2 27 #&gt; 3 1 60 #&gt; 4 1 83 #&gt; 5 1 16 #&gt; 6 1 50 #&gt; # … with 3.368e+05 more rows 对数函数 log()/log2()/log10() 在处理取值范围变化多个数量级的数据时，对数变换很有用。其他条件相同的情况下，更推荐使用log2()函数，因为它的解释很容易，对数变换后的变量每增加一个单位，意味着原始变量加倍 ； 减少一个单位，则原始数据变为原来的一半。 偏移函数 lead()和lag()函数分别将一个向量向前或向后移动指定的单位： x &lt;- 1:10 ## 将x向前移动2个单位 lead(x,n=2) #&gt; [1] 3 4 5 6 7 8 9 10 NA NA ## 将x向后移动一个单位（默认n=1） lag(x) #&gt; [1] NA 1 2 3 4 5 6 7 8 9 累加和滚动聚合 R的基础包提供了计算累加和、累加积、累加最小值和累加最大值的函数：cumsum()、cumprod()、cummax()、cummin()；dplyr包还提供了cummean()函数以计算累积平均值。 x &lt;- 1:10 cumsum(x) #&gt; [1] 1 3 6 10 15 21 28 36 45 55 cumprod(x) #&gt; [1] 1 2 6 24 120 720 5040 40320 362880 #&gt; [10] 3628800 cummax(x) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 cummin(x) #&gt; [1] 1 1 1 1 1 1 1 1 1 1 cummean(x) #&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 逻辑比较 &gt;、&lt;=、&gt;、&gt;=、==、!= 如果要进行一系列复杂的逻辑运算，最好将中间结果保存在新变量中，这样就可以检查每一步是否都符合预期。 排秩 排秩函数有很多，从min_rank()开始，它可以完成最常用的排秩任务。默认的排秩方式是，最小的值获得最前面的秩（升序），使用desc(x)可以让最大的值获得前面的名次,NA值对应的秩也是NA： x &lt;- c(1,2,2,NA,3,4) min_rank(x) #&gt; [1] 1 2 2 NA 4 5 min_rank(desc(x)) #&gt; [1] 5 3 3 NA 2 1 min_rank()函数把相同值赋予相同的秩，如果有n个值秩相同为x，则下一个值的秩会直接从x+n开始 如果min_rank()无法满足需要，可以看一下它的一些变体： row_number(),相同值不同秩 x &lt;- c(1,2,2,NA,3,4) min_rank(x) #&gt; [1] 1 2 2 NA 4 5 row_number(x) #&gt; [1] 1 2 3 NA 4 5 dense_rank：相同值的秩相同，但下一个值的秩不会跳转 x &lt;- c(1,2,2,NA,3,4) min_rank(x) #&gt; [1] 1 2 2 NA 4 5 row_number(x) #&gt; [1] 1 2 3 NA 4 5 dense_rank(x) #&gt; [1] 1 2 2 NA 3 4 percent_rank(): 将秩按照比例压缩为[0,1]的值 x &lt;- c(1,2,2,NA,3,4) percent_rank(x) #&gt; [1] 0.00 0.25 0.25 NA 0.75 1.00 ntile()：breaks the input vector into n buckets. x &lt;- c(1,3,4,5,6,8) ntile(x,n=2) #&gt; [1] 1 1 1 2 2 2 ntile(x,n=3) #&gt; [1] 1 1 2 2 3 3 1.5.2 练习 虽然现在的dep_time和sched_dep_time变量方便阅读，但不适合计算，因为它们实际上并不是连续型数值。将它们转换为一种更方便的表示形式，即从0点开始的分钟数 ## 观察两个变量的存储方式 flights %&gt;% select(dep_time,sched_dep_time) #&gt; # A tibble: 336,776 x 2 #&gt; dep_time sched_dep_time #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 517 515 #&gt; 2 533 529 #&gt; 3 542 540 #&gt; 4 544 545 #&gt; 5 554 600 #&gt; 6 554 558 #&gt; # … with 3.368e+05 more rows xyz表示x点yz分，则总分钟数为x %/% 100 * 60 + x %% 100 ; 但有一个问题是，由于0点是用2400代表的，经过这样的转换它变为1440，我们希望它变为0，所以在外层再套一个%% 1440 flights %&gt;% transmute(dep_time_mins = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440, sched_dep_time_mins = (sched_dep_time %/% 100 * 60 + sched_dep_time %% 100) %% 1440) #&gt; # A tibble: 336,776 x 2 #&gt; dep_time_mins sched_dep_time_mins #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 317 315 #&gt; 2 333 329 #&gt; 3 342 340 #&gt; 4 344 345 #&gt; 5 354 360 #&gt; 6 354 358 #&gt; # … with 3.368e+05 more rows 比较dep_time、sched_dep_time和dep_delay，这三者应该是何种关系？ flights_deptime &lt;- mutate(flights, dep_time_min = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440, sched_dep_time_min = (sched_dep_time %/% 100 * 60 + sched_dep_time %% 100) %% 1440, dep_delay_diff = dep_delay - dep_time_min + sched_dep_time_min ) filter(flights_deptime, dep_delay_diff != 0) %&gt;% select(dep_delay_diff) #&gt; # A tibble: 1,236 x 1 #&gt; dep_delay_diff #&gt; &lt;dbl&gt; #&gt; 1 1440 #&gt; 2 1440 #&gt; 3 1440 #&gt; 4 1440 #&gt; 5 1440 #&gt; 6 1440 #&gt; # … with 1,230 more rows 如上所示，经过分钟的转换后，有1236行的dep_delay 不等于 dep_time - sched_dep_time. 有趣的是，这些差值全部等于1440。 &gt; the discrepancies could be because a flight was scheduled to depart before midnight, but was delayed after midnight. All of these discrepancies are exactly equal to 1440 (24 hours), and the flights with these discrepancies were scheduled to depart later in the day. 使用排秩函数找出10个出发延误时间最长的航班 ## 使min_rank默认小的值获得小的秩，arrange()默认降序排列，其中一个函数中要使用desc() flights %&gt;% mutate(delay_rank = min_rank(desc(dep_delay))) %&gt;% arrange(delay_rank) %&gt;% select(year,month,day,dep_delay,delay_rank) #&gt; # A tibble: 336,776 x 5 #&gt; year month day dep_delay delay_rank #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 2013 1 9 1301 1 #&gt; 2 2013 6 15 1137 2 #&gt; 3 2013 1 10 1126 3 #&gt; 4 2013 9 20 1014 4 #&gt; 5 2013 7 22 1005 5 #&gt; 6 2013 4 10 960 6 #&gt; # … with 3.368e+05 more rows 1:3 + 1:10会返回什么？为什么？ 1:3 + 1:10 #&gt; [1] 2 4 6 5 7 9 8 10 12 11 当一个向量中的值不够用时，这个向量会被循环使用 1:3 + 1:10等价于c(1 + 1, 2 + 2, 3 + 3, 1 + 4, 2 + 5, 3 + 6, 1 + 7, 2 + 8, 3 + 9, 1 + 10) c(1 + 1, 2 + 2, 3 + 3, 1 + 4, 2 + 5, 3 + 6, 1 + 7, 2 + 8, 3 + 9, 1 + 10) #&gt; [1] 2 4 6 5 7 9 8 10 12 11 1.6 使用summarize()进行分组摘要 最后一个核心函数是summarize()，它用来计算摘要统计量，可以将数据框折叠成一行： ## 计算平均出发延误时间 summarize(flights,delay = mean(dep_delay,na.rm = TRUE)) #&gt; # A tibble: 1 x 1 #&gt; delay #&gt; &lt;dbl&gt; #&gt; 1 12.6 如果不和 group_by() 一起使用，那么 summarize() 也就没什么大用。group_by() 函数与 summarize() 联合使用的时候可以将分析单位从整个数据集更改为单个分组，接下来，在分组后的数据框上使用dplyr函数时，它们会自动应用到每个分组。更简单第说，你想从哪个层级上分析问题，就在group_by中对什么层级进行分组。group_by() + summarize()可以实现类似aggregate()函数的效果。 例如，我们想知道每一天的平均出发延误时间，可以先对(year,month,day)进行分组，然后再使用summarize()： flights %&gt;% group_by(year,month,day) %&gt;% summarize(delay = mean(dep_delay,na.rm = T)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.5 #&gt; 2 2013 1 2 13.9 #&gt; 3 2013 1 3 11.0 #&gt; 4 2013 1 4 8.95 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; # … with 359 more rows 注意，summarize()很不同的一点就是它会自动选择列，只在结果中显示之前在group_by中进行分类的变量和summarize()中算出的摘要统计量。 这个生成的数据框只有365行，因为flights数据集中的时间跨度只有一年，(year, month, day)的唯一组合只可能有365个，这就是summarize()中的摘要函数的折叠效果：接受一个向量，只返回一个值，然后再用分组变量的一个组合来标识这个摘要量的对象（哪个层级上的平均值、最大值？）。从这个角度看，summarize()和mutate()对函数的要求恰好相反。 用aggregate()函数的写法： aggregate(dep_delay~year+month+day, FUN = mean, data = flights) %&gt;% head(20) #&gt; year month day dep_delay #&gt; 1 2013 1 1 11.549 #&gt; 2 2013 2 1 10.853 #&gt; 3 2013 3 1 11.016 #&gt; 4 2013 4 1 12.421 #&gt; 5 2013 5 1 2.903 #&gt; 6 2013 6 1 2.778 #&gt; 7 2013 7 1 56.234 #&gt; 8 2013 8 1 34.574 #&gt; 9 2013 9 1 4.233 #&gt; 10 2013 10 1 -0.099 #&gt; 11 2013 11 1 13.273 #&gt; 12 2013 12 1 9.004 #&gt; 13 2013 1 2 13.859 #&gt; 14 2013 2 2 5.422 #&gt; 15 2013 3 2 8.027 #&gt; 16 2013 4 2 8.260 #&gt; 17 2013 5 2 6.389 #&gt; 18 2013 6 2 34.013 #&gt; 19 2013 7 2 19.285 #&gt; 20 2013 8 2 13.254 比较这两个结果，我们可以发现group_by()中越靠后的参数是越基本的单位，group_by(year,month,day)将按照 day, month, year 的顺序开始循环 ； 而 aggregate() 函数则正好相反 1.6.1 缺失值 在按照日期计算平均出发延误时间的例子中，使用mean()时设置了参数na.rm = T，如果没有这样做，很多日期的平均延误时间将是缺失值： flights %&gt;% group_by(year,month,day) %&gt;% summarize(delay = mean(dep_delay)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 NA #&gt; 2 2013 1 2 NA #&gt; 3 2013 1 3 NA #&gt; 4 2013 1 4 NA #&gt; 5 2013 1 5 NA #&gt; 6 2013 1 6 NA #&gt; # … with 359 more rows 这是因为聚合函数遵循缺失值的一般规则：如果输入中有缺失值，那么输出也是缺失值。好在所有聚合函数都有一个 na.rm 参数，可以在计算前出去缺失值。 在这个示例中，缺失值来源于取消的航班。我们也可以先取出取消的航班来解决却实质问题。保存去除缺失值的数据集为not_cancelled，以便我们可以在接下来的几个示例中继续使用： not_cancelled &lt;- flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) not_cancelled %&gt;% group_by(year,month,day) %&gt;% summarize(delay = mean(dep_delay)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.4 #&gt; 2 2013 1 2 13.7 #&gt; 3 2013 1 3 10.9 #&gt; 4 2013 1 4 8.97 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; # … with 359 more rows 1.6.2 计数函数 n() 函数是一个与摘要函数summarize()配合的计数函数，它不需要任何参数，单独使用时，它计算的就是行计数： flights %&gt;% summarize(n = n()) #&gt; # A tibble: 1 x 1 #&gt; n #&gt; &lt;int&gt; #&gt; 1 336776 和group_by联合使用时，它可以计算分组变量的每个水平上各有多少个观测： ## 每个月各有多少趟航班 flights %&gt;% group_by(month) %&gt;% summarize(n = n()) ## 等价于summarize(n = sum(month)) #&gt; # A tibble: 12 x 2 #&gt; month n #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 27004 #&gt; 2 2 24951 #&gt; 3 3 28834 #&gt; 4 4 28330 #&gt; 5 5 28796 #&gt; 6 6 28243 #&gt; # … with 6 more rows n()会把缺失值也包含到计数中，如果想要计算出非缺失值的数量，可以使用sum(is.na(x))。如果想要计算唯一值的数量，可以使用n_distinct() ## 哪个目的地有最多的航空公司？ flights %&gt;% group_by(dest) %&gt;% summarize(carriers = n_distinct(carrier)) %&gt;% arrange(desc(carriers)) #&gt; # A tibble: 105 x 2 #&gt; dest carriers #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 ATL 7 #&gt; 2 BOS 7 #&gt; 3 CLT 7 #&gt; 4 ORD 7 #&gt; 5 TPA 7 #&gt; 6 AUS 6 #&gt; # … with 99 more rows 除了n() 以外， dplyr 提供了 4 个正式的计数函数： tally(x, wt = NULL, sort = FALSE, name = &quot;n&quot;) count(x, ..., wt = NULL, sort = FALSE, name = &quot;n&quot;, .drop = group_by_drop_default(x)) add_tally(x, wt, sort = FALSE, name = &quot;n&quot;) add_count(x, ..., wt = NULL, sort = FALSE, name = &quot;n&quot;) x %&gt;% group_by(var) %&gt;% tally() 是简化版的 group_by(var) + summarize(n()) x %&gt;% count(var) 等价于 x %&gt;% gruop_by(var) %&gt;% tally() x %&gt;% group_by(var) %&gt;% add_tally 在 原数据集 中增添一列，记录 var 的不同水平的计数，等价于 x %&gt;% add_count(var)，注意这两个函数返回值的维度和原数据框相同(摘要数据框往往不利于细节观察)！！它们等价于 group_by() %&gt;% mutate(n()) ## 无分组时，tally()即为样本数 mtcars %&gt;% tally #&gt; n #&gt; 1 32 ## tally() 的一般用法 mtcars %&gt;% group_by(cyl) %&gt;% tally() #&gt; # A tibble: 3 x 2 #&gt; cyl n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 4 11 #&gt; 2 6 7 #&gt; 3 8 14 ## count() 等价 group_by() + tally() mtcars %&gt;% count(cyl) #&gt; # A tibble: 3 x 2 #&gt; cyl n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 4 11 #&gt; 2 6 7 #&gt; 3 8 14 ## count() 也可以在已有分组上继续分组 mtcars %&gt;% group_by(gear) %&gt;% count(carb) #&gt; # A tibble: 11 x 3 #&gt; # Groups: gear [3] #&gt; gear carb n #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 3 1 3 #&gt; 2 3 2 4 #&gt; 3 3 3 3 #&gt; 4 3 4 5 #&gt; 5 4 1 4 #&gt; 6 4 2 4 #&gt; # … with 5 more rows ## add_tally() is short-hand for mutate() mtcars %&gt;% add_tally() #&gt; # A tibble: 32 x 12 #&gt; mpg cyl disp hp drat wt qsec vs am gear carb n #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 32 #&gt; 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 32 #&gt; 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 32 #&gt; 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 32 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 32 #&gt; 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 32 #&gt; # … with 26 more rows ## add_count() is a short-hand for group_by() + add_tally() mtcars %&gt;% add_count(cyl, name = &quot;count&quot;) %&gt;% select(cyl, count) #&gt; # A tibble: 32 x 2 #&gt; cyl count #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 6 7 #&gt; 2 6 7 #&gt; 3 4 11 #&gt; 4 6 7 #&gt; 5 8 14 #&gt; 6 6 7 #&gt; # … with 26 more rows # add_count() is useful for groupwise filtering # e.g.: show details for species that have a single member starwars %&gt;% add_count(species) %&gt;% filter(n == 1) #&gt; # A tibble: 29 x 14 #&gt; name height mass hair_color skin_color eye_color birth_year gender homeworld #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Gree… 173 74 &lt;NA&gt; green black 44 male Rodia #&gt; 2 Jabb… 175 1358 &lt;NA&gt; green-tan… orange 600 herma… Nal Hutta #&gt; 3 Yoda 66 17 white green brown 896 male &lt;NA&gt; #&gt; 4 Bossk 190 113 none green red 53 male Trandosha #&gt; 5 Ackb… 180 83 none brown mot… orange 41 male Mon Cala #&gt; 6 Wick… 88 20 brown brown brown 8 male Endor #&gt; # … with 23 more rows, and 5 more variables: species &lt;chr&gt;, films &lt;list&gt;, #&gt; # vehicles &lt;list&gt;, starships &lt;list&gt;, n &lt;int&gt; 另外，在z和一些函数中函数中设置sort = T可以使观测按照计数倒序排列，name参数可以指定新生成的计数行名字（默认为“n”): not_cancelled %&gt;% count(dest, sort = T, name = &quot;count&quot;) #&gt; # A tibble: 104 x 2 #&gt; dest count #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 ATL 16837 #&gt; 2 ORD 16566 #&gt; 3 LAX 16026 #&gt; 4 BOS 15022 #&gt; 5 MCO 13967 #&gt; 6 CLT 13674 #&gt; # … with 98 more rows 还可以提供一个加权变量。例如，可以使用一下代码算出每架飞机飞行的总里程（实际上就是按计算某变量分组上另一个变量的和）： not_cancelled %&gt;% count(tailnum, wt = distance) #&gt; # A tibble: 4,037 x 2 #&gt; tailnum n #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 D942DN 3418 #&gt; 2 N0EGMQ 239143 #&gt; 3 N10156 109664 #&gt; 4 N102UW 25722 #&gt; 5 N103US 24619 #&gt; 6 N104UW 24616 #&gt; # … with 4,031 more rows 进行聚合时，包含一列计数n()或非缺失值的计数sum(!is.na())很有用。这样就可以检查一下，以确保自己没有基于非常有限的样本做结论。 例如，查看一下具有最长平均到达延误时间的飞机（基于飞机编号进行识别): delays &lt;- not_cancelled %&gt;% group_by(tailnum) %&gt;% summarize(delay = mean(arr_delay)) ggplot(delays) + geom_histogram(aes(delay)) 有些飞机的平均到达延误事件竟然接近300分钟，我们可以画一张航班数量和平均延误时间的散点图，一遍获得更深刻的理解: ## n = n()对group_by中的变量水平进行计数，生成一个计数变量命名为n delays &lt;- not_cancelled %&gt;% group_by(tailnum) %&gt;% summarize( delay = mean(arr_delay), n = n()) ggplot(delays) + geom_point(aes(x = n,y = delay),alpha = 0.1) 从散点图可以看出，如果航班对应的出航次数非常少时，平均延误时间的变动特别大，所有延误时间较长的航班的出航次数几乎都在 0 右边一点点。这张图的形状非常能说明问题:当绘制均值（或其他摘要统计量）和分组规模的关系时，总能看到样本量的增加，变动在不断减小。（样本统计量的方差随样本数变小）。 这种数据模式还有另外一种常见的变体。我们来看一下棒球击球手的平均表现与击球次数之间的关系。我们用Lahman包中的数据埃及算棒球大联盟中的每个棒球队员的加大率（安打数 / 打数): library(Lahman) batters &lt;- Batting %&gt;% group_by(playerID) %&gt;% summarize( ba = sum(H,na.rm = T) / sum(AB,na.rm = T), ab = sum(AB,na.rm = T)) batters %&gt;% filter(ab &gt; 100) %&gt;% ggplot(aes(ab, ba)) + geom_point() + geom_smooth(se = FALSE) 当绘制击球手的能力（用打击率 ba 衡量）与击球机会数量（用总打数ab衡量）之间的关系时，可以看到两个趋势： 总大数越多，不同击球手的打击率之间变动越小 能力（ba）和击球机会数量（ab）之间存在正相关。这是因为球队会控制击球手的出场，很显然，球队会优先选择最好的队员。 这对球员排名也有重要印象，如果只是使用desc(ba)进行排序，明显受益的将是那些因为出场数很少而侥幸有很高击打率的球员，而不是真正能力最高的球员： batters %&gt;% arrange(desc(ba)) #&gt; # A tibble: 19,428 x 3 #&gt; playerID ba ab #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 abramge01 1 1 #&gt; 2 alberan01 1 1 #&gt; 3 allarko01 1 1 #&gt; 4 banisje01 1 1 #&gt; 5 bartocl01 1 1 #&gt; 6 bassdo01 1 1 #&gt; # … with 1.942e+04 more rows 1.6.3 逻辑值的计数和比例:sum(x &gt; 10) 和 mean(y == 0) 当与数值型函数一同使用时，TRUE会转换为1，FALSE会转换为0。这使得sum()和mean()非常适用于逻辑值：sum()可以找出x中TRUE的数量，mean()则可以找出比例。 ## 每天中有多少架航班是在早上5点前出发的？（这通常表明前一天延误的航班数量） not_cancelled %&gt;% group_by(year,month,day) %&gt;% summarize(n_early = sum(dep_time &lt; 500)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day n_early #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 0 #&gt; 2 2013 1 2 3 #&gt; 3 2013 1 3 4 #&gt; 4 2013 1 4 3 #&gt; 5 2013 1 5 3 #&gt; 6 2013 1 6 2 #&gt; # … with 359 more rows ## 每天中到达时间误超过一小时的航班比例是多少？ not_cancelled %&gt;% group_by(year,month,day) %&gt;% summarize(hour_perc = mean(arr_delay &gt; 60)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day hour_perc #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 0.0722 #&gt; 2 2013 1 2 0.0851 #&gt; 3 2013 1 3 0.0567 #&gt; 4 2013 1 4 0.0396 #&gt; 5 2013 1 5 0.0349 #&gt; 6 2013 1 6 0.0470 #&gt; # … with 359 more rows 1.6.4 其他常用的摘要函数 R中还提供了许多常用的摘要函数 位置度量 我们已经使用过mean(x)、但用 median(x) 计算中位数也非常有用。 ## 将聚合函数和逻辑筛选组合起来使用 not_cancelled %&gt;% group_by(year,month,day) %&gt;% summarize( ## 延误时间的中位数 arr_delay1 = median(arr_delay), ## 正延误时间的中位数 arr_delay2 = median(arr_delay[arr_delay &gt; 0]) ) #&gt; # A tibble: 365 x 5 #&gt; # Groups: year, month [12] #&gt; year month day arr_delay1 arr_delay2 #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 3 17 #&gt; 2 2013 1 2 4 16 #&gt; 3 2013 1 3 1 16 #&gt; 4 2013 1 4 -8 16 #&gt; 5 2013 1 5 -7 11 #&gt; 6 2013 1 6 -1 15 #&gt; # … with 359 more rows 分散程度度量sd(x)、IQR(x)和mad(x) 标准差是分散程度的标准度量方式。四分位距INterquartile RangeIQR(x)和绝对中位差mad(x)基本等价，更适合有离群点的情况： ## 为什么到某些目的地距离比到其他目的地更多变？ not_cancelled %&gt;% group_by(dest) %&gt;% summarize(distance_sd = sd(distance)) %&gt;% arrange(desc(distance_sd)) #&gt; # A tibble: 104 x 2 #&gt; dest distance_sd #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 EGE 10.5 #&gt; 2 SAN 10.4 #&gt; 3 SFO 10.2 #&gt; 4 HNL 10.0 #&gt; 5 SEA 9.98 #&gt; 6 LAS 9.91 #&gt; # … with 98 more rows 秩的度量:min(x)、quantile(x,0.25)和max(x) 分位数是中位数的扩展。例如quantile(x,0.25)会找出x中按从小到大顺序大于前25%而小于后75%的值（即下四分位数） ## 每天最早和最晚的航班何时出发？ not_cancelled %&gt;% group_by(year,month,day) %&gt;% summarize(first = min(dep_time),last = max(dep_time)) #&gt; # A tibble: 365 x 5 #&gt; # Groups: year, month [12] #&gt; year month day first last #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 2356 #&gt; 2 2013 1 2 42 2354 #&gt; 3 2013 1 3 32 2349 #&gt; 4 2013 1 4 25 2358 #&gt; 5 2013 1 5 14 2357 #&gt; 6 2013 1 6 16 2355 #&gt; # … with 359 more rows 定位度量:first(x)、nth(x,n)、last(x) 这几个函数的作用与x[1]、x[n]和x[length(x)]相同，只是当定位不存在时（比如尝试从只有两个元素的分组中得到第三个元素），这些函数允许通过参数default设置一个默认值，而后者不能正常工作。 ## 找出每天排在第10的的出发时间记录 not_cancelled %&gt;% group_by(month,year,day) %&gt;% summarize(tenth_dep = nth(dep_time,10)) #&gt; # A tibble: 365 x 4 #&gt; # Groups: month, year [12] #&gt; month year day tenth_dep #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 2013 1 558 #&gt; 2 1 2013 2 554 #&gt; 3 1 2013 3 552 #&gt; 4 1 2013 4 553 #&gt; 5 1 2013 5 555 #&gt; 6 1 2013 6 558 #&gt; # … with 359 more rows 1.6.5 多个分组变量的消耗 当时用多个分组变量时，每使用一次summarize就会消耗掉一个分组变量，如group_by(year,month,day)经过一次summarize后生成的数据集默认在(year,month)上分组，这使得我们可以对数据集进行循序渐进的分析： daily &lt;- not_cancelled %&gt;% group_by(year,month,day) ## 每天有多少架航班记录 (per_day &lt;- daily %&gt;% summarize(flights = n())) #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day flights #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 831 #&gt; 2 2013 1 2 928 #&gt; 3 2013 1 3 900 #&gt; 4 2013 1 4 908 #&gt; 5 2013 1 5 717 #&gt; 6 2013 1 6 829 #&gt; # … with 359 more rows ## 每月有多少架航班记录 (per_month &lt;- per_day %&gt;% summarize(flights = sum(flights))) #&gt; # A tibble: 12 x 3 #&gt; # Groups: year [1] #&gt; year month flights #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 26398 #&gt; 2 2013 2 23611 #&gt; 3 2013 3 27902 #&gt; 4 2013 4 27564 #&gt; 5 2013 5 28128 #&gt; 6 2013 6 27075 #&gt; # … with 6 more rows ## 等价于not_cancelled %&gt;% group_by(year,month) %&gt;% summarize(flights = n()) ## 每年有多少架航班记录 (per_year &lt;- per_month %&gt;% summarize(flights = sum(flights))) #&gt; # A tibble: 1 x 2 #&gt; year flights #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 327346 ## 等价于not_cancelled %&gt;% group_by(year) %&gt;% summarize(flights = n()) 由于分组操作拥有这样的“继承性质”，有的时候可能想要取消分组，并回到未分组的数据继续操作，那么可以使用ungroup()函数取消分组： daily %&gt;% ungroup() %&gt;% summarize(flights = n()) ## 对数据集整体进行摘要统计 #&gt; # A tibble: 1 x 1 #&gt; flights #&gt; &lt;int&gt; #&gt; 1 327346 在循序渐进地进行摘要分析的时候，需要小心：使用求和与计数操作是没有问题的，但如果想要使用加权平均和方差的话，就要仔细考虑一下，任何基于秩的统计数据（如中位数，分为差）都不支持这样的操作。换句话说，对分组结果再求和就是对整体求和，但各分组中的中位数的中位数可不是整体的中位数。 1.7 group_by() 结合其他函数 虽然与summarize()函数结合起来使用是最有效的，但分组也可以和mutate()和filter()函数结合使用,以完成非常便捷的操作。 当group_by和mutate()函数结合使用时，摘要函数(summary functions，如mean,median等)将会自动以分组为基础，一些非摘要函数也会受到分组的影响，如偏移函数lead()、lag()和排秩函数min_rank()、row_number()。而普通的数字运算符+ , -、逻辑运算符&lt; , ==，对数运算log()和余数运算%/% , %%等将无视分组。 同理，当 group_by 和 filter() 结合使用时，如果用于筛选的条件是上述提到的受分组影响的函数，那么筛选的结果也依赖于分组。 ## 分组前后mutate()函数效果的对比 df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(x_mean = mean(x)) %&gt;% group_by(group) %&gt;% mutate(x_mean_2 = mean(x)) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group x_mean x_mean_2 #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 a 5 2 #&gt; 2 2 a 5 2 #&gt; 3 3 a 5 2 #&gt; 4 4 b 5 5 #&gt; 5 5 b 5 5 #&gt; 6 6 b 5 5 #&gt; # … with 3 more rows ## Arithmetic operators +, -, *, /, ^ are not affected by group_by(). df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(y = x + 2) %&gt;% group_by(group) %&gt;% mutate(z = x + 2) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group y z #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 a 3 3 #&gt; 2 2 a 4 4 #&gt; 3 3 a 5 5 #&gt; 4 4 b 6 6 #&gt; 5 5 b 7 7 #&gt; 6 6 b 8 8 #&gt; # … with 3 more rows ## The modular arithmetic operators %/% and %% are not affected by group_by() df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(y = x %% 2) %&gt;% group_by(group) %&gt;% mutate(z = x %% 2) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group y z #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 a 1 1 #&gt; 2 2 a 0 0 #&gt; 3 3 a 1 1 #&gt; 4 4 b 0 0 #&gt; 5 5 b 1 1 #&gt; 6 6 b 0 0 #&gt; # … with 3 more rows ## The logarithmic functions log(), log2(), and log10() are not affected by group_by(). df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(y = log(x)) %&gt;% group_by(group) %&gt;% mutate(z = log(x)) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group y z #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 a 0 0 #&gt; 2 2 a 0.693 0.693 #&gt; 3 3 a 1.10 1.10 #&gt; 4 4 b 1.39 1.39 #&gt; 5 5 b 1.61 1.61 #&gt; 6 6 b 1.79 1.79 #&gt; # … with 3 more rows ## The offset functions lead() and lag() respect the groupings in group_by(). The functions lag() and lead() will only return values within each group. df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(lag_x = lag(x), lead_x = lead(x)) %&gt;% group_by(group) %&gt;% mutate( lag_x_grouped = lag(x), lead_x_grouped = lead(x) ) #&gt; # A tibble: 9 x 6 #&gt; # Groups: group [3] #&gt; x group lag_x lead_x lag_x_grouped lead_x_grouped #&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 a NA 2 NA 2 #&gt; 2 2 a 1 3 1 3 #&gt; 3 3 a 2 4 2 NA #&gt; 4 4 b 3 5 NA 5 #&gt; 5 5 b 4 6 4 6 #&gt; 6 6 b 5 7 5 NA #&gt; # … with 3 more rows ## The cumulative and rolling aggregate functions cumsum(), cumprod(), cummin(), cummax(), and cummean() calculate values within each group. df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(x_cumsum = cumsum(x)) %&gt;% group_by(group) %&gt;% mutate(x_cumsum_2 = cumsum(x)) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group x_cumsum x_cumsum_2 #&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 a 1 1 #&gt; 2 2 a 3 3 #&gt; 3 3 a 6 6 #&gt; 4 4 b 10 4 #&gt; 5 5 b 15 9 #&gt; 6 6 b 21 15 #&gt; # … with 3 more rows ## Logical comparisons, &lt;, &lt;=, &gt;, &gt;=, !=, and == are not affected by group_by(). df &lt;- tibble( x = 1:9, y = 9:1, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(x_lte_y = x &lt;= y) %&gt;% group_by(group) %&gt;% mutate(x_lte_y_2 = x &lt;= y) #&gt; # A tibble: 9 x 5 #&gt; # Groups: group [3] #&gt; x y group x_lte_y x_lte_y_2 #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; #&gt; 1 1 9 a TRUE TRUE #&gt; 2 2 8 a TRUE TRUE #&gt; 3 3 7 a TRUE TRUE #&gt; 4 4 6 b TRUE TRUE #&gt; 5 5 5 b TRUE TRUE #&gt; 6 6 4 b FALSE FALSE #&gt; # … with 3 more rows ## Ranking functions like min_rank() work within each group when used with group_by(). df &lt;- tibble( x = 1:9, group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% mutate(rnk = min_rank(x)) %&gt;% group_by(group) %&gt;% mutate(rnk2 = min_rank(x)) #&gt; # A tibble: 9 x 4 #&gt; # Groups: group [3] #&gt; x group rnk rnk2 #&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 a 1 1 #&gt; 2 2 a 2 2 #&gt; 3 3 a 3 3 #&gt; 4 4 b 4 1 #&gt; 5 5 b 5 2 #&gt; 6 6 b 6 3 #&gt; # … with 3 more rows 此外,基于 arrange() 函数进行的排序一般也无视分组。不过，如果我们在 arrange() 中使用表达式作为排序依据，且这个表达式又和分组有关系，那么 arrange() 的排序结果就和是否分组有关了，不过这并不算是arrange()本身受分组影响。 ## arrange() ignores groups when sorting values. df &lt;- tibble( x = runif(9), group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% group_by(group) %&gt;% arrange(x) #&gt; # A tibble: 9 x 2 #&gt; # Groups: group [3] #&gt; x group #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 0.0562 c #&gt; 2 0.337 a #&gt; 3 0.514 b #&gt; 4 0.523 b #&gt; 5 0.525 a #&gt; 6 0.557 b #&gt; # … with 3 more rows ## 和上面的结果进行比较 df &lt;- tibble( x = runif(9), group = rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ) df %&gt;% group_by(group) %&gt;% mutate(mean = mean(x)) %&gt;% ## mean受分组影响，最后的排序结果也受分组影响 arrange(mean) #&gt; # A tibble: 9 x 3 #&gt; # Groups: group [3] #&gt; x group mean #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 0.188 a 0.493 #&gt; 2 0.725 a 0.493 #&gt; 3 0.567 a 0.493 #&gt; 4 0.888 b 0.511 #&gt; 5 0.268 b 0.511 #&gt; 6 0.378 b 0.511 #&gt; # … with 3 more rows 1.8 练习 Exercise 1.8 找到每个日期分组中到达时间延迟最长的10条记录 ## min_rank自动在分组内排序 not_cancelled %&gt;% group_by(year,month,day) %&gt;% filter(rank(desc(arr_delay)) &lt;= 10) %&gt;% select(month,year,day,arr_delay) #&gt; # A tibble: 3,609 x 4 #&gt; # Groups: year, month, day [365] #&gt; month year day arr_delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 2013 1 851 #&gt; 2 1 2013 1 338 #&gt; 3 1 2013 1 263 #&gt; 4 1 2013 1 166 #&gt; 5 1 2013 1 174 #&gt; 6 1 2013 1 222 #&gt; # … with 3,603 more rows Exercise 1.9 找出一年中到达航班多于 365 次的目的地： ## n()以分组为基础 not_cancelled %&gt;% count(dest, sort = T) %&gt;% filter(n &gt; 365) #&gt; # A tibble: 75 x 2 #&gt; dest n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 ATL 16837 #&gt; 2 ORD 16566 #&gt; 3 LAX 16026 #&gt; 4 BOS 15022 #&gt; 5 MCO 13967 #&gt; 6 CLT 13674 #&gt; # … with 69 more rows Exercise 1.10 哪一架飞机（用飞机尾号来识别，tailnum)具有最差的准点记录： 衡量一个飞机的准点情况有很多种可能的选择，这里只提供两个方向： 该航班未取消且延误（到达和出发）次数占总飞行次数的比例最小 该航班的平均到达延误时间最长 从第一个方向出发： ## 查看飞机飞行次数的分布 count_by_tail &lt;- flights %&gt;% group_by(tailnum) %&gt;% summarize(n = n()) quantile(count_by_tail$n) #&gt; 0% 25% 50% 75% 100% #&gt; 1 23 54 110 2512 flights %&gt;% filter(!is.na(tailnum)) %&gt;% mutate(on_time = !is.na(arr_time) &amp; (arr_delay &lt;= 0) &amp; (dep_delay &lt;= 0) ) %&gt;% group_by(tailnum) %&gt;% summarize(on_time = mean(on_time), n = n()) %&gt;% ## mean和逻辑值结合计算比例 filter(n &gt; 20) %&gt;% ## 避免因频次过少做出结论,选择20是因为它是飞行次数的下四分位数 filter(min_rank(on_time) == 1) ## 未取消且准点比例最低的飞机 #&gt; # A tibble: 1 x 3 #&gt; tailnum on_time n #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 N988AT 0.0541 37 接下来是第二个方向： flights %&gt;% group_by(tailnum) %&gt;% summarize(arr_delay = mean(arr_delay,na.rm = T),n = n()) %&gt;% ##注意这一步的mean中的参数 filter(n &gt; 20) %&gt;% filter(min_rank(desc(arr_delay)) == 1) #&gt; # A tibble: 1 x 3 #&gt; tailnum arr_delay n #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 N203FR 59.1 41 Exercise 1.11 如果想要尽量避免航班延误，应该在一天中的哪个时间搭乘飞机？ 对 hour 分组计算平均到达延误时间： flights %&gt;% group_by(hour) %&gt;% summarize(arr_delay = mean(arr_delay, na.rm = T)) %&gt;% arrange(arr_delay) #&gt; # A tibble: 20 x 2 #&gt; hour arr_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 7 -5.30 #&gt; 2 5 -4.80 #&gt; 3 6 -3.38 #&gt; 4 9 -1.45 #&gt; 5 8 -1.11 #&gt; 6 10 0.954 #&gt; # … with 14 more rows Exercise 1.12 计算每个目的地的到达延误总时间的分钟数，以及每条记录到每个目的地的延误时间比例 flights %&gt;% filter(arr_delay &gt; 0) %&gt;% group_by(dest) %&gt;% mutate( arr_delay_total = sum(arr_delay), ## 经过分组后，求和在组内操作 arr_delay_prop = arr_delay / arr_delay_total ) %&gt;% select( dest, tailnum, arr_delay, arr_delay_prop ) %&gt;% arrange(dest, desc(arr_delay_prop)) #&gt; # A tibble: 133,004 x 4 #&gt; # Groups: dest [103] #&gt; dest tailnum arr_delay arr_delay_prop #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ABQ N784JB 153 0.0341 #&gt; 2 ABQ N659JB 149 0.0332 #&gt; 3 ABQ N640JB 138 0.0308 #&gt; 4 ABQ N589JB 137 0.0305 #&gt; 5 ABQ N556JB 136 0.0303 #&gt; 6 ABQ N598JB 126 0.0281 #&gt; # … with 1.33e+05 more rows Exercise 1.13 延误通常是由临时原因造成的：即使最初引起延误的问题已经解决，但因为要让前面的航班先起飞，所以后面的航班也会延误。使用lag() 探究一架航班延误与前一架航班延误之间的关系。 ## This calculates the departure delay of the preceding flight from the same airport. (lagged_delays &lt;- flights %&gt;% arrange(origin, month, day, dep_time) %&gt;% ## 这一步排序确保了偏移是有意义的 group_by(origin) %&gt;% mutate(dep_delay_lag = lag(dep_delay)) %&gt;% ## 偏移函数基于分组 filter(!is.na(dep_delay),!is.na(dep_delay_lag))) #&gt; # A tibble: 327,649 x 20 #&gt; # Groups: origin [3] #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 554 558 -4 740 728 #&gt; 2 2013 1 1 555 600 -5 913 854 #&gt; 3 2013 1 1 558 600 -2 923 937 #&gt; 4 2013 1 1 559 600 -1 854 902 #&gt; 5 2013 1 1 601 600 1 844 850 #&gt; 6 2013 1 1 606 610 -4 858 910 #&gt; # … with 3.276e+05 more rows, and 12 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, #&gt; # dep_delay_lag &lt;dbl&gt; lagged_delays %&gt;% group_by(dep_delay_lag) %&gt;% summarise(dep_delay_mean = mean(dep_delay)) %&gt;% ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) + geom_point() + scale_x_continuous(breaks = seq(0, 1500, by = 120)) + labs(y = &quot;Departure Delay&quot;, x = &quot;Previous Departure Delay&quot;) + theme_classic() ## This plots the relationship between the mean delay of a flight for all values of the previous flight. For delays less than two hours, the relationship between the delay of the preceding flight and the current flight is nearly a line. After that the relationship becomes more variable, as long-delayed flights are interspersed with flights leaving on-time. After about 8-hours, a delayed flight is likely to be followed by a flight leaving on time. Exercise 1.14 根据到达地点的数量，对航空公司进行排序 ; 找出至少有两个航空公司的目的地 ## rank carriers by numer of destinations flights %&gt;% group_by(carrier) %&gt;% summarize(n_dest = n_distinct(dest)) %&gt;% arrange(desc(n_dest)) #&gt; # A tibble: 16 x 2 #&gt; carrier n_dest #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 EV 61 #&gt; 2 9E 49 #&gt; 3 UA 47 #&gt; 4 B6 42 #&gt; 5 DL 40 #&gt; 6 MQ 20 #&gt; # … with 10 more rows ## find all airports with &gt; 1 carrier flights %&gt;% group_by(dest) %&gt;% summarize(n_carriers = n_distinct(carrier)) %&gt;% filter(n_carriers &gt; 1) #&gt; # A tibble: 76 x 2 #&gt; dest n_carriers #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 ATL 7 #&gt; 2 AUS 6 #&gt; 3 AVL 2 #&gt; 4 BDL 2 #&gt; 5 BGR 2 #&gt; 6 BNA 5 #&gt; # … with 70 more rows Exercise 1.15 每天取消的航班数量和总航班数量存在什么关系？每天的平均到达延误时间和取消航班的比例有什么关系？ 取消的航班定义为is.na(arr_delay) | is.na(dep_delay) ## One pattern in cancelled flights per day is that ## the number of cancelled flights increases with the total number of flights per day. flights %&gt;% group_by(year,month,day) %&gt;% summarize(n_cancelled = sum(is.na(arr_delay) | is.na(dep_delay)),n_total = n()) %&gt;% ggplot(aes(x = n_total,y = n_cancelled)) + geom_point() #2 flights %&gt;% group_by(year,month,day) %&gt;% summarize(cancelled_prop = mean(is.na(arr_delay) | is.na(dep_delay)), avg_arr_delay = mean(arr_delay,na.rm = T)) %&gt;% ggplot() + geom_point(aes(x = avg_arr_delay,y = cancelled_prop)) Exercise 1.16 哪个航空公司的延误情况最严重？你能否分清这是因为糟糕的机场设备，还是航空公司的问题？（考虑一下flights %&gt;% group_by(carrier,dest) %&gt;% summarize(n()) flights %&gt;% group_by(carrier) %&gt;% summarize(avg_arr_delay = mean(arr_delay,na.rm = T)) %&gt;% arrange(desc(avg_arr_delay)) #&gt; # A tibble: 16 x 2 #&gt; carrier avg_arr_delay #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 F9 21.9 #&gt; 2 FL 20.1 #&gt; 3 EV 15.8 #&gt; 4 YV 15.6 #&gt; 5 OO 11.9 #&gt; 6 MQ 10.8 #&gt; # … with 10 more rows ## What airline corresponds to the &quot;F9&quot; carrier code? filter(airlines,carrier == &quot;F9&quot;) #&gt; # A tibble: 1 x 2 #&gt; carrier name #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 F9 Frontier Airlines Inc. You can get part of the way to disentangling the effects of airports versus bad carriers by comparing the average delay of each carrier to the average delay of flights within a route (flights from the same origin to the same destination). Comparing delays between carriers and within each route disentangles the effect of carriers and airports. A better analysis would compare the average delay of a carrier’s flights to the average delay of all other carrier’s flights within a route. flights %&gt;% filter(!is.na(arr_delay)) %&gt;% # Total delay by carrier within each origin, dest group_by(origin, dest, carrier) %&gt;% summarise( arr_delay = sum(arr_delay), flights = n() ) %&gt;% # Total delay within each origin dest group_by(origin, dest) %&gt;% mutate( arr_delay_total = sum(arr_delay), flights_total = sum(flights) ) %&gt;% # average delay of each carrier - average delay of other carriers ungroup() %&gt;% mutate( arr_delay_others = (arr_delay_total - arr_delay) / (flights_total - flights), arr_delay_mean = arr_delay / flights, arr_delay_diff = arr_delay_mean - arr_delay_others ) %&gt;% # remove NaN values (when there is only one carrier) filter(is.finite(arr_delay_diff)) %&gt;% # average over all airports it flies to group_by(carrier) %&gt;% summarise(arr_delay_diff = mean(arr_delay_diff)) %&gt;% arrange(desc(arr_delay_diff)) #&gt; # A tibble: 15 x 2 #&gt; carrier arr_delay_diff #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 OO 27.3 #&gt; 2 F9 17.3 #&gt; 3 EV 11.0 #&gt; 4 B6 6.41 #&gt; 5 FL 2.57 #&gt; 6 VX -0.202 #&gt; # … with 9 more rows 1.9 作用域 这里的作用域是指 dplyr 函数能影响的变量范围。一般而言，arrange()、mutate()、summarize() 作用的变量需要显式指明，而它们的一些变体 (scoped variants) 有更加复杂的作用域规则。 Scoped variants of a function operates on a selection of variables. The variants suffixed with _if, _at or _all apply an expression (sometimes several) to all variables within a specified subset. This subset can contain all variables (_all variants), a vars() selection (_at variants), or variables selected with a predicate (_if variants). https://dplyr.tidyverse.org/reference/mutate_all.html https://dplyr.tidyverse.org/reference/summarise_all.html https://dplyr.tidyverse.org/reference/filter_all.html library(tidyverse) 1.9.1 arrange() 1.9.2 mutate() The scoped variants of mutate() and transmute() make it easy to apply the same transformation to multiple variables. There are three variants: _all affects every variable _at affects variables selected with a character vector or vars() _if affects variables selected with a predicate function mutate_all(.tbl, .funs, ...) mutate_if(.tbl, .predicate, .funs, ...) mutate_at(.tbl, .vars, .funs, ..., .cols = NULL) transmute_all(.tbl, .funs, ...) transmute_if(.tbl, .predicate, .funs, ...) transmute_at(.tbl, .vars, .funs, ..., .cols = NULL) Arguments tbl: A tbl object .funs: a function to transform the selection of variables ...: Additional arguments for the function calls in .funs .predicate: _if 变体进行逻辑判断的函数 _all() 影响所有变量： df &lt;- tibble(x = c(10, 100, NA), y = c(1000, NA, 10000)) df %&gt;% mutate_all(log10) #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 3 #&gt; 2 2 NA #&gt; 3 NA 4 所有 scoped variants 都可以传入任何函数及其参数： scale2 &lt;- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm) df %&gt;% mutate_all(scale2, na.rm = T) #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.707 -0.707 #&gt; 2 0.707 NA #&gt; 3 NA 0.707 _at 变体作用于变量的某个子集，可以用一个字符向量指定，也可以使用 使用select()选择列 中的帮助函数，但这些帮助函数必须包裹在 vars() 之内，可以把 vars() 看作是 scoped variants 内部的 select() starwars %&gt;% mutate_at(c(&quot;height&quot;, &quot;mass&quot;), scale2, na.rm = T) #&gt; # A tibble: 87 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Luke… -0.0678 -0.120 blond fair blue 19 male #&gt; 2 C-3PO -0.212 -0.132 &lt;NA&gt; gold yellow 112 &lt;NA&gt; #&gt; 3 R2-D2 -2.25 -0.385 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; #&gt; 4 Dart… 0.795 0.228 none white yellow 41.9 male #&gt; 5 Leia… -0.701 -0.285 brown light brown 19 female #&gt; 6 Owen… 0.105 0.134 brown, gr… light blue 52 male #&gt; # … with 81 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, #&gt; # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; # You can also supply selection helpers to _at() functions but you have # to quote them with vars(): iris &lt;- as_tibble(iris) iris %&gt;% mutate_at(vars(matches(&quot;Sepal&quot;)), scale2) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 -0.898 1.02 1.4 0.2 setosa #&gt; 2 -1.14 -0.132 1.4 0.2 setosa #&gt; 3 -1.38 0.327 1.3 0.2 setosa #&gt; 4 -1.50 0.0979 1.5 0.2 setosa #&gt; 5 -1.02 1.25 1.4 0.2 setosa #&gt; 6 -0.535 1.93 1.7 0.4 setosa #&gt; # … with 144 more rows iris %&gt;% mutate_at(vars(contains(&quot;Length&quot;)), scale2) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 -0.898 3.5 -1.34 0.2 setosa #&gt; 2 -1.14 3 -1.34 0.2 setosa #&gt; 3 -1.38 3.2 -1.39 0.2 setosa #&gt; 4 -1.50 3.1 -1.28 0.2 setosa #&gt; 5 -1.02 3.6 -1.34 0.2 setosa #&gt; 6 -0.535 3.9 -1.17 0.4 setosa #&gt; # … with 144 more rows _if 变体作用于 predicate function 返回的逻辑值为真的变量，注意这个参数的位置： # The _if() variants apply a predicate function (a function that # returns TRUE or FALSE) to determine the relevant subset of # columns. Here we divide all the numeric columns by 100: starwars %&gt;% mutate_if(is.numeric, scale2, na.rm = TRUE) #&gt; # A tibble: 87 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Luke… -0.0678 -0.120 blond fair blue -0.443 male #&gt; 2 C-3PO -0.212 -0.132 &lt;NA&gt; gold yellow 0.158 &lt;NA&gt; #&gt; 3 R2-D2 -2.25 -0.385 &lt;NA&gt; white, bl… red -0.353 &lt;NA&gt; #&gt; 4 Dart… 0.795 0.228 none white yellow -0.295 male #&gt; 5 Leia… -0.701 -0.285 brown light brown -0.443 female #&gt; 6 Owen… 0.105 0.134 brown, gr… light blue -0.230 male #&gt; # … with 81 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, #&gt; # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; 当需要转换某些变量的类型时，mutate_if 会很方便： ## 解决 data.frame 的强制转换 iris %&gt;% mutate_if(is.factor, as.character) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; # … with 144 more rows ## 双精度转换为整型 iris %&gt;% mutate_if(is.double, as.integer) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; #&gt; 1 5 3 1 0 setosa #&gt; 2 4 3 1 0 setosa #&gt; 3 4 3 1 0 setosa #&gt; 4 4 3 1 0 setosa #&gt; 5 5 3 1 0 setosa #&gt; 6 5 3 1 0 setosa #&gt; # … with 144 more rows 某些情况下，可能希望进行多种数据函数，可以在 ,funs 中传入一个函数列表，则列表中的每个函数均会作用于所有符合筛选条件的变量。有多个函数时，mutate 的 scoped vairiants 生成新列，而非就地修改原来的变量 iris %&gt;% mutate_if(is.numeric, list(scale2, log)) %&gt;% select(-(1:5)) #&gt; # A tibble: 150 x 8 #&gt; Sepal.Length_fn1 Sepal.Width_fn1 Petal.Length_fn1 Petal.Width_fn1 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.898 1.02 -1.34 -1.31 #&gt; 2 -1.14 -0.132 -1.34 -1.31 #&gt; 3 -1.38 0.327 -1.39 -1.31 #&gt; 4 -1.50 0.0979 -1.28 -1.31 #&gt; 5 -1.02 1.25 -1.34 -1.31 #&gt; 6 -0.535 1.93 -1.17 -1.05 #&gt; # … with 144 more rows, and 4 more variables: Sepal.Length_fn2 &lt;dbl&gt;, #&gt; # Sepal.Width_fn2 &lt;dbl&gt;, Petal.Length_fn2 &lt;dbl&gt;, Petal.Width_fn2 &lt;dbl&gt; 通过具名列表，可以控制生成的新列的名称： iris %&gt;% mutate_if(is.numeric, list(scale = scale2, log = log)) %&gt;% select(-(1:5)) #&gt; # A tibble: 150 x 8 #&gt; Sepal.Length_sc… Sepal.Width_sca… Petal.Length_sc… Petal.Width_sca… #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.898 1.02 -1.34 -1.31 #&gt; 2 -1.14 -0.132 -1.34 -1.31 #&gt; 3 -1.38 0.327 -1.39 -1.31 #&gt; 4 -1.50 0.0979 -1.28 -1.31 #&gt; 5 -1.02 1.25 -1.34 -1.31 #&gt; 6 -0.535 1.93 -1.17 -1.05 #&gt; # … with 144 more rows, and 4 more variables: Sepal.Length_log &lt;dbl&gt;, #&gt; # Sepal.Width_log &lt;dbl&gt;, Petal.Length_log &lt;dbl&gt;, Petal.Width_log &lt;dbl&gt; 若列表中只有一个函数，scoped variants 还是会就地修改原变量，传入具名列表可以避免这一点： # When there&#39;s only one function in the list, it modifies existing # variables in place. Give it a name to instead create new variables: iris %&gt;% mutate_if(is.numeric, list(scale2)) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 -0.898 1.02 -1.34 -1.31 setosa #&gt; 2 -1.14 -0.132 -1.34 -1.31 setosa #&gt; 3 -1.38 0.327 -1.39 -1.31 setosa #&gt; 4 -1.50 0.0979 -1.28 -1.31 setosa #&gt; 5 -1.02 1.25 -1.34 -1.31 setosa #&gt; 6 -0.535 1.93 -1.17 -1.05 setosa #&gt; # … with 144 more rows iris %&gt;% mutate_if(is.numeric, list(scale = scale2)) #&gt; # A tibble: 150 x 9 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Length_sc… #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa -0.898 #&gt; 2 4.9 3 1.4 0.2 setosa -1.14 #&gt; 3 4.7 3.2 1.3 0.2 setosa -1.38 #&gt; 4 4.6 3.1 1.5 0.2 setosa -1.50 #&gt; 5 5 3.6 1.4 0.2 setosa -1.02 #&gt; 6 5.4 3.9 1.7 0.4 setosa -0.535 #&gt; # … with 144 more rows, and 3 more variables: Sepal.Width_scale &lt;dbl&gt;, #&gt; # Petal.Length_scale &lt;dbl&gt;, Petal.Width_scale &lt;dbl&gt; 1.9.3 summarize() 1.9.4 dance summarize_() 不能对某些列执行一个action，另一些列执行另一个action，必须同时执行: iris %&gt;% group_by(Species) %&gt;% summarize_at(vars(Petal.Length, Petal.Width), list(mean = mean, median = median)) #&gt; # A tibble: 3 x 5 #&gt; Species Petal.Length_mean Petal.Width_mean Petal.Length_med… Petal.Width_med… #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 setosa 1.46 0.246 1.5 0.2 #&gt; 2 versico… 4.26 1.33 4.35 1.3 #&gt; 3 virgini… 5.55 2.03 5.55 2 # devtools::install_github(&quot;romainfrancois/dance&quot;) library(dance) iris %&gt;% group_by(Species) %&gt;% tango( swing(mean, starts_with(&quot;Petal&quot;)), swing(median, starts_with(&quot;Sepal&quot;)) ) #&gt; # A tibble: 3 x 5 #&gt; Species Petal.Length Petal.Width Sepal.Length Sepal.Width #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 setosa 1.46 0.246 5 3.4 #&gt; 2 versicolor 4.26 1.33 5.9 2.8 #&gt; 3 virginica 5.55 2.03 6.5 3 tidyverse 之外，12 中介绍的以 data.table 为中心的数据整理方法也值得一看↩ "],
["tibble.html", "2 tibble 2.1 简介 2.2 对比 tibble 和 data.frame 2.3 练习", " 2 tibble tidyverse 的设计理念之一是用 tibble 代替传统的 R 数据框(data.frame类)。tibble 是一种更简单的数据框，它对传统数据框的功能进行了一些修改，以便更易于使用。多数情况下，我们不再区分 tibble 和数据框这两个词 ； 如果想要强调 R 内置的传统数据框，用 data. frame 来表示。除了这里展示的知识以外，使用 vignette(\"tibble\") 可以获得更多关于 tibble 的信息。 2.1 简介 之前介绍的所有函数几乎都将返回一个tibble，filter()、arrange()、select()、mutate()、summarize()等函数最后的结果都是一个tibble，因为它是tidyverse最底层的功能之一。由于多数其他R包使用的是标准数据框，因此经常需要将data.frame转换为tibble，可以使用as_tibble()函数来完成转换： ## iris数据集是一个data.frame class(iris) #&gt; [1] &quot;data.frame&quot; ## 转换为tibble (iris_tibble &lt;- as_tibble(iris)) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; # … with 144 more rows 相比于 data.frame() 函数，tibble()函数的功能要少的多：它不能改变输入的类型（例如，不能将字符串转变为因子)、变量的名称,也不能创建行名称。 有些比较旧的函数不支持tibble，如果遇到这种函数，可以使用as.data.frame()转换到data.frame`上。 2.2 对比 tibble 和 data.frame tibble 和传统 data.frame 的机理主要有三处不同：创建、打印和取子集。 2.2.1 创建 tibble()函数用于创建现代数据框：tibble ： df &lt;- tibble( x = 1:3, y = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;) ) df #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 a #&gt; 2 2 b #&gt; 3 3 c 可以发现 tibble() 不会自作聪明地更改 y 的 class 属性，它将原原本本地被当做一个字符向量处理。 而 data.frame() 函数用于创建一个传统数据框： df &lt;- data.frame( x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) str(df) #&gt; &#39;data.frame&#39;: 3 obs. of 2 variables: #&gt; $ x: int 1 2 3 #&gt; $ y: Factor w/ 3 levels &quot;a&quot;,&quot;b&quot;,&quot;c&quot;: 1 2 3 2.2.1.1 强制转换 在 data.frame 中，为了防止 y 被强制转换为因子，必须设置 stringAsFactors = FALSE df &lt;- data.frame( x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), stringsAsFactors = F ) str(df) #&gt; &#39;data.frame&#39;: 3 obs. of 2 variables: #&gt; $ x: int 1 2 3 #&gt; $ y: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; By the way, 创建tibble的另一种方法是使用tribble()函数，tribble是 transposed tibble 的缩写。tribble()是高度定制化的，就像在 Markdown 中创建表格一样，一个一个填入元素：列标题以波浪线~开头，不同列的元素之间以逗号分隔，这样就可以用易读的方式对少量数据创建一个 tibble 类型： tribble( ~x, ~y, ~z, &quot;a&quot;, 1, 2, &quot;b&quot;, 1, 8.5 ) #&gt; # A tibble: 2 x 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 1 2 #&gt; 2 b 1 8.5 2.2.1.2 行标签 data.frame 支持提供一个不包含重复元素的字符向量给每行打上标签： df &lt;- data.frame( age = c(35, 27, 18), hair = c(&quot;blond&quot;, &quot;brown&quot;, &quot;black&quot;), row.names = c(&quot;Bob&quot;, &quot;Susan&quot;, &quot;Sam&quot;) ) df #&gt; age hair #&gt; Bob 35 blond #&gt; Susan 27 brown #&gt; Sam 18 black attributes(df) #&gt; $names #&gt; [1] &quot;age&quot; &quot;hair&quot; #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; #&gt; #&gt; $row.names #&gt; [1] &quot;Bob&quot; &quot;Susan&quot; &quot;Sam&quot; row.names参数为data.frame创建了一个同名的属性，rownames()函数可以提取这个属性： rownames(df) #&gt; [1] &quot;Bob&quot; &quot;Susan&quot; &quot;Sam&quot; 如果我们认为数据框是二维矩阵的自然拓展(不止包含数值)，那么行标签的存在似乎是很自然的，毕竟矩阵有i、j两个索引。但是矩阵和数据框有本质区别，矩阵是添加了维度属性的原子向量，数据框则是列表，我们可以对矩阵取转置，因为它们的行和列可以互换，一个矩阵的转置是另一个矩阵。数据框则是不可转置的，它的行列互换之后就不再是数据框(一行未必能构成一个原子向量)。 出于以下三个原因，我们不应该使用row.names这一属性，也不应该考虑在任何场合添加行标签： 元数据也是数据，所以把行标签从其他变量中抽出来单独对待不是个好主意。否则我们可能要对行标签单独发展出一套操作工具，而不能直接应用我们已经习惯的对变量的操作方法 行标签很多时候不能完成唯一标识观测的任务，因为row.names要求只能传入数值或者字符串向量。如果我们想要用时间日期型数据标识观测呢？或者需要传入不止一个向量(例如标识位置同时需要经度和纬度) 行标签中的元素必须是唯一的，但很多场合(比如bootstrapping)中同一个对象也可能有多条记录 所以，tibble的设计思想就是不支持添加行标签，且提供了一套很方便的、处理已有行标签的工具，要么移除它，要么把它直接变成tibble中的一列： Tools for working with row names Description While a tibble can have row names (e.g., when converting from a regular data frame), they are removed when subsetting with the [ operator. A warning will be raised when attempting to assign non-NULL row names to a tibble. Generally, it is best to avoid row names, because they are basically a character column with different semantics to every other column. These functions allow to you detect if a data frame has row names (has_rownames()), remove them (remove_rownames()), or convert them back-and-forth between an explicit column (rownames_to_column() and column_to_rownames()). Also included is rowid_to_column() which adds a column at the start of the dataframe of ascending sequential row ids starting at 1. Note that this will remove any existing row names. Usage has_rownames(.data) remove_rownames(.data) rownames_to_column(.data, var = \"rowname\") rowid_to_column(.data, var = \"rowid\") column_to_rownames(.data, var = \"rowname\") Arguments .data A data frame. var Name of column to use for rownames. Value column_to_rownames() always returns a data frame. has_rownames() returns a scalar logical. All other functions return an object of the same class as the input. 一些示例： mtcars %&gt;% has_rownames() #&gt; [1] TRUE mtcars %&gt;% remove_rownames() #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; 5 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; 9 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; 11 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; 12 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; 13 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; 14 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; 15 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; 16 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; 17 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; 18 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; 19 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; 20 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; 21 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; 22 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; 23 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; 24 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; 25 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; 26 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; 27 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; 28 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; 29 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; 30 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; 31 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; 32 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 mtcars %&gt;% rownames_to_column(var = &quot;car_type&quot;) #&gt; car_type mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; 5 Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; 9 Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; 11 Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; 12 Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; 13 Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; 14 Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; 15 Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; 16 Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; 17 Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; 18 Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; 19 Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; 20 Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; 21 Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; 22 Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; 23 AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; 24 Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; 25 Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; 26 Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; 27 Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; 28 Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; 29 Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; 30 Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; 31 Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; 32 Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 mtcars %&gt;% rowid_to_column() #&gt; rowid mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 1 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; 2 2 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; 3 3 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 4 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; 5 5 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 6 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; 7 7 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; 8 8 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; 9 9 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; 10 10 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; 11 11 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; 12 12 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; 13 13 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; 14 14 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; 15 15 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; 16 16 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; 17 17 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; 18 18 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; 19 19 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; 20 20 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; 21 21 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; 22 22 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; 23 23 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; 24 24 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; 25 25 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; 26 26 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; 27 27 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; 28 28 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; 29 29 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; 30 30 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; 31 31 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; 32 32 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 2.2.1.3 循环 tibble()会循环使用那些长度为1的列，将其自动扩展到最长的列的长度。而长度不为1，且和其他列元素个数不同的列不会被循环 ； data.frame()会自动循环长度可被最长一列的长度整除的列： tibble(x = 1:4, y = 1) #&gt; # A tibble: 4 x 2 #&gt; x y #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 1 #&gt; 2 2 1 #&gt; 3 3 1 #&gt; 4 4 1 tibble(x = 1:4, y = 1:2) #&gt; Error: Tibble columns must have consistent lengths, only values of length one are recycled: #&gt; * Length 2: Column `y` #&gt; * Length 4: Column `x` data.frame(x = 1:4, y = 1:2) #&gt; x y #&gt; 1 1 1 #&gt; 2 2 2 #&gt; 3 3 1 #&gt; 4 4 2 data.frame(x = 1:4, y = 1:3) #&gt; Error in data.frame(x = 1:4, y = 1:3): arguments imply differing number of rows: 4, 3 2.2.1.4 无效变量名称 tibble的一个很大特色是可以使用在R中无效的变量名称，即不符合变量命名规定的名称可以在tibble中成为列名，实际上这个规则约束了R中所有“名称”的设定。R规定名称只能包含字母、数字、点.和下划线_，必须以字母开头，数字不能跟在.之后，也不能和R中保留的关键字重名(see ?Reserved)。 如果想创建不合法的列名，可以用反引号```将它们括起来： tb &lt;- tibble( `:)` = &quot;smile&quot;, ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) tb #&gt; # A tibble: 1 x 3 #&gt; `:)` ` ` `2000` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 smile space number 类似地，如果想要在 ggolot2 或者其他tidyverse包中使用这些名称特殊的变量，也需要用反引号括起来。 相比之下，data.frame()会依据make.names()的规则自行更改无效的列名称(除非设置check.names = FALSE)。如果你的名称不以字母开头(字母的界定依据当前电脑的地域设置，但不能超越ASCII字符集)，这个函数会地添加X作为前缀；如果包含特殊字符，用.代替；未给出的名称用NA代替；与R的保留关键字重名的，在后面添加.: names(data.frame(`1` = 1)) #&gt; [1] &quot;X1&quot; names(data.frame(`1` = 1,check.names = F)) #&gt; [1] &quot;1&quot; 2.2.1.5 变量引用 最后，我们可以在创建tibble创建过程中就引用其中的变量，因为变量在tibble中是被从左到右依次添加的(而data.frame()不支持这一点)： tibble( x = 1:3, y = x * 2 ) #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 2 #&gt; 2 2 4 #&gt; 3 3 6 2.2.2 打印 tibble 的打印方法进行了优化，只显示前 10 行结果，显示列的数目将自动适应屏幕的宽度，这种打印方式非常适合大数据集。除了打印列名，tibble 还会第一行的下面打印出列的类型，这项功能有些类似于 str() 函数 tibble( a = lubridate::now() + runif(1e3) * 96400, b = lubridate::today() + runif(1e3) * 30, c = 1:1e3, d = runif(1e3), e = sample(letters,1e3, replace = T) ) #&gt; # A tibble: 1,000 x 5 #&gt; a b c d e #&gt; &lt;dttm&gt; &lt;date&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2019-12-12 21:49:54 2019-12-14 1 0.392 i #&gt; 2 2019-12-12 14:53:28 2019-12-16 2 0.409 p #&gt; 3 2019-12-12 09:50:02 2019-12-27 3 0.944 t #&gt; 4 2019-12-12 14:34:31 2020-01-05 4 0.614 z #&gt; 5 2019-12-12 14:49:10 2019-12-28 5 0.672 f #&gt; 6 2019-12-12 15:43:59 2019-12-22 6 0.113 q #&gt; # … with 994 more rows 在打印大数据框时，tibble的这种设计避免了输出一下子占据控制台的很多行。 有时需要比默认显示更多的输出，这是要设置几个参数。 首先，可以明确使用print()函数来打印数据框（实际上是print.tbl())，并控制打印的行数（n）和显示的宽度（width）。width = Inf可以显示出所有列: nycflights13::flights %&gt;% print(n = 10, width = Inf) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; arr_delay carrier flight tailnum origin dest air_time distance hour minute #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 11 UA 1545 N14228 EWR IAH 227 1400 5 15 #&gt; 2 20 UA 1714 N24211 LGA IAH 227 1416 5 29 #&gt; 3 33 AA 1141 N619AA JFK MIA 160 1089 5 40 #&gt; 4 -18 B6 725 N804JB JFK BQN 183 1576 5 45 #&gt; 5 -25 DL 461 N668DN LGA ATL 116 762 6 0 #&gt; 6 12 UA 1696 N39463 EWR ORD 150 719 5 58 #&gt; 7 19 B6 507 N516JB EWR FLL 158 1065 6 0 #&gt; 8 -14 EV 5708 N829AS LGA IAD 53 229 6 0 #&gt; 9 -8 B6 79 N593JB JFK MCO 140 944 6 0 #&gt; 10 8 AA 301 N3ALAA LGA ORD 138 733 6 0 #&gt; time_hour #&gt; &lt;dttm&gt; #&gt; 1 2013-01-01 05:00:00 #&gt; 2 2013-01-01 05:00:00 #&gt; 3 2013-01-01 05:00:00 #&gt; 4 2013-01-01 05:00:00 #&gt; 5 2013-01-01 06:00:00 #&gt; 6 2013-01-01 05:00:00 #&gt; 7 2013-01-01 06:00:00 #&gt; 8 2013-01-01 06:00:00 #&gt; 9 2013-01-01 06:00:00 #&gt; 10 2013-01-01 06:00:00 #&gt; # … with 3.368e+05 more rows 2.2.3 取子集 取子集(Subsetting)时的行为又是区分data.frame和tibble很重要的一个特性。简单来讲，R中有两种取子集的系统。一种是用[在原子向量、列表、矩阵、数组和数据框中提取任意数量的元素，一种是用[[或者$在以上对象中提取单个元素。 对于传统的数据框data.frame在这两种方式上均有缺陷： 当想用df[, vars]在data.frame中提取变量时，如果vars包含多个变量，则返回一个数据框；如果vars只包含一个变量，则返回一个向量(因为[不要求必须提取多于一个元素)。这种不一致性有时这会导致很多bug，因为很多函数不能作用于向量。 df &lt;- data.frame( x = rnorm(10), y = rnorm(10), z = rnorm(10) ) ## 向量 df[,&quot;x&quot;] #&gt; [1] -1.5723 0.8783 -0.0461 -0.0778 0.1201 0.7874 -0.7307 -0.3133 -0.6744 #&gt; [10] -0.9759 ## 数据框 df[,c(&quot;x&quot;,&quot;y&quot;)] #&gt; x y #&gt; 1 -1.5723 1.442 #&gt; 2 0.8783 -0.738 #&gt; 3 -0.0461 -0.280 #&gt; 4 -0.0778 0.451 #&gt; 5 0.1201 1.437 #&gt; 6 0.7874 1.531 #&gt; 7 -0.7307 0.728 #&gt; 8 -0.3133 0.018 #&gt; 9 -0.6744 -0.108 #&gt; 10 -0.9759 1.533 ## drop = FALSE始终返回数据框 df[,&quot;x&quot;, drop = FALSE] #&gt; x #&gt; 1 -1.5723 #&gt; 2 0.8783 #&gt; 3 -0.0461 #&gt; 4 -0.0778 #&gt; 5 0.1201 #&gt; 6 0.7874 #&gt; 7 -0.7307 #&gt; 8 -0.3133 #&gt; 9 -0.6744 #&gt; 10 -0.9759 当想用df$x提取出变量x时，如果x不在data.frame中，data.frame会返回一个名字以x开始的变量(这种行为被称为部分匹配(partial matching))，如果不存在这样的变量，则返回NULL。这使得我们很容易选取到错误的变量 tibble 在这两点缺陷上做了改进。首先，当 df[, vars]作用于tibble 时，无论 vars 包含多少个变量，返回值总是一个tibble: df &lt;- tibble( x = runif(5), y = rnorm(5) ) df[, c(&quot;x&quot;,&quot;y&quot;)] #&gt; # A tibble: 5 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.548 0.281 #&gt; 2 0.804 -0.272 #&gt; 3 0.837 0.388 #&gt; 4 0.930 1.79 #&gt; 5 0.785 -0.308 df[, &quot;x&quot;] #&gt; # A tibble: 5 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 0.548 #&gt; 2 0.804 #&gt; 3 0.837 #&gt; 4 0.930 #&gt; 5 0.785 其次，使用$或者[[]]时,tibble不会进行部分匹配，如果该变量不存在，直接报错： df_1 &lt;- data.frame(xyz = 1) df_2 &lt;- tibble(xyz = 1) df_1$xy #&gt; [1] 1 df_2$xy #&gt; NULL 另外，[[可以按名称和位置提取变量，$只能按名称提取变量，但可以减少一些输入： ## 按名称提取 df$x #&gt; [1] 0.548 0.804 0.837 0.930 0.785 df[[&quot;x&quot;]] #&gt; [1] 0.548 0.804 0.837 0.930 0.785 ## 按位置提取 df[[1]] ## 提取第一列 #&gt; [1] 0.548 0.804 0.837 0.930 0.785 如果想在管道中使用这些取子集操作，需要使用特殊的占位符 . df %&gt;% .[, &quot;x&quot;] #&gt; # A tibble: 5 x 1 #&gt; x #&gt; &lt;dbl&gt; #&gt; 1 0.548 #&gt; 2 0.804 #&gt; 3 0.837 #&gt; 4 0.930 #&gt; 5 0.785 df %&gt;% .$x #&gt; [1] 0.548 0.804 0.837 0.930 0.785 df %&gt;% .[[&quot;x&quot;]] #&gt; [1] 0.548 0.804 0.837 0.930 0.785 2.3 练习 Exercise 2.1 如何识别一个数据框是否为tibble？ 可以直接根据打印时的显示来判断。 更一般地，直接使用 class() 函数进行判断, 一个传统数据框将返回“data.frame” ，而tibble返回c(\"tbl_df\", \"tbl\", \"data.frame\") class(mtcars) #&gt; [1] &quot;data.frame&quot; class(ggplot2::diamonds) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(nycflights13::flights) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Exercise 2.2 在以下的数据框中练习如何引用不符合语法规则的变量名 annoying &lt;- tibble( `1` = 1:10, `2` = `1`*2 + rnorm(length(`1`)) ) ## 提取名称为1的变量（不可以用annoying[[`1`]]） annoying$`1` #&gt; [1] 1 2 3 4 5 6 7 8 9 10 ## 绘制表示变量1和变量2关系的散点图 ggplot(annoying,mapping = aes(x = `1`, y = `2`)) + geom_point() + geom_smooth(method = &quot;lm&quot;,se = F) ## 创建一个名称为3的新列，其值为列2除以列1 mutate(annoying,`3`= `2`/`1`) #&gt; # A tibble: 10 x 3 #&gt; `1` `2` `3` #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2.17 2.17 #&gt; 2 2 3.85 1.93 #&gt; 3 3 5.58 1.86 #&gt; 4 4 7.20 1.80 #&gt; 5 5 9.12 1.82 #&gt; 6 6 12.1 2.02 #&gt; # … with 4 more rows ## 将前两列重新命名为one、two (annoying &lt;- rename(annoying,one = `1`, two = `2`)) #&gt; # A tibble: 10 x 2 #&gt; one two #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 2.17 #&gt; 2 2 3.85 #&gt; 3 3 5.58 #&gt; 4 4 7.20 #&gt; 5 5 9.12 #&gt; 6 6 12.1 #&gt; # … with 4 more rows Exercise 2.3 tibble::enframe()函数的功能是什么？什么时候可以使用这个函数？ enframe()接受一个具名向量(named vectors)转换为一个tibble： enframe(c(a = 5, b = 7)) #&gt; # A tibble: 2 x 2 #&gt; name value #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 a 5 #&gt; 2 b 7 enframe(c(a = 1:3, b = 2:4, c = 3:5)) #&gt; # A tibble: 9 x 2 #&gt; name value #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 a1 1 #&gt; 2 a2 2 #&gt; 3 a3 3 #&gt; 4 b1 2 #&gt; 5 b2 3 #&gt; 6 b3 4 #&gt; # … with 3 more rows tibble() 在这种情况下只会识别一个完整的向量 tibble(c(a = 1:3, b = 2:4, c = 3:5)) #&gt; # A tibble: 9 x 1 #&gt; `c(a = 1:3, b = 2:4, c = 3:5)` #&gt; &lt;int&gt; #&gt; 1 1 #&gt; 2 2 #&gt; 3 3 #&gt; 4 2 #&gt; 5 3 #&gt; 6 4 #&gt; # … with 3 more rows "],
["readr.html", "3 readr 3.1 base R 中的数据读取 3.2 readr 简介 3.3 解析向量(Parsing a vector) 3.4 解析文件 3.5 readxl", " 3 readr 3.1 base R 中的数据读取 base R中有 3 个最主要的数据导入函数： 函数 用途 read.csv() 读取以逗号分隔的文件(sep = \",\", header = T) read.delim() 读取以制表符分隔的文件(sep = \"\\t\", header = T) read.table() 读取其他一般性的文件，默认添加表头(sep = \"\", header = F)。read.csv()和read.delim()可以看做read.table()针对于特定情况的封装。 用于导入数据的函数一般都有大量的参数，上述的三个函数中，比较重要的参数有： dec: 指定文件中用于表示小数点的符号，很多文件中可能会用;或者,当做小数点，这时不仅需要设置dec，也要适当调整sep。read.csv2()和read.delim2()是对一些设置的封装。 col.names用于在header = F时指定列名，默认情况下将被命名为“V1”、“V2”、··· row.names用于设置行名，既可以传入一个向量直接指定，也可以选择数据中的某一列作为列名（用一个数字表明该列是第几列） colClasses:指定列的数据类型。特别是当你希望有些列作为因子，有些列作为字符串，这个参数便很有用。常用的类别有“numeric”,“factor”,“logical”,“character”。如果某列被指定为\"NULL\"，则该列不会被读入。 skip指定读取数据前跳过的行数 nrows读入的最大行数 我们使用本地数据集hotdogs.txt简要说明这些函数的用法，它没有列名，且用空格分隔： ## 分别使用三个函数 hotdogs1 &lt;- read.table(&quot;data/hotdogs.txt&quot;,sep = &quot;\\t&quot;) head(hotdogs1) #&gt; V1 V2 V3 #&gt; 1 Beef 186 495 #&gt; 2 Beef 181 477 #&gt; 3 Beef 176 425 #&gt; 4 Beef 149 322 #&gt; 5 Beef 184 482 #&gt; 6 Beef 190 587 hotdogs2 &lt;- read.csv(&quot;data/hotdogs.txt&quot;,sep = &quot;\\t&quot;,header = F) head(hotdogs2) #&gt; V1 V2 V3 #&gt; 1 Beef 186 495 #&gt; 2 Beef 181 477 #&gt; 3 Beef 176 425 #&gt; 4 Beef 149 322 #&gt; 5 Beef 184 482 #&gt; 6 Beef 190 587 hotdogs2 &lt;- read.delim(&quot;data/hotdogs.txt&quot;,header = F) head(hotdogs2) #&gt; V1 V2 V3 #&gt; 1 Beef 186 495 #&gt; 2 Beef 181 477 #&gt; 3 Beef 176 425 #&gt; 4 Beef 149 322 #&gt; 5 Beef 184 482 #&gt; 6 Beef 190 587 设定 col.names 和 colClasses： hotdogs &lt;- read.delim(&quot;data\\\\hotdogs.txt&quot;, header = FALSE, col.names = c(&quot;type&quot;, &quot;calories&quot;, &quot;sodium&quot;), colClasses = c(&quot;factor&quot;, &quot;NULL&quot;, &quot;numeric&quot;)) head(hotdogs) #&gt; type sodium #&gt; 1 Beef 495 #&gt; 2 Beef 477 #&gt; 3 Beef 425 #&gt; 4 Beef 322 #&gt; 5 Beef 482 #&gt; 6 Beef 587 3.2 readr 简介 readr 是 tidyverse 的核心 R 包之一，作用是将平面数据(flat files)快速读取至 R 中，并转换为易用的 tibble 格式。相对于 base R 中有的数据读取函数，它有以下的优点： 一般来说，它们比基础模块中的函数速度更快（约快 10 倍）。如果只考虑读取速度的话，还可以尝试使用第 12 章中的 fread() 或第 10 章中的 vroom() 它们可以生成 tibble，而且不会将字符串向量转换为因子，不使用行名称，也不会随意改动列名称。这些都是使用 base R 时比较烦人的事情 它们更容易重复使用。base R 中的函数会继承操作系统的功能，并依赖环境变量，因此，可以在你的计算机上正常运行的代码未必适用于他人的计算机 主要函数有： read_csv() 读取逗号分割文件、read_csv2() 读取分号分隔文件（这在用逗号表示小数点的国家非常普遍），read_tsv() 读取制表符分隔文件，read_delim()函数可以读取使用任意分隔符的文件(通过指定 delim 参数) read_fwf() 读取固定宽度的文件(fixed width file)。既可以使用 fwf_width() 函按照宽度来设定域，也可以使用 fwf_positions() 函数按照位置来设定域。read_table() 读取固定宽度文件的一种常用变体，其中使用空白字符来分隔各列 重要参数： delim 指定分隔符 col_names = T：以上的函数默认将第一行用作列名，如果设定col_names = F则列名为X1、X2、···。也可以指定一个字符向量。 col_types用一个字符串指定各列的数据类型 字符 含义 “i” integer “d” double “c” character “l” logical \"_\" 舍弃该列 n_max最大读取行数 na表明文件中缺失值的表示方法 下面用一些例子演示read_delim()函数的用法，因为它是最一般的形式，一旦掌握它，我们就可将从中学到的经验轻松应用于readr的其他函数。 ## column names properties &lt;- c(&quot;area&quot;, &quot;temp&quot;, &quot;size&quot;, &quot;storage&quot;, &quot;method&quot;, &quot;texture&quot;, &quot;flavor&quot;, &quot;moistness&quot;) ## 文件中用制表符为分隔符 potatoes &lt;- read_delim(&quot;data\\\\potatoes.txt&quot;,delim = &quot;\\t&quot;, col_names = properties) potatoes #&gt; # A tibble: 160 x 8 #&gt; area temp size storage method texture flavor moistness #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 1 1 2.9 3.2 3 #&gt; 2 1 1 1 1 2 2.3 2.5 2.6 #&gt; 3 1 1 1 1 3 2.5 2.8 2.8 #&gt; 4 1 1 1 1 4 2.1 2.9 2.4 #&gt; 5 1 1 1 1 5 1.9 2.8 2.2 #&gt; 6 1 1 1 2 1 1.8 3 1.7 #&gt; # … with 154 more rows 当运行readr中的数据导入函数时，会打印出一份数据了说明，给出每个列的名称和类型。后面我们学习解析时，还会继续讨论这项功能。 通过col_types指定前五列为integer类型： properties &lt;- c(&quot;area&quot;, &quot;temp&quot;, &quot;size&quot;, &quot;storage&quot;, &quot;method&quot;, &quot;texture&quot;, &quot;flavor&quot;, &quot;moistness&quot;) potatoes &lt;- read_delim(&quot;data\\\\potatoes.txt&quot;,delim = &quot;\\t&quot;, col_names = properties, col_types = &quot;iiiiiddd&quot;) potatoes #&gt; # A tibble: 160 x 8 #&gt; area temp size storage method texture flavor moistness #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 1 1 2.9 3.2 3 #&gt; 2 1 1 1 1 2 2.3 2.5 2.6 #&gt; 3 1 1 1 1 3 2.5 2.8 2.8 #&gt; 4 1 1 1 1 4 2.1 2.9 2.4 #&gt; 5 1 1 1 1 5 1.9 2.8 2.2 #&gt; 6 1 1 1 2 1 1.8 3 1.7 #&gt; # … with 154 more rows 我们还可以创建一个行内 csv 文件。这种文件非常适合用readr进行实验，以及与他人分享可重现的例子： read_delim(&quot;a, b, c 1, 2 , 3 4, 5, 6&quot;, delim = &quot;,&quot;) #&gt; # A tibble: 2 x 3 #&gt; a ` b` ` c` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &quot; 1&quot; &quot; 2 &quot; &quot; 3&quot; #&gt; 2 &quot; 4&quot; &quot; 5&quot; &quot; 6&quot; 有时文件开头会有几行元数据。可以使用 skip = n 来跳过前 n 行；或者使用 comment = \"#\" 丢弃所有以 # 开头的行： read_delim(&quot;The first line metadata The second line of metadata x,y,z 1,2,3&quot;, delim = &quot;,&quot;, skip = 2) #&gt; # A tibble: 1 x 3 #&gt; ` x` y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 &quot; 1&quot; 2 3 read_delim(&quot;# A comment I want to skip x,y,z 1,2,3&quot;, delim = &quot;,&quot;, comment = &quot;#&quot;) #&gt; # A tibble: 1 x 3 #&gt; ` x` y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 &quot; 1&quot; 2 3 设置na: read_delim(&quot;a,b,c 1,2,.&quot;, delim = &quot;,&quot;, na = &quot;.&quot;) #&gt; # A tibble: 1 x 3 #&gt; a b c #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; #&gt; 1 &quot; 1&quot; 2 NA 3.2.1 写入文件 readr还提供了两个非常有用的函数，用于将数据写回到磁盘：write_csv() 和 write_tsv()，这两个函数输出的文件能够顺利读取的概率更高，因为： 它们总使用 UTF-8 对字符串进行编码 它们都是用 ISO 8601 日期格式来保存日期和日期时间数据 如果想要将 CSV 文件导为 Excel 文件，可以使用 write_excel_csv() 函数，该函数会在文件开头写入一个特殊字符（字节顺序标记），告诉 Excel 这个文件采用的是 UTF-8 编码。 这几个函数中最重要的参数是 x (要保存的数据框)和path(保存文件的位置)。还可以使用 na 参数设定如何写入缺失值。默认情况下，写入函数会创建一个新文件或清空原有的文件再导入数据(Python中open()函数的\"mode = w\"模式)，如果想要追加到现有的文件，可以设置 append = T (Python中的mode = \"a\"模式)： library(gapminder) write_csv(x = gapminder, path = &quot;data\\\\gapminder.csv&quot;) 打开对应的文件： 3.2.2 练习 Exercise 3.1 如果一个文件中的域是由“|”分隔的，那么应该使用哪个函数读取这个文件？ 应该使用read_delim(path, delim = \"|\") Exercise 3.2 read_fwf()函数中最重要的参数是什么？ read_fwf()用于固定宽度文件(fixed width files)。在固定宽度文件中，每一列的的宽度是固定的（不足的用某种填充符号填充），如第一列总是10个字符长度，第二列 5 个字符长度，第三列8个字符长度，每列内采取统一的对齐方式。readr安装时附带了一个固定宽度文件的示例,我们用一个变量存储它的路径： fwf_sample &lt;- readr_example(&quot;fwf-sample.txt&quot;) fwf_sample #&gt; [1] &quot;C:/Users/56570/Documents/R/win-library/3.6/readr/extdata/fwf-sample.txt&quot; txt 文件内的内容： 读取固定宽度文件时，最重要的是告诉 R 每列的位置，参数 col_positions 用于这项工作，有几种不同的表示方式： # You can specify column positions in several ways: # 1. Guess based on position of empty columns read_fwf(fwf_sample, col_positions = fwf_empty(fwf_sample, col_names = c(&quot;first&quot;, &quot;last&quot;, &quot;state&quot;, &quot;ssn&quot;))) #&gt; # A tibble: 3 x 4 #&gt; first last state ssn #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 John Smith WA 418-Y11-4111 #&gt; 2 Mary Hartford CA 319-Z19-4341 #&gt; 3 Evan Nolan IL 219-532-c301 # 2. A vector of field widths read_fwf(fwf_sample, col_positions = fwf_widths(c(20, 10, 12), col_names = c(&quot;name&quot;, &quot;state&quot;, &quot;ssn&quot;))) #&gt; # A tibble: 3 x 3 #&gt; name state ssn #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 John Smith WA 418-Y11-4111 #&gt; 2 Mary Hartford CA 319-Z19-4341 #&gt; 3 Evan Nolan IL 219-532-c301 # 3. Paired vectors of start and end positions read_fwf(fwf_sample, col_positions = fwf_positions(c(1, 30), c(20, 42), col_names = c(&quot;name&quot;, &quot;ssn&quot;))) #&gt; # A tibble: 3 x 2 #&gt; name ssn #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 John Smith 418-Y11-4111 #&gt; 2 Mary Hartford 319-Z19-4341 #&gt; 3 Evan Nolan 219-532-c301 # 4. Named arguments with start and end positions read_fwf(fwf_sample, col_positions = fwf_cols(name = c(1, 20), ssn = c(30, 42))) #&gt; # A tibble: 3 x 2 #&gt; name ssn #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 John Smith 418-Y11-4111 #&gt; 2 Mary Hartford 319-Z19-4341 #&gt; 3 Evan Nolan 219-532-c301 # 5. Named arguments with column widths read_fwf(fwf_sample, col_positions = fwf_cols(name = 20, state = 10, ssn = 12)) #&gt; # A tibble: 3 x 3 #&gt; name state ssn #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 John Smith WA 418-Y11-4111 #&gt; 2 Mary Hartford CA 319-Z19-4341 #&gt; 3 Evan Nolan IL 219-532-c301 3.3 解析向量(Parsing a vector) 在详细介绍 readr 如何从磁盘读取文件之前，我们需要先讨论一下 parse_*()函数族。这些函数接受一个字符向量（因为文件中的数据全部是以字符串的形式进入 R 的），并返回一个特定向量，如逻辑、整数或日期向量： ## 用str()函数返回类别 str(parse_logical(c(&quot;True&quot;, &quot;False&quot;, &quot;True&quot;))) #&gt; logi [1:3] TRUE FALSE TRUE str(parse_integer(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;))) #&gt; int [1:3] 1 2 3 str(parse_date(c(&quot;2010-01-01&quot;, &quot;2019-08-15&quot;))) #&gt; Date[1:2], format: &quot;2010-01-01&quot; &quot;2019-08-15&quot; 这些函数各司其职，且都是 readr 的重要组成部分。一旦掌握了本节中这些单个解析函数的用法，我们就可以继续讨论如何综合使用它们来解析整个文件了。 和 tidyverse 中出现的函数族一样，parse_*() 函数族有着相同的参数结构。第一个参数是需要解析的字符向量，na参数设定了哪些字符串应该当做缺失值处理： parse_integer(c(&quot;1&quot;,&quot;2&quot;,&quot;.&quot;,&quot;456&quot;),na = &quot;.&quot;) #&gt; [1] 1 2 NA 456 如果解析失败，你会收到一条警告： x &lt;- parse_integer(c(&quot;123&quot;, &quot;345&quot;, &quot;abc&quot;, &quot;123.45&quot;)) 解析失败的值在输出中以缺失值的形式存在: x #&gt; [1] 123 345 NA NA #&gt; attr(,&quot;problems&quot;) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters .45 如果解析失败的值很多，那么就应该使用 problems() 函数来获取完整的失败信息集合。这个函数会返回一个 tibble，可以使用 dplyr 来处理它： problems(x) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters .45 在解析函数的使用方面，最重要的是知道有哪些解析函数，以及每种解析函数用来处理哪种类型的输入。具体来说，重要的解析函数有8中： parse_logical()和parse_integer()函数分别解析逻辑值和整数，因为这两个解析函数基本不会出现问题，所以我们不再进行更多介绍 parse_double()是严格的数值型解析函数，而parse_number()则是灵活的数值型解析函数，这两个函数背后很复杂，因为世界各地书写数值的方式不尽相同 parse_character()函数似乎太过简单，甚至没必要存在，因为R读取的文件本身就是字符串形式。但一个棘手的问题使得这个函数非常重要：字符编码 parse_factor()函数可以创建因子，R使用这种数据结构表示分类变量，该变量具有固定数目的已知值 parse_datetime()、parse_date()和parse_time()函数可以解析不同类型的日期和时间，它们是最复杂的，因为有太多不同的日期书写形式 3.3.1 数值 解析数值似乎是直截了当的，但以下 3 个问题增加了数値解析的复杂性： 世界各地的人们书写数值的方式不尽相同。例如有些国家使用.当做小数点，而有些国家使用, 数值周围可能会有其他字符，例如$1000、15℃ 和10% 数值经常包含某种形式的分组(grouping)，以便更易读，如1 000 000，而且世界各地用来分组的字符也不统一 为了解决第一个问题，readr使用了地区的概念(locale)，使得可以按照不同地区设置解析选项。在解析数值时，最重要的选项就是用来表示小数点的字符，通过设置一个新的地区对象并设定decimal_mark参数，可以覆盖.的默认值： parse_double(&quot;1.23&quot;) #&gt; [1] 1.23 parse_double(&quot;1,23&quot;, locale = locale(decimal_mark = &quot;,&quot;)) #&gt; [1] 1.23 locale()函数可以通过decimal_mark,grouping_mark,date_format,time_format,tz,encoding等参数创建一个地区对象，设定该地区内的一些表示习惯，这里我们告诉R哪个符号被用来当做小数点。 readr的默认地区是US-centric。获取默认地区的另一种方法是利用操作系统，但这可能让你的代码只能在你的电脑上运行，通过电子邮件共享给另一个国家的同事时，就可能失效。 parse_number()解决了第二个问题：它可以忽略数值前后的非数值型字符。这个函数特别适合处理货币和百分比，你可以提取嵌在文本中的数值： parse_number(&quot;$100&quot;) #&gt; [1] 100 parse_number(&quot;20%&quot;) #&gt; [1] 20 parse_number(&quot;37℃&quot;) #&gt; [1] 37 parse_number(&quot;It cost $123.45&quot;) #&gt; [1] 123 组合使用 parse_number() 和 locale() 可以解决最后一个问题，因为 parse_number() 可以忽略“分组符号” ： ## 适用于美国，忽略分组符号 parse_number(&quot;123,456,789&quot;) #&gt; [1] 1.23e+08 ## 适用于多数欧洲国家，需要用locale设置分组符号，因为.被默认为小数点 parse_number(&quot;123.456.789&quot;, locale = locale(grouping_mark = &quot;.&quot;)) #&gt; [1] 1.23e+08 ## 适用于瑞士 parse_number(&quot;123&#39;456&#39;789&quot;, locale = locale(grouping_mark = &quot;&#39;&quot;)) #&gt; [1] 1.23e+08 3.3.2 字符串 parse_character() 似乎真的很简单，只要返回输入值就可以了。问题是同一个字符串有多种表示编码方式。在继续探讨之前，需要厘清一些概念： 什么是字符？ 字符是各种文字和符号的总称，包括各个国家文字、标点符号、图形符号、数字等，甚至还包括表情符号。 什么是字符集？ 字符集是多个字符的集合，字符集种类较多，每个字符集包含的字符个数不同，常见字符集有：ASCII字符集、ISO 8859字符集、GB2312字符集、BIG5字符集、GB18030字符集、Unicode字符集等。ASCII可以非常好地表示英文字符，因为它就是美国信息交换标准代码(American Standard Code for Information Interchange)的缩写。Unicode是国际组织制定的可以容纳世界上所有文字和符号的字符编码方案。 什么是字符编码？ 计算机要准确的处理各种字符集文字，需要进行字符编码，以便计算机能够识别和存储各种文字。 字符编码(encoding)和字符集不同。字符集只是字符的集合，不一定适合作网络传送、处理，有时须经编码(encode)后才能应用。如Unicode可依不同需要以UTF-8、UTF-16、UTF-32等方式编码。 字符编码就是以二进制的数字来对应字符集的字符。因此，对字符进行编码，是信息交流的技术基础。 概括 使用哪些字符。也就是说哪些汉字，字母和符号会被收入标准中。所包含“字符”的集合就叫做“字符集”。 规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储，这个规定就叫做“编码”。 各个国家和地区在制定编码标准的时候，“字符的集合”和“编码”一般都是同时制定的。因此，平常我们所说的“字符集”，比如：GB2312, GBK, JIS等，除了有“字符的集合”这层含义外，同时也包含了“编码”的含义。 注意：Unicode字符集有多种编码方式，如UTF-8、UTF-16等；ASCII只有一种；大多数MBCS（包括GB2312，GBK）也只有一种。 在R中，我们可以使用charToRaw()函数获得一个字符串的底层表示（underlying representation）： char_raw &lt;- charToRaw(&quot;Maxine&quot;) char_raw #&gt; [1] 4d 61 78 69 6e 65 charToRaw()返回的尚不是编码结果（二进制），而是十六进制的表示。每个十六进制数表示字符串的一个字节：4d是M，61是a等。charToRaw()返回的对象在R中被称为raw type，想要得到真正的二进制编码，要对raw type再使用rawToBits()函数： rawToBits(char_raw) #&gt; [1] 01 00 01 01 00 00 01 00 01 00 00 00 00 01 01 00 00 00 00 01 01 01 01 00 01 #&gt; [26] 00 00 01 00 01 01 00 00 01 01 01 00 01 01 00 01 00 01 00 00 01 01 00 readr默认使用UTF-8编码。其中的含义在于，每当接受到一个字符串，R收到的不是字符串本身，而是它背后的二进制表示，于是R便尝试按照UTF-8的规则解读这些二进制码，把它们还原为人类所能理解的字符。问题是，如果你的文件不是用UTF-8编码，这就像用英文字典来解释汉语拼音，可能小张计算机存储字母”A”是1100001，而小王存储字母”A”是11000010，这样双方交换信息时就会误解。比如小张把1100001发送给小王，小王并不认为1100001是字母”A”，可能认为这是字母”X”，于是小王在用记事本访问存储在硬盘上的1100001时，在屏幕上显示的就是字母”X”。 要解决这个问题，需要在parse_character()函数中通过locale(encoding = )参数设定编码方式： 如何才能找到正确的编码方式呢？有可能数据来源会注明，但如果没有到话，readr包提供了guess_encoding()函数来帮助你找出编码方式。这个函数并非万无一失，如果有大量文本效果就会更好，它的第一个参数可以是直接的文件路径，也可以是一个raw type: guess_encoding(charToRaw(&quot;中国&quot;)) #&gt; # A tibble: 1 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ASCII 1 parse_character(&quot;中国&quot;,locale = locale(encoding = &quot;UTF-8&quot;)) #&gt; [1] &quot;&lt;U+4E2D&gt;&lt;U+56FD&gt;&quot; parse_character(&quot;中国&quot;,locale = locale(encoding = &quot;windows-1252&quot;)) #&gt; [1] &quot;&lt;U+4E2D&gt;&lt;U+56FD&gt;&quot; guess_encoding(&quot;data\\\\hotdogs.txt&quot;) #&gt; # A tibble: 1 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ASCII 1 编码问题博大精深，这里只是蜻蜓点水式地介绍一下。如果想要学习更多相关知识，可以阅读http://kunststube.net/encoding/ 3.3.3 因子 因子对应的解析函数是 parse_factor() ，其中 levels 参数被赋予一个包含所有因子可能水平的向量，如果要解析的列存在 levels 中没有的值，就会生成一条警告。 fruit &lt;- c(&quot;apple&quot;, &quot;banana&quot;) f &lt;- parse_factor(c(&quot;apple&quot;, &quot;banana&quot;, &quot;bananana&quot;), levels = fruit) problems(f) #&gt; # A tibble: 1 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA value in level set bananana 如果有很多问题条目的话，最简单的是它们当做字符串来解析，然后用forcats包进行后续处理。 3.3.4 日期时间、日期、时间 根据需要的是日期型数据（从1970-01-01开始的天数）、日期时间型数据（从1970-01-01开始的秒数）还是时间型数据（从午夜开始的描述），我们可以在3中解析函数之间进行选择。在没有使用任何附加参数时调用，具体情况如下： parse_datetime()期待的是符合 ISO 8601 标准的日期时间。ISO 8601是一种国际标准，其中日期的各个部分按从大到小的顺序排列，即年、月、日、小时、分钟、秒： parse_datetime(&quot;2010-10-01 201002&quot;) #&gt; [1] &quot;2010-10-01 20:10:02 UTC&quot; ## 如果时间被忽略了，就会被设置为午夜 parse_datetime(&quot;20101001&quot;) #&gt; [1] &quot;2010-10-01 UTC&quot; 这是最重要的日期/时间标准，如果经常使用日期和时间，可以阅读以下维基百科上的ISO 8601标准 parse_date()期待的是四位数的年份、一个-或者/作为分隔符，月，一个-或者/作为分隔符，然后是日： parse_date(&quot;2010-10-01&quot;) #&gt; [1] &quot;2010-10-01&quot; parse_date(&quot;2010/10/01&quot;) #&gt; [1] &quot;2010-10-01&quot; parse_time()期待的是小时，:作为分隔符，分钟，可选的:和后面的秒，以及一个可选的 am/pm 标识符： parse_time(&quot;8:20 pm&quot;) #&gt; 20:20:00 parse_time(&quot;8:20:05&quot;) #&gt; 08:20:05 如果默认数据不适合实际数据，那么可以为 parse_date() 的第二个参数 format 传入一个字符串指定自己的日期时间格式(这个参数是解析日期时间的函数在parse_*()函数族中特有的)，格式由以下各部分组成： 成分 符号 年 %Y(四位数)%y(两位数；00-69被解释为2000-2069、70-99被解释为1970-1999) 月 %m(两位数) %b（简写名称，如“Jan”） %B（完整名称，如January） 日 %d(一位数或两位数) %e(两位数) 时间 %H(0-23小时)%I(0-12小时，必须和%p一起使用) %p(表示am/pm) %M(分钟) S(整数秒) %OS(实数秒) %Z(时区) 非数值字符 %.(跳过一个非数值字符) %*跳过所有非数值字符 找出正确格式的最好方法是创建几个解析字符向量的示例，并使用某种解析函数进行测试（如果数据中有分隔符，则）： parse_date(&quot;100101&quot;,format = &quot;%m%d%y&quot;) #&gt; [1] &quot;2001-10-01&quot; parse_date(&quot;01/02/15&quot;,&quot;%y/%m/%d&quot;) #&gt; [1] &quot;2001-02-15&quot; parse_date(&quot;Nov/12/1998&quot;,&quot;%b/%d/%Y&quot;) #&gt; [1] &quot;1998-11-12&quot; 3.3.5 练习 Exercise 3.3 如果在locale()函数中把decimal_mark和grouping_mark设为同一个字符，会发生什么情况？如果将decimal_mark设为逗号，grouping_mark的默认值会发生什么变化？如果将grouping_mark设置为句点，decimal_mark的默认值会发生什么变化？ 不能将decimal_mark 和 group_mark设为同一个字符： locale(decimal_mark = &quot;.&quot;,grouping_mark = &quot;.&quot;) #&gt; Error: `decimal_mark` and `grouping_mark` must be different 将decimal_mark设为逗号时，grouping_mark的默认值将变为.(见第一行): locale(decimal_mark = &quot;,&quot;) #&gt; &lt;locale&gt; #&gt; Numbers: 123.456,78 #&gt; Formats: %AD / %AT #&gt; Timezone: UTC #&gt; Encoding: UTF-8 #&gt; &lt;date_names&gt; #&gt; Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday #&gt; (Thu), Friday (Fri), Saturday (Sat) #&gt; Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), #&gt; June (Jun), July (Jul), August (Aug), September (Sep), October #&gt; (Oct), November (Nov), December (Dec) #&gt; AM/PM: AM/PM 将grouping_mark设为句点时，decimal_mark的默认值将变为,: locale(grouping_mark = &quot;.&quot;) #&gt; &lt;locale&gt; #&gt; Numbers: 123.456,78 #&gt; Formats: %AD / %AT #&gt; Timezone: UTC #&gt; Encoding: UTF-8 #&gt; &lt;date_names&gt; #&gt; Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday #&gt; (Thu), Friday (Fri), Saturday (Sat) #&gt; Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), #&gt; June (Jun), July (Jul), August (Aug), September (Sep), October #&gt; (Oct), November (Nov), December (Dec) #&gt; AM/PM: AM/PM Exercise 3.4 locale()函数中的date_format()和time_format()参数有什么用？ date_format() 和 time_format() 和 format 参数的功能一样，用以指定日期时间数据的格式，如果在 locale() 中设定了以上两个参数，就不需要再设定 format；反之亦然： parse_date(&quot;170625&quot;, locale = locale(date_format = &quot;%y%m%d&quot;)) #&gt; [1] &quot;2017-06-25&quot; 生成正确行使的字符串来解析以下日期和时间。 d1 &lt;- &quot;January 1,2010&quot; parse_date(d1,&quot;%B %d,%Y&quot;) #&gt; [1] &quot;2010-01-01&quot; d2 &lt;- &quot;2015-Mar-07&quot; parse_date(d2,&quot;%Y-%b-%e&quot;) #&gt; [1] &quot;2015-03-07&quot; d3 &lt;- c(&quot;August 19 (2015)&quot;,&quot;July 1 (2015)&quot;) parse_date(d3,&quot;%B %d (%Y)&quot;) #&gt; [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; t1 &lt;- &quot;1705&quot; parse_time(&quot;1705&quot;,&quot;%H%M&quot;) #&gt; 17:05:00 t2 &lt;- &quot;11:15:10.12 PM&quot; parse_time(t2,&quot;%I:%M:%OS %p&quot;) #&gt; 23:15:10.12 3.4 解析文件 现在我们已经学会了如何用 parse_*() 函数族解析单个向量，接下来就能回到本章的最初目标，研究readr是如何解析文件的。我们将关注以下两点： readr如何自动猜出文件每列的数据类型 如何修改默认设置 3.4.1 解析策略(strategies) readr 通过一种启发式过程(heuristic)来确定每列的类型：先读取文件的前1000行，然后使用（相对保守的）某种启发式算法确定每列的类型。readr 中的导入函数会先用 guess_parser() 函数返回对于所需解析函数最可信的猜测，然后尝试用可能性最大的解析函数解析该列： guess_parser(&quot;123.45&quot;) #&gt; [1] &quot;double&quot; guess_parser(&quot;12,352,561&quot;) #&gt; [1] &quot;number&quot; guess_parser(&quot;1998-11-12&quot;) #&gt; [1] &quot;date&quot; guess_parser(c(&quot;True&quot;, &quot;False&quot;)) #&gt; [1] &quot;logical&quot; 这个过程会依次尝试以下每种数据类型，直到找到匹配的类型。 逻辑值(logical)： 只包括F、T、FALSE和True 整数(integer) 只包括数值型字符（以及-） 双精度浮点数(double) 只包括有效的双精度浮点数 数值(number) 只包括带有分组符号的有效双精度浮点数 时间 与默认的time_format匹配的值 日期 与默认的date_format匹配的值 日期时间 符合ISO 8601标准的任何日期 如果以上数据不符合上述要求中的任意一个，那么这一列就是一个字符串向量，readr将使用parse_character()解析它。 3.4.2 可能遇到的问题 这些默认设置对更大的文件并不总是有效。以下是两个可能遇到的主要问题： readr通过前 1000 行猜测数据类型，但是前 1000 行可能只是一种特殊情况，不足以代表整列。例如，一列双精度数值的前1000行有可能都是整数 列中可能包含大量缺失值。如果前 1000 行都是NA，那么readr会认为这是一个字符向量，但你其实想将这一类解析为更具体的值。 readr的安装包里包含了一份文件challenge.csv，用来说明解析过程中可能遇到的问题。这个csv文件包含两列x，y和2001行观测。x 列的前 1001 行均为整数，但之后的值均为双精度整数。y 列的前 1001 行均为NA，后面是日期型数据： ## readr_example()找到包含在R包中的文件的路径 challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;)) 可以看到，read_csv()成功解析了 x，但对于 y 则无从下手，因为使用了错误的解析函数col_logical()。使用 problems() 函数明确列出这些失败记录，以便深入探究其中的问题： problems(challenge) #&gt; # A tibble: 1,000 x 5 #&gt; row col expected actual file #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1001 y 1/0/T/F/TRUE/… 2015-01… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; 2 1002 y 1/0/T/F/TRUE/… 2018-05… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; 3 1003 y 1/0/T/F/TRUE/… 2015-09… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; 4 1004 y 1/0/T/F/TRUE/… 2012-11… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; 5 1005 y 1/0/T/F/TRUE/… 2020-01… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; 6 1006 y 1/0/T/F/TRUE/… 2016-04… &#39;C:/Users/56570/Documents/R/win-library/3… #&gt; # … with 994 more rows 可以使用spec_csv() 函数来直接查看 readr 在默认情况下用那种类型的解析函数解析数据： spec_csv(readr_example(&quot;challenge.csv&quot;)) #&gt; cols( #&gt; x = col_double(), #&gt; y = col_logical() #&gt; ) 为了解决这个问题，我们用read_csv()函数中的col_types指定每列的解析方法(column specification)，之前我们向col_types传入一个字符串说明各列的类别，但这里是要直接指明解析函数了。这样做的指定必须通过cols()函数来创建(具体格式和spec_csv()或者read_csv自动打印的说明是一样的)： challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), col_types =cols( x = col_double(), y = col_date() )) tail(challenge) #&gt; # A tibble: 6 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 0.805 2019-11-21 #&gt; 2 0.164 2018-03-29 #&gt; 3 0.472 2014-08-04 #&gt; 4 0.718 2015-08-16 #&gt; 5 0.270 2020-02-04 #&gt; 6 0.608 2019-01-06 每个parse_*()函数都有一个对应的col_*()函数。如果数据已经保存在R的字符向量中，那么可以使用parse_*()，如果要告诉readr如何加载数据，则应该使用col_*()。 The available specifications are: (with string abbreviations in brackets) col_logical() [l], containing only T, F, TRUE or FALSE. col_integer() [i], integers. col_double() [d], doubles. col_character() [c], everything else. col_factor(levels, ordered) [f], a fixed set of values. col_date(format = \"\") [D]: with the locale’s date_format. col_time(format = \"\") [t]: with the locale’s time_format. col_datetime(format = \"\") [T]: ISO8601 date times col_number() [n], numbers containing the grouping_mark col_skip() [_, -], don’t import this column. col_guess() [?], parse using the “best” type based on the input. cols_only()代替cols()可以仅指定部分列的解析方式；.default表示未提及的所有列(read_csv()的默认设置可以表示为read_csv( col_type = cols(.default = col_guess())) 一旦我们指定了正确的解析函数，问题便迎刃而解。 3.4.3 其他技巧 我们再介绍其他几种有注意解析文件的通用技巧： 在前面的示例中，如果比默认方式再多检查一行，我们就能一蹴而就，解析成功： challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), guess_max = 1001) type_convert()函数在一个数据框的所有字符列上应用启发式解析过程： df &lt;- tribble( ~x,~y, &quot;1&quot;,&quot;1.21&quot;, &quot;4&quot;,&quot;2,32&quot;, &quot;3&quot;,&quot;4,56&quot; ) df #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 1.21 #&gt; 2 4 2,32 #&gt; 3 3 4,56 ## 注意列类型 type_convert(df) #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1.21 #&gt; 2 4 232 #&gt; 3 3 456 如果正在读取一个非常大的文件，那么应该将n_max设置为一个较小的数，比如10,000或者100,000，这可以让我们在解决常见问题时加快重复试验的过程。 3.5 readxl 要想将其他类型的数据导入 R 中，可以先从下列的tidyverse包开始。对矩形数据来说： haven可以读取SPSS、Stata和SAS文件: 配合专用的数据库后端程序（如 RMySQL，RSQLite，RpostgreSQL等），DBI可以对相应数据库进行SQL查询，并返回一个数据框 readxl 专门为读取 Excel 文件打造(.xlsx和xls均可) 下面主要介绍 readxl 的用法，不同于readr，readxl 不是 tidyverse 的核心包，我们总需要显示地加载它： library(readxl) read_excel() 是 readxl 中的核心函数，它的第一个参数path接受 xlsx 或 xls 文件的路径。但由于一个 Excel 文件（工作簿）经常包含多个工作表，所以我们在读取时需要指明某张工作表，excel_sheets() 函数返回一个工作簿文件中各个工作表(sheet)的名字： ## readxl附带的Excel文件 readxl_example() #&gt; [1] &quot;clippy.xls&quot; &quot;clippy.xlsx&quot; &quot;datasets.xls&quot; &quot;datasets.xlsx&quot; #&gt; [5] &quot;deaths.xls&quot; &quot;deaths.xlsx&quot; &quot;geometry.xls&quot; &quot;geometry.xlsx&quot; #&gt; [9] &quot;type-me.xls&quot; &quot;type-me.xlsx&quot; ## read_expample()函数获取路径 path &lt;- readxl_example(&quot;deaths.xlsx&quot;) excel_sheets(path) #&gt; [1] &quot;arts&quot; &quot;other&quot; 获悉一个工作簿内部的表结构以后，可以使用sheets参数指定要读取的表，可以是一个整数（第几张彪），也可以是字符串（表明）, read_excel()默认读取第一张表： deaths &lt;- read_excel(path, sheet = &quot;arts&quot;) 经常会在读取Excel文件时遇到的一个问题是,有些人喜欢在表格的前面几行或最后几行添加一些无关真正分析内容元数据（metadata），比如在deaths.xlsx这个Excel文件中： 默认设置下，read_excel()会将这些元数据一并读入： deaths #&gt; # A tibble: 18 x 6 #&gt; `Lots of people` ...2 ...3 ...4 ...5 ...6 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 simply cannot resist writ… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; some notes #&gt; 2 at the top &lt;NA&gt; of their spreadsh… #&gt; 3 or merging &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; cells #&gt; 4 Name Professi… Age Has ki… Date of bi… Date of death #&gt; 5 David Bowie musician 69 TRUE 17175 42379 #&gt; 6 Carrie Fisher actor 60 TRUE 20749 42731 #&gt; # … with 12 more rows 一个很有用的方法是通过Rstudio的File\\(\\rightarrow\\)Import Dataset\\(\\rightarrow\\)From Excel 接口导入数据，我们可以通过预览来观察导入后的数据，还可以对read_excel()的导入参数进行设置： 对于deaths.xlsx这个Excel文件，可以结合使用n_max 和 skip 参数去除不想读取的部分（分别对应图形界面里的Max Rows和Skip： read_excel(path, skip= 4, n_max = 10) #&gt; # A tibble: 10 x 6 #&gt; Name Profession Age `Has kids` `Date of birth` `Date of death` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dttm&gt; &lt;dttm&gt; #&gt; 1 David Bow… musician 69 TRUE 1947-01-08 00:00:00 2016-01-10 00:00:00 #&gt; 2 Carrie Fi… actor 60 TRUE 1956-10-21 00:00:00 2016-12-27 00:00:00 #&gt; 3 Chuck Ber… musician 90 TRUE 1926-10-18 00:00:00 2017-03-18 00:00:00 #&gt; 4 Bill Paxt… actor 61 TRUE 1955-05-17 00:00:00 2017-02-25 00:00:00 #&gt; 5 Prince musician 57 TRUE 1958-06-07 00:00:00 2016-04-21 00:00:00 #&gt; 6 Alan Rick… actor 69 FALSE 1946-02-21 00:00:00 2016-01-14 00:00:00 #&gt; # … with 4 more rows read_excel()中另一个很有用的参数是range，用于指定一块Excel表中要读取的区域： read_excel(path, sheet = &quot;arts&quot;, range = &quot;A5:F15&quot;) #&gt; # A tibble: 10 x 6 #&gt; Name Profession Age `Has kids` `Date of birth` `Date of death` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dttm&gt; &lt;dttm&gt; #&gt; 1 David Bow… musician 69 TRUE 1947-01-08 00:00:00 2016-01-10 00:00:00 #&gt; 2 Carrie Fi… actor 60 TRUE 1956-10-21 00:00:00 2016-12-27 00:00:00 #&gt; 3 Chuck Ber… musician 90 TRUE 1926-10-18 00:00:00 2017-03-18 00:00:00 #&gt; 4 Bill Paxt… actor 61 TRUE 1955-05-17 00:00:00 2017-02-25 00:00:00 #&gt; 5 Prince musician 57 TRUE 1958-06-07 00:00:00 2016-04-21 00:00:00 #&gt; 6 Alan Rick… actor 69 FALSE 1946-02-21 00:00:00 2016-01-14 00:00:00 #&gt; # … with 4 more rows ## 还可以在range中指定列名 read_excel(path, range = &quot;arts!A5:F15&quot;) #&gt; # A tibble: 10 x 6 #&gt; Name Profession Age `Has kids` `Date of birth` `Date of death` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dttm&gt; &lt;dttm&gt; #&gt; 1 David Bow… musician 69 TRUE 1947-01-08 00:00:00 2016-01-10 00:00:00 #&gt; 2 Carrie Fi… actor 60 TRUE 1956-10-21 00:00:00 2016-12-27 00:00:00 #&gt; 3 Chuck Ber… musician 90 TRUE 1926-10-18 00:00:00 2017-03-18 00:00:00 #&gt; 4 Bill Paxt… actor 61 TRUE 1955-05-17 00:00:00 2017-02-25 00:00:00 #&gt; 5 Prince musician 57 TRUE 1958-06-07 00:00:00 2016-04-21 00:00:00 #&gt; 6 Alan Rick… actor 69 FALSE 1946-02-21 00:00:00 2016-01-14 00:00:00 #&gt; # … with 4 more rows 与range相关的帮助函数cell_rows()、cell_cols()和cell_limits()可以为区域选择提供更大的自由度，下面的示例中使用文件geometry.xls，读取预览： path &lt;- readxl_example(&quot;geometry.xls&quot;) # Specify only the rows or only the columns read_excel(path, range = cell_rows(3:6)) #&gt; # A tibble: 3 x 3 #&gt; B3 C3 D3 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 B4 C4 D4 #&gt; 2 B5 C5 D5 #&gt; 3 B6 C6 D6 read_excel(path, range = cell_cols(&quot;C:D&quot;)) #&gt; # A tibble: 3 x 2 #&gt; C3 D3 #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 C4 D4 #&gt; 2 C5 D5 #&gt; 3 C6 D6 read_excel(path, range = cell_cols(2)) #&gt; # A tibble: 3 x 1 #&gt; B3 #&gt; &lt;chr&gt; #&gt; 1 B4 #&gt; 2 B5 #&gt; 3 B6 # Specify exactly one row or column bound read_excel(path, range = cell_rows(c(5, NA))) #&gt; # A tibble: 1 x 3 #&gt; B5 C5 D5 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 B6 C6 D6 read_excel(path, range = cell_rows(c(NA, 4))) #&gt; # A tibble: 3 x 3 #&gt; ...1 ...2 ...3 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; #&gt; 2 B3 C3 D3 #&gt; 3 B4 C4 D4 read_excel(path, range = cell_cols(c(&quot;C&quot;, NA))) #&gt; # A tibble: 3 x 2 #&gt; C3 D3 #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 C4 D4 #&gt; 2 C5 D5 #&gt; 3 C6 D6 read_excel(path, range = cell_cols(c(NA, 2))) #&gt; # A tibble: 3 x 2 #&gt; ...1 B3 #&gt; &lt;lgl&gt; &lt;chr&gt; #&gt; 1 NA B4 #&gt; 2 NA B5 #&gt; 3 NA B6 # General open rectangles # upper left = C4, everything else unspecified read_excel(path, range = cell_limits(c(4, 3), c(NA, NA))) #&gt; # A tibble: 2 x 2 #&gt; C4 D4 #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 C5 D5 #&gt; 2 C6 D6 # upper right = D4, everything else unspecified read_excel(path, range = cell_limits(c(4, NA), c(NA, 4))) #&gt; # A tibble: 2 x 4 #&gt; ...1 B4 C4 D4 #&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 NA B5 C5 D5 #&gt; 2 NA B6 C6 D6 "],
["lubridate.html", "4 lubridate 4.1 创建日期和时间 4.2 日期时间成分 4.3 时间间隔（Time Span）", " 4 lubridate 本章将介绍如何在 R 中处理日期和时间。乍看起来，日期和时间非常容易，但是随着对他们的了解越来越多，我们就会越来越发现其复杂之处。思考一下下面三个看似很简单的问题： 确定闰年的完整规则是什么？ “四年一闰，百年不闰，四百年再闰” 每一天都是24小时吗？ 世界上很多地区使用夏时制（不包括中国），因此很多天是23个小时，有些天则是25个小时。 每分钟都是60秒吗？ 因为地球自转正在逐渐变慢，所以有时候要增加一个“闰秒”，有些分钟就变成了61秒。目前，全球已经进行了27次闰秒，均为正闰秒。最近一次闰秒在北京时间2017年1月1日7时59分59秒（时钟显示07:59:60）出现。这也是本世纪的第五次闰秒。 日期和时间非常复杂，因为它们要兼顾两种物理现象（地球的自转以及围绕太阳的公转）和一系列地理政治现象（包括月份、市区和夏时制）。本章主要讨论 lubridate 包，它可以使得R对日期和时间的处理更加容易。lubridate 不是 tidyverse 的核心 R 包，故需要手动加载。此外还需要 nycflights 作为练习数据。 library(lubridate) library(nycflights13) 4.1 创建日期和时间 表示日期或时间的数据有3种类型: 日期： 用年月日表示，在tibble中显示为&lt;date&gt; 时间： 一天中的某个时刻，用24小时制表示，在tibble中显示为&lt;time&gt; 日期时间: 可以唯一标识某个时刻（通常精确到秒）的日期+时间，在tibble中显示为&lt;dttm&gt;。而这种类型在R语言的其他地方被称作POSIXct 如果能够满足需要，就应该使用最简单的数据类型。这意味着只要能够使用日期型数据，那么就不应该使用日期时间型数据。日期时间型数据要复杂很多，因为要处理时期，我们会在本章末尾继续讨论这个问题。 要想得到当前日期或当前时期时间，可以使用 today() 或 now() 函数： today() #&gt; [1] &quot;2019-12-12&quot; now() #&gt; [1] &quot;2019-12-12 00:49:31 CST&quot; 除此之外，以下3种方法也可以创建日期或时间： 通过字符串创建 通过日期时间的各个成分创建 通过现有的日期时间对象创建 4.1.1 通过字符串创建 日期时间数据经常用字符串表示。在事先知晓各个组成部分顺序的前提下，通过 lubridate 中的一些辅助函数，可以轻松将字符串转换为日期时间格式。因为要想使用函数，需要先确定年、月、日在日期数据中的顺序，然后按照同样的顺讯排列字母 y、m、d，这样就可以组成能够创建日期格式的 lubridate 函数名称，例如： ymd(&quot;2017-03-01&quot;) #&gt; [1] &quot;2017-03-01&quot; mdy(&quot;January 1st,2017&quot;) #&gt; [1] &quot;2017-01-01&quot; dmy(&quot;31-Jan-2017&quot;) #&gt; [1] &quot;2017-01-31&quot; 这些函数也可以接受不带引号的数值，这是创建单个时期时间对象的最简单的方法。在筛选日期时间数据时，就可以使用这种方法： ymd(20190731) #&gt; [1] &quot;2019-07-31&quot; ymd()和其他类似函数可以创建日期数据。想要创建日期时间型数据，可以在后面加一个下划线，以及h、m、s之中的一个或多个字母（依然要遵循顺序），这样就可以得到解析日期时间数据的函数了： ymd_hms(&quot;2017-01-31 20:11:59&quot;) #&gt; [1] &quot;2017-01-31 20:11:59 UTC&quot; mdy_hm(&quot;01/31/2017 08:01&quot;) #&gt; [1] &quot;2017-01-31 08:01:00 UTC&quot; 如果用类似函数尝试解析包含无效内容的字符串，将会返回 NA ： ymd(&quot;2010-10-10&quot;, &quot;bananas&quot;) #&gt; [1] &quot;2010-10-10&quot; NA 通过添加一个时区参数，可以将一个时期强制转换为日期时间： ## 这是一个日期时间型变量 ymd(20170131, tz = &quot;UTC&quot;) #&gt; [1] &quot;2017-01-31 UTC&quot; 4.1.2 通过各个成分创建 除了单个字符串，日期时间数据的各个成分还经常分布在表格的多个列中。flights 数据就是这样的： flights %&gt;% select(year, month, day, hour, minute) #&gt; # A tibble: 336,776 x 5 #&gt; year month day hour minute #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 15 #&gt; 2 2013 1 1 5 29 #&gt; 3 2013 1 1 5 40 #&gt; 4 2013 1 1 5 45 #&gt; 5 2013 1 1 6 0 #&gt; 6 2013 1 1 5 58 #&gt; # … with 3.368e+05 more rows 想要用这样的多个变量创建一个完整的日期或时间数据，可以使用make_date(year,month.day,hour,min,sec,tz)(创建日期)或make_datetime(year,month.day,hour,min,sec,tz)（创建日期时间）函数: ## 使用make_datetime flights %&gt;% select(year, month, day, hour, minute) %&gt;% mutate(departure = make_datetime(year, month, day, hour, minute)) #&gt; # A tibble: 336,776 x 6 #&gt; year month day hour minute departure #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; #&gt; 1 2013 1 1 5 15 2013-01-01 05:15:00 #&gt; 2 2013 1 1 5 29 2013-01-01 05:29:00 #&gt; 3 2013 1 1 5 40 2013-01-01 05:40:00 #&gt; 4 2013 1 1 5 45 2013-01-01 05:45:00 #&gt; 5 2013 1 1 6 0 2013-01-01 06:00:00 #&gt; 6 2013 1 1 5 58 2013-01-01 05:58:00 #&gt; # … with 3.368e+05 more rows 因为这里没有给出分钟，所以 make_datetime() 默认其 为0. flights 数据集中的 hour 和 time 均是航班起飞时间的预计值。为了算出实际起飞、到达时间，我们需要使用dep_time和arr_time这两个变量，不过，它们同时包括了小时和分钟数： flights %&gt;% select(dep_time, arr_time, sched_dep_time, sched_arr_time) #&gt; # A tibble: 336,776 x 4 #&gt; dep_time arr_time sched_dep_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 517 830 515 819 #&gt; 2 533 850 529 830 #&gt; 3 542 923 540 850 #&gt; 4 544 1004 545 1022 #&gt; 5 554 812 600 837 #&gt; 6 554 740 558 728 #&gt; # … with 3.368e+05 more rows 为了创建出表示实际出发和到达时间的日期时间型数据，我们首先编写一个函数以使make_datetime函数适应dep_time和arr_time这种比较奇怪的表示方式，思想是使用模运算将小时成分与分钟成分分离。一旦创建了日期时间变量，我们就在本章剩余部分使用这些变量进行讨论： make_datetime_100 &lt;- function(year, month, day, time) { hour = time %/% 100 minute = time %% 100 make_datetime(year, month, day, hour, minute) } (flights_dt &lt;- flights %&gt;% filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% mutate( dep_time = make_datetime_100(year, month, day, dep_time), arr_time = make_datetime_100(year, month, day, arr_time), sched_dep_time = make_datetime_100(year, month, day, sched_dep_time), sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;% select(origin,dest,ends_with(&quot;delay&quot;), ends_with(&quot;time&quot;)) ) #&gt; # A tibble: 328,063 x 9 #&gt; origin dest dep_delay arr_delay dep_time sched_dep_time #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dttm&gt; #&gt; 1 EWR IAH 2 11 2013-01-01 05:17:00 2013-01-01 05:15:00 #&gt; 2 LGA IAH 4 20 2013-01-01 05:33:00 2013-01-01 05:29:00 #&gt; 3 JFK MIA 2 33 2013-01-01 05:42:00 2013-01-01 05:40:00 #&gt; 4 JFK BQN -1 -18 2013-01-01 05:44:00 2013-01-01 05:45:00 #&gt; 5 LGA ATL -6 -25 2013-01-01 05:54:00 2013-01-01 06:00:00 #&gt; 6 EWR ORD -4 12 2013-01-01 05:54:00 2013-01-01 05:58:00 #&gt; # … with 3.281e+05 more rows, and 3 more variables: arr_time &lt;dttm&gt;, #&gt; # sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt; 我们还可以使用这些数据做出一年间出发时间或某一天内出发时间的可视化分布（精确到分钟）。注意，当将日期时间型数据当做数值使用时（比如在直方图中），1 表示一秒，因此分箱宽度 86400 才能够表示一天。对于日期型数据(通过 make_date()创建)，1则表示一天。： ## 一年内起飞时间的分布 flights_dt %&gt;% ggplot() + geom_freqpoly(aes(x = dep_time),binwidth = 86400) ## 86000秒= 1天 ## 1月1日起飞时间的分布 flights_dt %&gt;% filter(dep_time &lt; ymd(20130102)) %&gt;% ggplot(aes(x=dep_time))+ geom_freqpoly(binwidth = 600) ## 600秒 = 10分钟 4.1.3 日期时间型和日期型数据的相互转换 有时候需要在日期时间和日期型数据之间进行转换，这正是as_datetime()和as_date()函数的功能： today() #&gt; [1] &quot;2019-12-12&quot; as_datetime(today()) #&gt; [1] &quot;2019-12-12 UTC&quot; now() #&gt; [1] &quot;2019-12-12 00:49:34 CST&quot; as_date(now()) #&gt; [1] &quot;2019-12-12&quot; 有时人们会使用距离”Unix时间戳“（即1970-01-01）的偏移量来表示日期时间。如果偏移量单位是秒，就用as_datetime()函数来转换 ； 如果偏移量单位是天，就用as_date()函数来转换： as_datetime(24 * 60 * 60) #&gt; [1] &quot;1970-01-02 UTC&quot; as_date(1) #&gt; [1] &quot;1970-01-02&quot; 4.1.4 练习 Exercise 4.1 使用恰当的 lubridate 函数来解析以下每个日期： d1 &lt;- &quot;January 1,2010&quot; mdy(d1) #&gt; [1] &quot;2010-01-01&quot; d2 &lt;- &quot;2015-Mar-07&quot; ymd(d2) #&gt; [1] &quot;2015-03-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; dmy(d3) #&gt; [1] &quot;2017-06-06&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;,&quot;July 1 (2015)&quot;) mdy(d4) #&gt; [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; d5 &lt;- &quot;12/30/14&quot; # 2014年12月30日 mdy(d5) #&gt; [1] &quot;2014-12-30&quot; 4.2 日期时间成分 现在我们知道了如何将日期时间型数据保存在 R 的相应数据结构中。接下来我们研究一下能够对这些数据进行何种处理。本节将重点关注如何获取日期时间型或者日期型数据中的成分，例如如何从一个日期中获得相应的年、月、日。 4.2.1 获取成分 如果想要提取出日其中的独立成分，可以使用以下访问器函数（accessor function）： year()、month()、mday()(一个月中的第几天)、yday()(一年中的第几天)、wday()(一周中的第几天，即星期几)、hour()、minute()、second() ： ## 创建一个日期时间型数据 datetime &lt;- ymd_hms(&quot;2016-07-08 12:34:56&quot;) year(datetime) #&gt; [1] 2016 month(datetime) #&gt; [1] 7 mday(datetime) #&gt; [1] 8 yday(datetime) #&gt; [1] 190 wday(datetime) #&gt; [1] 6 hour(datetime) #&gt; [1] 12 minute(datetime) #&gt; [1] 34 second(datetime) #&gt; [1] 56 对于wday()和month()函数，可以设置 label = T 来返回月份名称和星期数的缩写，还可以设置abbr = F来返回全名 ; 这样做还有一个重要意义，它将返回的字符串变为有序因子, 否则 ggplot2 将其作为连续型变量对待： month(datetime, label = T) #&gt; [1] Jul #&gt; 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec wday(datetime, label = T, abbr = F) #&gt; [1] Friday #&gt; 7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday 通过wday()函数，我们可以知道在工作日出发的航班要多于周末出发的航班： flights_dt %&gt;% mutate(weekday = wday(dep_time, label = T)) %&gt;% ggplot(aes(weekday)) + geom_bar() 再看一个使用minute()函数获取分钟成分的例子。比如我们想知道出发时间的分钟数与平均到达延误时间的关系： flights_dt %&gt;% mutate(minute = minute(dep_time)) %&gt;% group_by(minute) %&gt;% summarize(avg_delay = mean(arr_delay, na.rm = T)) %&gt;% ggplot(aes(minute, avg_delay))+ geom_line() 我们可以发现一个有趣的趋势，似乎在2030分钟和第5060分钟出发的航班的到达延误时间远远低于其他时间出发的航班。 4.2.2 舍入（Rouding） 另一种获取日期成分的办法是将日期时间型数据近似到一个邻近的时间单位上，这要通过 round_date()、floor_date()、ceiling_date() 等函数。这些函数的参数都包括一个待调整的日期时间型数据（可以是向量），以及希望近似到的时间单位。函数会将这个日期时间型数据舍下 floor_date()、入上ceiling_date()或者四舍五入 round_date() 到这个时间单位。例如，以下代码可以绘制出每周的航班数量： flights_dt %&gt;% mutate(week = floor_date(dep_time, &quot;week&quot;)) %&gt;% ggplot(aes(week))+ geom_bar() 下面的例子可以更深入地了解这个函数族的用法： x &lt;- ymd_hms(&quot;2009-08-03 12:01:59.23&quot;) round_date(x, &quot;.5s&quot;) #&gt; [1] &quot;2009-08-03 12:01:59 UTC&quot; round_date(x, &quot;sec&quot;) #&gt; [1] &quot;2009-08-03 12:01:59 UTC&quot; round_date(x, &quot;second&quot;) #&gt; [1] &quot;2009-08-03 12:01:59 UTC&quot; round_date(x, &quot;minute&quot;) #&gt; [1] &quot;2009-08-03 12:02:00 UTC&quot; round_date(x, &quot;5 mins&quot;) #&gt; [1] &quot;2009-08-03 12:00:00 UTC&quot; round_date(x, &quot;hour&quot;) #&gt; [1] &quot;2009-08-03 12:00:00 UTC&quot; round_date(x, &quot;2 hours&quot;) #&gt; [1] &quot;2009-08-03 12:00:00 UTC&quot; round_date(x, &quot;day&quot;) #&gt; [1] &quot;2009-08-04 UTC&quot; round_date(x, &quot;week&quot;) #&gt; [1] &quot;2009-08-02 UTC&quot; round_date(x, &quot;month&quot;) #&gt; [1] &quot;2009-08-01 UTC&quot; round_date(x, &quot;bimonth&quot;) ## 舍入到1月、3月、5月、7月、9月和11月上 #&gt; [1] &quot;2009-09-01 UTC&quot; round_date(x, &quot;quarter&quot;) == round_date(x, &quot;3 months&quot;) #&gt; [1] TRUE round_date(x, &quot;halfyear&quot;) #&gt; [1] &quot;2009-07-01 UTC&quot; round_date(x, &quot;year&quot;) #&gt; [1] &quot;2010-01-01 UTC&quot; 4.2.3 设置成分 还可以使用访问器函数来指定日期时间型数据中的成分： (datetime &lt;- ymd_hms(&quot;2016-07-08,12:34:56&quot;)) #&gt; [1] &quot;2016-07-08 12:34:56 UTC&quot; year(datetime) &lt;- 2020 month(datetime) &lt;- 11 mday(datetime) &lt;- 05 hour(datetime) &lt;- 01 datetime #&gt; [1] &quot;2020-11-05 01:34:56 UTC&quot; 除了直接修改，还可以通过update()函数来更新一个日期时间型数据，只需要在参数中指定各个成分的新值。这样也可以同时设置多个成分的更改： datetime &lt;- ymd_hms(&quot;2016-07-08,12:34:56&quot;) update(datetime,year = 2000, month = 11, mday = 05, hour = 01) #&gt; [1] &quot;2000-11-05 01:34:56 UTC&quot; 如果修改yday，相当于同时修改mday和month: datetime &lt;- ymd_hms(&quot;2016-07-08,12:34:56&quot;) update(datetime, yday = 1) #&gt; [1] &quot;2016-01-01 12:34:56 UTC&quot; update()函数还有一种比较巧妙的用法，比如我们想可视化一年中所有航班的的出发时间在一天中的分布： flights_dt %&gt;% mutate(dep_hour = update(dep_time, yday = 1)) %&gt;% ## 将所有出发时间都转为在1月1号的 ggplot(aes(x=dep_hour)) + geom_freqpoly(binwidth = 300) + ## 五分钟一个分箱 ggtitle(&quot;将日期中较大的成分设定为常数来探索其中较小成分的模式&quot;) 如果不用 update() 函数，我们可能需要先用hour()、minute()、second()获取三种成分，然后再用make_datetime()对这三种成分进行合并。 4.2.4 练习 Exercise 4.2 以月份作为分组变量，在一年的范围内，航班时间在一天中的分布是如何变化的？ flights_dt %&gt;% mutate(month = factor(month(dep_time)), dep_time = update(dep_time,yday = 1)) %&gt;% ggplot(aes(x=dep_time,color = month)) + geom_freqpoly(binwidth = 600) Exercise 1.2 如果想要再将延误的几率降至最低，那么应该在星期几搭乘航班？ flights_dt %&gt;% mutate(weekday = wday(dep_time, label = T, abbr = T)) %&gt;% group_by(weekday) %&gt;% summarize(delay_prob = mean(arr_delay &gt; 0, na.rm = T)) %&gt;% ggplot(aes(weekday,delay_prob)) + geom_line(aes(group = 1)) Exercise 4.3 航班预计起飞的小时对应的平均延误时间在一天的范围内是如何变化的？ flights_dt %&gt;% mutate(hour = hour(sched_dep_time)) %&gt;% group_by(hour) %&gt;% summarize(avg_delay = mean(dep_delay, na.rm = T)) %&gt;% ggplot(aes(hour, avg_delay))+ geom_point()+ geom_smooth() 4.3 时间间隔（Time Span） 接下来我们将讨论如何对时间进行数学运算，其中包括减法、加法和除法。我们可以把用于进行数学运算的时间称为时间间隔，它表示一种跨度，而不是某个静态的时间。本节将介绍3种用于表示时间间隔的重要类： 时期（Durations）：以秒为单位表示一段精确的时间 阶段(Periods)： 用人类单位定义的时间间隔，如几周或几个月 区间(Intervals)：由起点和终点定义的一段时间 4.3.1 时期 Durations 默认情况下，如果我们将两个日期相间，将得到一个 difftime 类对象： h_age &lt;- today() - ymd(19981112) ## 年龄 h_age #&gt; Time difference of 7700 days difftime对象的单位可以是秒、分钟、小时、日或周。这种模棱两可的对象处理起来非常困难，，所以 lubridate提供了总是以秒为单位的另一种时间间隔：时期。 as.duration(h_age) #&gt; [1] &quot;665280000s (~21.08 years)&quot; 可以用很多方便的函数来构造时期，它们有统一的格式d + 时间单位（复数）： dseconds(15) #&gt; [1] &quot;15s&quot; dminutes(10) #&gt; [1] &quot;600s (~10 minutes)&quot; dhours(c(12,24)) #&gt; [1] &quot;43200s (~12 hours)&quot; &quot;86400s (~1 days)&quot; ddays(0:5) #&gt; [1] &quot;0s&quot; &quot;86400s (~1 days)&quot; &quot;172800s (~2 days)&quot; #&gt; [4] &quot;259200s (~3 days)&quot; &quot;345600s (~4 days)&quot; &quot;432000s (~5 days)&quot; dweeks(3) ## 没有dmonths() #&gt; [1] &quot;1814400s (~3 weeks)&quot; dyears(1) #&gt; [1] &quot;31536000s (~52.14 weeks)&quot; 时期 Durations 总是以秒为单位来记录时间间隔。使用标准比率（1 分钟为 60 秒，1 小时为 60 分钟，1 天为 24 小时，1 周为 7 天，一年为 365 天）将分钟、小时、周和年转换为秒，从而建立具有更大值的对象。出于相同的原因，没有dmonths()函数, 因为一个月可能有 31 天、30 天、29 天或 28 天，所以 lubridate 不能将它转换为一个确切的秒数。 可以对时期进行加法和乘法操作： 2 * ddays(2) #&gt; [1] &quot;345600s (~4 days)&quot; dyears(1) + dweeks(12) + ddays(10) #&gt; [1] &quot;39657600s (~1.26 years)&quot; 最重要的，时期可以和日期时间型数据进行运算 ： (tomorrow &lt;- today() + ddays(1)) #&gt; [1] &quot;2019-12-13&quot; (last_year &lt;- now() - dyears(1)) #&gt; [1] &quot;2018-12-12 00:49:40 CST&quot; 然而，因为时期表示的是秒为单位的一个精确数值，有时我们会得到意想不到的结果： one_pm &lt;- ymd_hms(&quot;2016-03-12 13:00:00&quot;, tz = &quot;America/New_York&quot;) one_pm #&gt; [1] &quot;2016-03-12 13:00:00 EST&quot; one_pm + ddays(1) #&gt; [1] &quot;2016-03-13 14:00:00 EDT&quot; 为什么3月12日下午1点加上一天后变成了下午2点？如果仔细观察，就会发现时区发生了变化。因为夏时制，3月12日只有23个小时，但我们告诉R“加上24个小时代表的秒数”，所以得到了一个不正确的时间。 4.3.2 阶段 Periods 为了解决时期对象的问题，lubridate 提供了 阶段 对象。阶段也是一种 time span，但是它不以秒为单位 ； 相反，它使用“人工”时间，比如日和月。这使得阶段使用起来更加符合习惯 one_pm #&gt; [1] &quot;2016-03-12 13:00:00 EST&quot; one_pm + days(1) ## 阶段对象 #&gt; [1] &quot;2016-03-13 13:00:00 EDT&quot; one_pm + days(1)告诉 R，加上一天，而不是加上多少秒。 创建阶段对象的函数与时期很类似，只是前面少个“d”，不要把创建阶段的函数与获取时间日期成分的函数搞混了，创建 Periods 的函数都是复数形式： seconds(15) #&gt; [1] &quot;15S&quot; minutes(10) #&gt; [1] &quot;10M 0S&quot; hours(c(12,24)) #&gt; [1] &quot;12H 0M 0S&quot; &quot;24H 0M 0S&quot; days(7) #&gt; [1] &quot;7d 0H 0M 0S&quot; months(1:6) #&gt; [1] &quot;1m 0d 0H 0M 0S&quot; &quot;2m 0d 0H 0M 0S&quot; &quot;3m 0d 0H 0M 0S&quot; &quot;4m 0d 0H 0M 0S&quot; #&gt; [5] &quot;5m 0d 0H 0M 0S&quot; &quot;6m 0d 0H 0M 0S&quot; weeks(3) #&gt; [1] &quot;21d 0H 0M 0S&quot; years(1) #&gt; [1] &quot;1y 0m 0d 0H 0M 0S&quot; 可以对阶段进行加法和乘法操作： 10 * (months(6) + days(10)) #&gt; [1] &quot;60m 100d 0H 0M 0S&quot; days(50) + hours(25) + minutes(2) #&gt; [1] &quot;50d 25H 2M 0S&quot; 当然，阶段也可以和日期时间型数据进行运算。与 Durations 相比，使用 Periods 得到的计算结果更符合我们的预期： ## 闰年 ymd(&quot;2016-01-01&quot;) + dyears(1) #&gt; [1] &quot;2016-12-31&quot; ymd(&quot;2016-01-01&quot;) + years(1) #&gt; [1] &quot;2017-01-01&quot; ## 夏时制 one_pm + ddays(1) #&gt; [1] &quot;2016-03-13 14:00:00 EDT&quot; one_pm + days(1) #&gt; [1] &quot;2016-03-13 13:00:00 EDT&quot; 下面我们使用 Periods 来解决与航班日期有关的一个怪现象。有些飞机似乎从纽约市起飞前就到达了目的地： flights_dt %&gt;% filter(arr_time &lt; dep_time) %&gt;% select(arr_time, dep_time) #&gt; # A tibble: 10,633 x 2 #&gt; arr_time dep_time #&gt; &lt;dttm&gt; &lt;dttm&gt; #&gt; 1 2013-01-01 00:03:00 2013-01-01 19:29:00 #&gt; 2 2013-01-01 00:29:00 2013-01-01 19:39:00 #&gt; 3 2013-01-01 00:08:00 2013-01-01 20:58:00 #&gt; 4 2013-01-01 01:46:00 2013-01-01 21:02:00 #&gt; 5 2013-01-01 00:25:00 2013-01-01 21:08:00 #&gt; 6 2013-01-01 00:16:00 2013-01-01 21:20:00 #&gt; # … with 1.063e+04 more rows 这些都是过夜航班。我们使用了同一种日期来表示出发时间和到达时间，但这些航班是在第二天到达的。将每个过夜航班的到达时间加上一个days(1)，就可以解决这个问题了： flights_dt &lt;- flights_dt %&gt;% mutate(overnight = arr_time &lt; dep_time, arr_time = arr_time + days(overnight * 1)) ## 这样一来，航班数据就符合常理了 flights_dt %&gt;% filter(overnight, arr_time &lt; dep_time) #&gt; # A tibble: 0 x 10 #&gt; # … with 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;, #&gt; # arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, arr_time &lt;dttm&gt;, #&gt; # sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;, overnight &lt;lgl&gt; 4.3.3 区间 Intervals 显然，dyears(1)/ddays(365)应该返回1，因为时期总是以秒来表示的，表示1年的时间就定义为相当于365天的秒数。 那么years(1) / days(1)应该返回什么呢？如果年份 是 2015 年，那么结果就是 365，但如果年份是 2016 年，那么结果就是 366！没有足够的信息让 lubridate 返回一个明确的结果。lubridate 的做法是给出一个估计值，同时给出一条警告： years(1) / days(1) #&gt; [1] 365 如果需要更精确的测量方式，那么就必须使用区间。区间是带有明确起点和终点的时期，这使得它非常精确,可以用interval()来创建一个区间： interval(ymd(20090201), ymd(20090101)) #&gt; [1] 2009-02-01 UTC--2009-01-01 UTC 一种更简单的创建区间的方式是使用操作符%--% next_year &lt;- today() + years(1) today() %--% next_year #&gt; [1] 2019-12-12 UTC--2020-12-12 UTC 要想知道一个区间内有多少个阶段，需要使用整数除法。利用区间进行精确计算： ## 闰年 (ymd(20160101) %--% ymd(20170101)) / days(1) #&gt; [1] 366 ## 平年 (ymd(20170101) %--% ymd(20180101)) / days(1) #&gt; [1] 365 4.3.4 小结 如何在时期、阶段和区间中进行选择呢？只要能够解决问题，我们就应该选择最简单的数据结构。如果只关心物理时间，那么就使用时期 Durations ； 如果还需要考虑人工时间，那么就使用阶段 Periods ； 如果需要找出人工时间范围内有多长的时间间隔，那么就使用区间。 下图总结了不同数据类型之间可以进行的数学运算： 4.3.5 练习 Exercise 4.4 创建一个日期向量来给出 2015 年每个月的第一天 ymd(20150101) + months(0:11) #&gt; [1] &quot;2015-01-01&quot; &quot;2015-02-01&quot; &quot;2015-03-01&quot; &quot;2015-04-01&quot; &quot;2015-05-01&quot; #&gt; [6] &quot;2015-06-01&quot; &quot;2015-07-01&quot; &quot;2015-08-01&quot; &quot;2015-09-01&quot; &quot;2015-10-01&quot; #&gt; [11] &quot;2015-11-01&quot; &quot;2015-12-01&quot; ## To get the vector of the first day of the month for this year, we first need to figure out what this year is, and get January 1st of it floor_date(today(),&quot;year&quot;) + months(0:11) #&gt; [1] &quot;2019-01-01&quot; &quot;2019-02-01&quot; &quot;2019-03-01&quot; &quot;2019-04-01&quot; &quot;2019-05-01&quot; #&gt; [6] &quot;2019-06-01&quot; &quot;2019-07-01&quot; &quot;2019-08-01&quot; &quot;2019-09-01&quot; &quot;2019-10-01&quot; #&gt; [11] &quot;2019-11-01&quot; &quot;2019-12-01&quot; Exercise 4.5 编写一个函数，输入你的生日（日期型），返回你的年龄（以年为单位）： age &lt;- function(birth) { birth &lt;- ymd(birth) (birth %--% today()) %/% years(1) } age(&quot;19981112&quot;) #&gt; [1] 21 "],
["forcats.html", "5 forcats 5.1 简介 5.2 排序 5.3 改变水平个数 5.4 编码 5.5 合并因子", " 5 forcats 5.1 简介 因子(factor)在 R 中用于处理分类变量。从历史上看，因子远比字符串容易处理。因此，R基础包的很多函数都自动将字符串转换为因子。这意味着因子经常出现在并不真正适合他们的地方。好在我们不用担心tidyverse中出现这种问题，可以将注意力集中于真正需要因子类型的地方。 Roger Peng的文章\"stringsAsFactors: An unauthorized bigraphy和Thomas Lumley的文章stringsAsFactors = sigh介绍了有关因子和字符串的一些历史背景。 2006 年, stringsAsFactors 这一设置的前身 charToFactor 被引入了 data.frame() 函数中，后来被纳入到 read.table() 里。默认情况下，stringsAsFactors被设置为True，R便会自动把字符串转换为因子型变量。在当时，这种设置是不难理解的。早期R的用户几乎都是统计科班出身的研究者，他们所用数据集里的字符串几乎都代表了一个定性变量，例如年龄(male/female),国家(US/other)，地区(East/West)。进一步地，由于统计学家们的工作重点几乎都集中在构建各种统计模型上，而像lm()和glm()的函数只有当一个变量是 factor 类型的时候才开始对其编码，在统计模型中构建虚拟变量。 另一个原因更隐秘一些。在内部的存储机制中，因子变量经过一些编码后用数值存储，使得因子比字符串在占用内存空间上更加划算。2007 年后，R 引入了一种“CHARSXP”的方法，使得字符串也被映射为数值存储，stringsAsFactors = T在这点上的优势便不复存在了。 如今，R 的用户群体大大地多样化了，许多人开始抱怨默认设置stringsAsFactors = T，因为他们数据集中的字符串未必要用来建模，而可能只是一种标签。例如，在基因组学中，基因位点的名字不是某个模型中的变量，而现在把它们转换为因子也不会再有存储上的优势，反而会使得一些分析方法失效（比如使用正则表达式）。 我们将使用forcats包来处理因子，这个包提供了能够处理分类变量（其实就是因子的另一种说法）的工具，其中还包括了处理因子的大量辅助函数。因为 forcats 不是tidyverse的核心 R 包，所以需要手动加载。 library(forcats) 所有 forcats 中用于因子处理的核心函数均以 fct_ 前缀开头，且第一个参数均为要处理的因子向量，这意味着forcats包中的函数在使用管道操作时，传入的必须是你要操作的向量。关于 fct_ 函数族最有用的一点是，它可以接受传入的向量是字符串变量（而不仅仅是因子类型），且不会在输出结果中改变变量的类型。这意味着字符串可以一方面享受 fct_ 函数带来的操作便利，一方面保有字符串的特性。 5.1.1 因子基础 假设我们想要创建一个记录月份的变量： x1 &lt;- c(&quot;Dec&quot;, &quot;Apr&quot;, &quot;Jan&quot;, &quot;Mar&quot;) 使用字符串来记录月份有两个问题： 理论上，月份只有12个取值。但使用字符串时，我们没有办法告诉 R 什么样的值才是合法的，即使输入错误，代码也不会有什么反应。 x2 &lt;- c(&quot;Dec&quot;, &quot;Apr&quot;, &quot;Jam&quot;, &quot;Mar&quot;) 对月份的排序没有意义，因为字符串总是按照字母顺序排列的 sort(x1) #&gt; [1] &quot;Apr&quot; &quot;Dec&quot; &quot;Jan&quot; &quot;Mar&quot; 我们可以使用因子来解决以上两个问题。想要创建一个因子，最好先创建指定因子水平顺序的一个向量： month_levels &lt;- c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;) 现在可以开始创建因子了： y1 &lt;- factor(x1, levels = month_levels) y1 #&gt; [1] Dec Apr Jan Mar #&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 使用因子类型后，不在有效水平向量内的的所有值都会自动转换 为NA： y2 &lt;- factor(x2, levels = month_levels) y2 #&gt; [1] Dec Apr &lt;NA&gt; Mar #&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 如果要显示错误信息，可以用readr::parse_factor()函数代替 R 基础包中的factor(),当向量x的中的某些元素不在有效水平列表时返回错误信息： y2 &lt;- parse_factor(x2, levels = month_levels) 如果省略了定义水平向量这个步骤，那么R会按照字母顺序作为水平由低到高的顺序： factor(x1) #&gt; [1] Dec Apr Jan Mar #&gt; Levels: Apr Dec Jan Mar 有时候我们会想让因子的水平顺序与创建时输入的顺序保持一致。在创建因子时，将levels设定为unique(x)，就可以达到这个目的： x1 #&gt; [1] &quot;Dec&quot; &quot;Apr&quot; &quot;Jan&quot; &quot;Mar&quot; f1 &lt;- factor(x1, levels = unique(x1)) f1 #&gt; [1] Dec Apr Jan Mar #&gt; Levels: Dec Apr Jan Mar 如果想要直接访问因子的有效水平向量或者个数，可以使用levels()和nlevels()函数： levels(f1) #&gt; [1] &quot;Dec&quot; &quot;Apr&quot; &quot;Jan&quot; &quot;Mar&quot; nlevels(f1) #&gt; [1] 4 5.2 排序 5.2.1 按照水平的频次排序 fct_infreq() 函数根据在数据集中出现的频次对因子的不同水平进行排序。 starwars数据集是对剧中角色信息的一些整理，假设我们想知道全部角色中最常见的发色是什么，可能会做出类似如下的条形图： starwars #&gt; # A tibble: 87 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender homeworld #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Luke… 172 77 blond fair blue 19 male Tatooine #&gt; 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; Tatooine #&gt; 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; Naboo #&gt; 4 Dart… 202 136 none white yellow 41.9 male Tatooine #&gt; 5 Leia… 150 49 brown light brown 19 female Alderaan #&gt; 6 Owen… 178 120 brown, gr… light blue 52 male Tatooine #&gt; # … with 81 more rows, and 4 more variables: species &lt;chr&gt;, films &lt;list&gt;, #&gt; # vehicles &lt;list&gt;, starships &lt;list&gt; ggplot(starwars, aes(hair_color)) + geom_bar()+ coord_flip() 对于这种条形图的常见调整是让因子的水平按照其在数据中出现的频次排列，fct_infreq()函数可以很轻松地完成这一任务(缺失值总会被排在最后)： ggplot(starwars,aes(fct_infreq(hair_color))) + geom_bar()+ coord_flip() 如果返回starwars数据集，你会发现hair_color其实是字符串变量，但是完全适用于fct_infreq()的操作。 5.2.2 按照其他变量排序 fct_reorder() 其实就是 reorder() 在 forcats 中的实现，它根据因子在其他变量上的统计量（中位数、平均数、···）的值对个水平进行排序，当绘制非频次条形图(stat = \"identity\")时它便很有用。 我们可以通过 fun 设定统计函数（默认为 median()），desc = T 设定降序排列（默认升序）： ## 对发色分组，计算身高的中位数 (avg_height &lt;- starwars %&gt;% group_by(hair_color) %&gt;% summarize(avg_height = mean(height))) #&gt; # A tibble: 13 x 2 #&gt; hair_color avg_height #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 auburn 150 #&gt; 2 auburn, grey 180 #&gt; 3 auburn, white 182 #&gt; 4 black NA #&gt; 5 blond 177. #&gt; 6 blonde 168 #&gt; # … with 7 more rows ggplot(avg_height,aes(x=hair_color,y=avg_height))+ geom_bar(aes(hair_color, avg_height), stat=&quot;identity&quot;) ggplot(avg_height,aes(fct_reorder(hair_color, avg_height), avg_height))+ geom_bar(stat=&quot;identity&quot;) 5.2.3 人工指定顺序 fct_infreq()和fct_reorder()排序的依据是明确的，但我们有时也需要人工指定、修改排序结果。fct_relevel()接受一个向量调整因子水平的排序。 这个例子中使用forcats::gss_cat数据集，该数据集是综合社会调查（General Social Survey）的一份抽样。综合社会调查是美国芝加哥大学的独立研究组织 NORC 进行的一项长期美国社会调查。gss_cat数据挑选了一些变量： gss_cat #&gt; # A tibble: 21,483 x 9 #&gt; year marital age race rincome partyid relig denom tvhours #&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 2000 Never mar… 26 White $8000 to … Ind,near r… Protesta… Souther… 12 #&gt; 2 2000 Divorced 48 White $8000 to … Not str re… Protesta… Baptist… NA #&gt; 3 2000 Widowed 67 White Not appli… Independent Protesta… No deno… 2 #&gt; 4 2000 Never mar… 39 White Not appli… Ind,near r… Orthodox… Not app… 4 #&gt; 5 2000 Divorced 25 White Not appli… Not str de… None Not app… 1 #&gt; 6 2000 Married 25 White $20000 - … Strong dem… Protesta… Souther… NA #&gt; # … with 2.148e+04 more rows levels(gss_cat$rincome) #&gt; [1] &quot;No answer&quot; &quot;Don&#39;t know&quot; &quot;Refused&quot; &quot;$25000 or more&quot; #&gt; [5] &quot;$20000 - 24999&quot; &quot;$15000 - 19999&quot; &quot;$10000 - 14999&quot; &quot;$8000 to 9999&quot; #&gt; [9] &quot;$7000 to 7999&quot; &quot;$6000 to 6999&quot; &quot;$5000 to 5999&quot; &quot;$4000 to 4999&quot; #&gt; [13] &quot;$3000 to 3999&quot; &quot;$1000 to 2999&quot; &quot;Lt $1000&quot; &quot;Not applicable&quot; 在这个数据集中，因子rincome个水平的顺序排列是正确的。为了演示fct_relevel()的用法，先用fct_shuffle()打乱该因子的水平顺序： reshuffled_income &lt;- fct_shuffle(gss_cat$rincome) ## reordering the levels of rincome randomly with fct_shuffle(): levels(reshuffled_income) #&gt; [1] &quot;$7000 to 7999&quot; &quot;Lt $1000&quot; &quot;$15000 - 19999&quot; &quot;$6000 to 6999&quot; #&gt; [5] &quot;$5000 to 5999&quot; &quot;$10000 - 14999&quot; &quot;$8000 to 9999&quot; &quot;$25000 or more&quot; #&gt; [9] &quot;$20000 - 24999&quot; &quot;$1000 to 2999&quot; &quot;Don&#39;t know&quot; &quot;$4000 to 4999&quot; #&gt; [13] &quot;No answer&quot; &quot;$3000 to 3999&quot; &quot;Not applicable&quot; &quot;Refused&quot; 在fct_relevel() 中，通过一个包含水平名称的向量调整排序。默认情况下，向量中的第一个水平被调整到第一个位置上，第二个水平被调整到第二个位置上，以此类推，你只需要指定那些需要调整的水平。可以通过after参数人工指定向量中各水平被调整到什么地方, after = -Inf 时第一个水平将被调整到排序的最后一位： ## move Lt $1000 and $1000 to 2999 to the front fct_relevel(reshuffled_income, c(&quot;Lt $1000&quot;, &quot;$1000 to 2999&quot;)) %&gt;% levels() #&gt; [1] &quot;Lt $1000&quot; &quot;$1000 to 2999&quot; &quot;$7000 to 7999&quot; &quot;$15000 - 19999&quot; #&gt; [5] &quot;$6000 to 6999&quot; &quot;$5000 to 5999&quot; &quot;$10000 - 14999&quot; &quot;$8000 to 9999&quot; #&gt; [9] &quot;$25000 or more&quot; &quot;$20000 - 24999&quot; &quot;Don&#39;t know&quot; &quot;$4000 to 4999&quot; #&gt; [13] &quot;No answer&quot; &quot;$3000 to 3999&quot; &quot;Not applicable&quot; &quot;Refused&quot; ## move Lt $1000 and $1000 to 2999 to the second and third place fct_relevel(reshuffled_income, c(&quot;Lt $1000&quot;, &quot;$1000 to 2999&quot;), after = 1) %&gt;% levels() #&gt; [1] &quot;$7000 to 7999&quot; &quot;Lt $1000&quot; &quot;$1000 to 2999&quot; &quot;$15000 - 19999&quot; #&gt; [5] &quot;$6000 to 6999&quot; &quot;$5000 to 5999&quot; &quot;$10000 - 14999&quot; &quot;$8000 to 9999&quot; #&gt; [9] &quot;$25000 or more&quot; &quot;$20000 - 24999&quot; &quot;Don&#39;t know&quot; &quot;$4000 to 4999&quot; #&gt; [13] &quot;No answer&quot; &quot;$3000 to 3999&quot; &quot;Not applicable&quot; &quot;Refused&quot; 5.3 改变水平个数 5.3.1 合并水平 forcats包提供了fct_count()函数可以很方便地查看因子各水平分布的情况，使用count()函数也可以达到同样的效果 fct_count(starwars$skin_color, sort = T) #&gt; # A tibble: 31 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 fair 17 #&gt; 2 light 11 #&gt; 3 dark 6 #&gt; 4 green 6 #&gt; 5 grey 6 #&gt; 6 pale 5 #&gt; # … with 25 more rows 因子skin_color总共有31个水平，但绝大部分的频次都集中在前5、6个水平上，这时候我们可能想把余下的水平合并为一个水平，即创建一个“其他”水平。 fct_lump(f,n,prop)函数用于合并因子中那些低频次的水平，参数n和prop采用不同的表示方法，指定哪些变量保留下来（被合并）: ## 留下频次最高的前5个水平，剩下全部水平合并为1个 starwars %&gt;% mutate(skin_color = fct_lump(skin_color, n = 5)) %&gt;% count(skin_color, sort = TRUE) #&gt; # A tibble: 6 x 2 #&gt; skin_color n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Other 41 #&gt; 2 fair 17 #&gt; 3 light 11 #&gt; 4 dark 6 #&gt; 5 green 6 #&gt; 6 grey 6 ## 频次不足样本数10%的被合并 starwars %&gt;% mutate(skin_color = fct_lump(skin_color, prop = 0.1)) %&gt;% count(skin_color, sort = TRUE) #&gt; # A tibble: 3 x 2 #&gt; skin_color n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Other 59 #&gt; 2 fair 17 #&gt; 3 light 11 默认情况下，合并生成的新水平被命名为“Other”，可以通过other_level参数为其设定一个名字： ## 将合并水平命名为“extra” starwars %&gt;% mutate(skin_color = fct_lump(skin_color, prop=0.1, other_level = &quot;extra&quot;)) %&gt;% count(skin_color, sort = TRUE) #&gt; # A tibble: 3 x 2 #&gt; skin_color n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 extra 59 #&gt; 2 fair 17 #&gt; 3 light 11 如果给参数n或者prop指定一个复数，则频数最多的水平将被合并： ## 留下频次最低的5个水平 starwars %&gt;% mutate(skin_color = fct_lump(skin_color, n = -5)) %&gt;% count(skin_color, sort = T) #&gt; # A tibble: 17 x 2 #&gt; skin_color n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Other 71 #&gt; 2 brown mottle 1 #&gt; 3 brown, white 1 #&gt; 4 fair, green, yellow 1 #&gt; 5 gold 1 #&gt; 6 green-tan, brown 1 #&gt; # … with 11 more rows ## 占据频数超过90%的水平被合并为other starwars %&gt;% mutate(skin_color = fct_lump(skin_color, prop = -0.1)) %&gt;% count(skin_color, sort = T) #&gt; # A tibble: 30 x 2 #&gt; skin_color n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Other 28 #&gt; 2 dark 6 #&gt; 3 green 6 #&gt; 4 grey 6 #&gt; 5 pale 5 #&gt; 6 brown 4 #&gt; # … with 24 more rows 如果想人为地对水平进行合并，而不考虑频次，可以使用fct_other(f,keep,drop,other_level = \"Other)函数，keep指定保留水平，drop指定合并水平： x &lt;- factor(rep(LETTERS[1:9], times = c(40, 10, 5, 27, 1, 1, 1, 1, 1))) fct_count(x,sort=T) #&gt; # A tibble: 9 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 A 40 #&gt; 2 D 27 #&gt; 3 B 10 #&gt; 4 C 5 #&gt; 5 E 1 #&gt; 6 F 1 #&gt; # … with 3 more rows fct_other(x, keep = c(&quot;A&quot;, &quot;B&quot;)) #&gt; [1] A A A A A A A A A A A A #&gt; [13] A A A A A A A A A A A A #&gt; [25] A A A A A A A A A A A A #&gt; [37] A A A A B B B B B B B B #&gt; [49] B B Other Other Other Other Other Other Other Other Other Other #&gt; [61] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [73] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [85] Other Other Other #&gt; Levels: A B Other fct_other(x, drop = c(&quot;A&quot;, &quot;B&quot;)) #&gt; [1] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [13] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [25] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [37] Other Other Other Other Other Other Other Other Other Other Other Other #&gt; [49] Other Other C C C C C D D D D D #&gt; [61] D D D D D D D D D D D D #&gt; [73] D D D D D D D D D D E F #&gt; [85] G H I #&gt; Levels: C D E F G H I Other 5.3.2 增加水平 fct_expand()函数用于对因子添加水平： ## 在abc三个字母中，放回抽样20次 f &lt;- factor(sample(letters[1:3], 20 , replace = T)) fct_count(f) #&gt; # A tibble: 3 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 a 10 #&gt; 2 b 6 #&gt; 3 c 4 ## 添加三个水平 f &lt;- fct_expand(f, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;) ## 新添加的水平频次为0 fct_count(f) #&gt; # A tibble: 6 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 a 10 #&gt; 2 b 6 #&gt; 3 c 4 #&gt; 4 d 0 #&gt; 5 e 0 #&gt; 6 f 0 5.3.3 舍弃水平(Dropping unused levels) 有时候我们希望在数据中取出一个子集，这可能导致在子集中，因子在某些水平上的频次为0，但R并不会自动舍弃舍弃频次为0的水平： ## 在原始数据汇总，hair_color共有12个水平 nlevels(factor(starwars$hair_color)) #&gt; [1] 12 fct_count(starwars$hair_color) #&gt; # A tibble: 13 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 auburn 1 #&gt; 2 auburn, grey 1 #&gt; 3 auburn, white 1 #&gt; 4 black 13 #&gt; 5 blond 3 #&gt; 6 blonde 1 #&gt; # … with 7 more rows ## 筛选重量在70~135的角色，得到一个子集 (starwars_sub &lt;- starwars %&gt;% filter(between(mass, 70, 135))) #&gt; # A tibble: 34 x 13 #&gt; name height mass hair_color skin_color eye_color birth_year gender homeworld #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Luke… 172 77 blond fair blue 19 male Tatooine #&gt; 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; Tatooine #&gt; 3 Owen… 178 120 brown, gr… light blue 52 male Tatooine #&gt; 4 Beru… 165 75 brown light blue 47 female Tatooine #&gt; 5 Bigg… 183 84 black light brown 24 male Tatooine #&gt; 6 Obi-… 182 77 auburn, w… fair blue-gray 57 male Stewjon #&gt; # … with 28 more rows, and 4 more variables: species &lt;chr&gt;, films &lt;list&gt;, #&gt; # vehicles &lt;list&gt;, starships &lt;list&gt; ## 现在hair_color只在8个有效水平上有记录，但是总的水平个数没有改变 nlevels(factor(starwars$hair_color)) #&gt; [1] 12 fct_count(starwars_sub$hair_color) #&gt; # A tibble: 9 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 auburn, white 1 #&gt; 2 black 5 #&gt; 3 blond 2 #&gt; 4 brown 7 #&gt; 5 brown, grey 1 #&gt; 6 grey 1 #&gt; # … with 3 more rows ## 用fct_drop()舍弃频次为0的那些水平 starwars_sub$hair_color %&gt;% fct_drop() %&gt;% nlevels() #&gt; [1] 8 还可以通过给only参数指定一个向量指定想要丢弃的水平，只有频次为0且包含在该向量中的水平才会被丢弃： f &lt;- factor(c(&quot;a&quot;, &quot;b&quot;), levels = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) fct_drop(f) #&gt; [1] a b #&gt; Levels: a b # Set only to restrict which levels to drop fct_drop(f, only = &quot;a&quot;) ## a水平上有频次，不会被丢弃；c水平上没有频次，但不在only中，也不会被丢弃 #&gt; [1] a b #&gt; Levels: a b c fct_drop(f, only = &quot;c&quot;) #&gt; [1] a b #&gt; Levels: a b 5.4 编码 比修改因子水平顺序、改变水平个数更强大的操作时修改水平的值。修改水平的值不仅可以使图形标签更为美观清晰，以满足出版发行的要求，还可以将水平汇集成更高层次的显示。修改水平最常用、最强大的工具是fct_recode()函数，它可以对每个水平进行修改或重新编码。例如，我们来看一下综合社会调查数据中的因子变量partyid: fct_count(gss_cat$partyid) #&gt; # A tibble: 10 x 2 #&gt; f n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 No answer 154 #&gt; 2 Don&#39;t know 1 #&gt; 3 Other party 393 #&gt; 4 Strong republican 2314 #&gt; 5 Not str republican 3032 #&gt; 6 Ind,near rep 1791 #&gt; # … with 4 more rows 在这个因子中，对水平的描述太过简单，而且不一致，我们用fct_recode()将其修改为较为详细的排比结构，格式为fct_recode(f,level_new = level_old): gss_cat %&gt;% mutate(partyid = fct_recode(partyid, &quot;Republican,strong&quot; = &quot;Strong republican&quot;, &quot;Republican weak&quot; = &quot;Not str republican&quot;, &quot;Independent,near rep&quot; =&quot;Ind,near rep&quot;, &quot;Independent,near dem&quot; = &quot;Ind,near dem&quot;, &quot;Democrat,weak&quot; = &quot;Not str democrat&quot;, &quot;Democrat,strong&quot; = &quot;Strong democrat&quot;)) %&gt;% count(partyid) #&gt; # A tibble: 10 x 2 #&gt; partyid n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 No answer 154 #&gt; 2 Don&#39;t know 1 #&gt; 3 Other party 393 #&gt; 4 Republican,strong 2314 #&gt; 5 Republican weak 3032 #&gt; 6 Independent,near rep 1791 #&gt; # … with 4 more rows fct_recode()函数会让没有明确提及的水平保持原样，如果不小心修改了一个不存在的水平，那么它也会给出警告。 可以将多个原水平赋给同一个新水平，这样就可以合并原来的分类，有点类似于人工指定该合并哪些水平的fct_lump()函数： ## 将&quot;no answer&quot;、&quot;Don&#39;t know&quot;和&quot;Other party&quot;合并为&quot;Other&quot; gss_cat %&gt;% mutate(partyid_recode = fct_recode( partyid, &quot;Republican,strong&quot; = &quot;Strong republican&quot;, &quot;Republican weak&quot; = &quot;Not str republican&quot;, &quot;Independent,near rep&quot; =&quot;Ind,near rep&quot;, &quot;Independent,near dem&quot; = &quot;Ind,near dem&quot;, &quot;Democrat,weak&quot; = &quot;Not str democrat&quot;, &quot;Democrat,strong&quot; = &quot;Strong democrat&quot;, &quot;Other&quot; = &quot;No answer&quot;, &quot;Other&quot; = &quot;Don&#39;t know&quot;, &quot;Other&quot; = &quot;Other party&quot; )) %&gt;% count(partyid_recode) #&gt; # A tibble: 8 x 2 #&gt; partyid_recode n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Other 548 #&gt; 2 Republican,strong 2314 #&gt; 3 Republican weak 3032 #&gt; 4 Independent,near rep 1791 #&gt; 5 Independent 4119 #&gt; 6 Independent,near dem 2499 #&gt; # … with 2 more rows 如果想要合并多个水平，那么可以使用fct_recode()函数的变体fct_collapse()函数。对于每个新水平，你都可以提供一个包含原水平的向量： gss_cat %&gt;% mutate(partyid = fct_collapse(partyid, other = c(&quot;No answer&quot;,&quot;Don&#39;t know&quot;,&quot;Other party&quot;), rep = c(&quot;Strong republican&quot;,&quot;Not str republican&quot;), ind = c(&quot;Ind,near rep&quot;,&quot;Independent&quot;,&quot;Ind,near dem&quot;), dem = c(&quot;Not str democrat&quot;,&quot;Strong democrat&quot;))) %&gt;% count(partyid) #&gt; # A tibble: 4 x 2 #&gt; partyid n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 other 548 #&gt; 2 rep 5346 #&gt; 3 ind 8409 #&gt; 4 dem 7180 5.4.1 练习： 美国民主党，共和党和中间派的人数是如何随时间变化的？ gss_cat_collapse &lt;- gss_cat %&gt;% mutate(partyid = fct_collapse(partyid, other = c(&quot;No answer&quot;,&quot;Don&#39;t know&quot;,&quot;Other party&quot;), rep = c(&quot;Strong republican&quot;,&quot;Not str republican&quot;), ind = c(&quot;Ind,near rep&quot;,&quot;Independent&quot;,&quot;Ind,near dem&quot;), dem = c(&quot;Not str democrat&quot;,&quot;Strong democrat&quot;))) gss_cat_collapse %&gt;% group_by(year) %&gt;% count(partyid) %&gt;% ggplot(aes(year,n,color = partyid))+ geom_line()+ geom_point(size = 2, shape= 1) 5.5 合并因子 fct_c() 函数用于将因子合并，使用gapminder::gapminder数据，首先创建两个子集： library(gapminder) gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; # … with 1,698 more rows df1 &lt;- gapminder %&gt;% filter(country %in% c(&quot;United States&quot;, &quot;Mexico&quot;), year &gt; 2000) df2 &lt;- gapminder %&gt;% filter(country %in% c(&quot;France&quot;, &quot;Germany&quot;), year &gt; 2000) 舍弃country中频次为 0 的水平： df1$country &lt;- fct_drop(df1$country) df2$country &lt;- fct_drop(df2$country) levels(df1$country) #&gt; [1] &quot;Mexico&quot; &quot;United States&quot; levels(df2$country) #&gt; [1] &quot;France&quot; &quot;Germany&quot; 用fct_c()将两个数据集中不同的因子country拼接起来 fct_c(df1$country, df2$country) #&gt; [1] Mexico Mexico United States United States France #&gt; [6] France Germany Germany #&gt; Levels: Mexico United States France Germany "],
["tidyr.html", "6 tidyr 6.1 简介 6.2 spread()和gather() 6.3 separate()和untie() 6.4 缺失值 6.5 Case Study 6.6 拓展：None-tidy data 6.7 tidyr 1.0.0", " 6 tidyr 6.1 简介 “Happy families are all alike; every unhappy family is unhappy in its own way.” –– Leo Tolstoy “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham 整洁的数据(Tidy data)是进行数据操作和 ggplot2 可视化的基础，所谓数据整理（清洗、清理），就是把 messy data 转换为 tidy data 的过程。在 tidyverse 生态中，tidyr 便负责数据的整理和变型： 如果一个数据集是整洁的，需要满足以下三个要素： 1. 每个变量有一个专属列(Each variable must have its own column) 2. 每个观测有一个专属行(Each observation must have its own row) 3. 每个值必须都有一个专属的存储单元(Each value must its own cell) 这三条规则是互相关联的，你不可能只满足三条规则中的两条，所以我们可以更简化地把清洁数据的要求写成： 1. 每列是一个变量(Variables go in columns) 2. 每行是一个观测(Observatiosn go in rows) 同样的数据可以有不同的表现形式，但只有满足整洁数据的三个条件的数据集才是最容易使用的，这也是。以下的3个数据集背后的均来自1999年和2000年世界卫生组织在阿富汗、巴西和中国的一次肺结核病例调查，都有country、year、cases和population四个变量，但采用了不同的组织方式: table1 #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 table2 #&gt; # A tibble: 12 x 4 #&gt; country year type count #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 1999 population 19987071 #&gt; 3 Afghanistan 2000 cases 2666 #&gt; 4 Afghanistan 2000 population 20595360 #&gt; 5 Brazil 1999 cases 37737 #&gt; 6 Brazil 1999 population 172006362 #&gt; # … with 6 more rows table3 #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745/19987071 #&gt; 2 Afghanistan 2000 2666/20595360 #&gt; 3 Brazil 1999 37737/172006362 #&gt; 4 Brazil 2000 80488/174504898 #&gt; 5 China 1999 212258/1272915272 #&gt; 6 China 2000 213766/1280428583 table4a和table4b分别是以 cases 和 population 为值的数据透视表： table4a #&gt; # A tibble: 3 x 3 #&gt; country `1999` `2000` #&gt; * &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 745 2666 #&gt; 2 Brazil 37737 80488 #&gt; 3 China 212258 213766 table4b #&gt; # A tibble: 3 x 3 #&gt; country `1999` `2000` #&gt; * &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 19987071 20595360 #&gt; 2 Brazil 172006362 174504898 #&gt; 3 China 1272915272 1280428583 在上面的例子中，只有table1 符合清洁数据的标准。在table2 中，type不是一个变量，它的值 cases 和 population 才是变量，进而导致了每一行不是一个完整的观测。在 table3 中，rate 同样不是一个变量，cases 和 population 的值被挤在了一个单元里。至于 table4a 和table4b，1999 和 2000不是变量，而是一个表示年份的变量的值。 为什么要为获得清洁的数据如此大费周折呢？主要有两个优点： 清洁数据的规则使得我们可以遵从一个一致、明确的结构存储数据。学习处理这些数据的工具变得很容易，因为你的对象在底层是一致的。 把变量存储在列中可以把R的向量化函数优势发挥到极致。我们已经学过 mutate() 和 summarize() 函数，许多内置的 R 函数都是对向量进行操作的。只要有了清洁的数据，后面的数据变换工作就很容易： # Compute rate per 10,000 table1 %&gt;% mutate(rate = cases / population * 10000) #&gt; # A tibble: 6 x 5 #&gt; country year cases population rate #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1999 745 19987071 0.373 #&gt; 2 Afghanistan 2000 2666 20595360 1.29 #&gt; 3 Brazil 1999 37737 172006362 2.19 #&gt; 4 Brazil 2000 80488 174504898 4.61 #&gt; 5 China 1999 212258 1272915272 1.67 #&gt; 6 China 2000 213766 1280428583 1.67 # Compute cases per year table1 %&gt;% group_by(year) %&gt;% summarize(cases = sum(cases)) #&gt; # A tibble: 2 x 2 #&gt; year cases #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1999 250740 #&gt; 2 2000 296920 # 或者： table1 %&gt;% count(year, wt = cases) #&gt; # A tibble: 2 x 2 #&gt; year n #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1999 250740 #&gt; 2 2000 296920 # Visualise changes over time library(ggplot2) ggplot(table1, aes(year, cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country))+ scale_x_continuous(breaks = c(1999,2000),labels = c(&quot;1999&quot;,&quot;2000&quot;)) 6.1.1 练习 用table2计算rate(\\(\\frac{cases}{population}\\))。提示：需要进行以下四步操作： 得到每个国家每年的cases 得到每个国家每年的population 计算rate = cases / population 把算好的数据存储到正确的位置 首先，分别对cases和population建立一张表，并且确保两张表的排列顺序相同： table2 #&gt; # A tibble: 12 x 4 #&gt; country year type count #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 1999 population 19987071 #&gt; 3 Afghanistan 2000 cases 2666 #&gt; 4 Afghanistan 2000 population 20595360 #&gt; 5 Brazil 1999 cases 37737 #&gt; 6 Brazil 1999 population 172006362 #&gt; # … with 6 more rows (t2_cases &lt;- filter(table2, type == &quot;cases&quot;) %&gt;% rename(cases = count) %&gt;% arrange(country, year)) #&gt; # A tibble: 6 x 4 #&gt; country year type cases #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 2000 cases 2666 #&gt; 3 Brazil 1999 cases 37737 #&gt; 4 Brazil 2000 cases 80488 #&gt; 5 China 1999 cases 212258 #&gt; 6 China 2000 cases 213766 (t2_population &lt;- filter(table2, type == &quot;population&quot;) %&gt;% rename(population = count) %&gt;% arrange(country, year)) #&gt; # A tibble: 6 x 4 #&gt; country year type population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 population 19987071 #&gt; 2 Afghanistan 2000 population 20595360 #&gt; 3 Brazil 1999 population 172006362 #&gt; 4 Brazil 2000 population 174504898 #&gt; 5 China 1999 population 1272915272 #&gt; 6 China 2000 population 1280428583 计算rate t2_cases_per_cap &lt;- tibble( t2_cases$country, t2_cases$year, cases = t2_cases$cases, population = t2_population$population ) t2_cases_per_cap #&gt; # A tibble: 6 x 4 #&gt; `t2_cases$country` `t2_cases$year` cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 t2_cases_per_cap %&gt;% mutate(rate = cases/population) %&gt;% select(1,2,5) %&gt;% ## 改变列名 mutate( country = t2_cases$country, year = t2_cases$year ) %&gt;% select(country,year,rate) #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1999 0.0000373 #&gt; 2 Afghanistan 2000 0.000129 #&gt; 3 Brazil 1999 0.000219 #&gt; 4 Brazil 2000 0.000461 #&gt; 5 China 1999 0.000167 #&gt; 6 China 2000 0.000167 6.2 spread()和gather() 请看下面的两张表格： 细看两表，不难发现它们实质上相同的数据(第二张表是以x为行字段，y为列字段，z为值的数据透视表)。第一种形式成为长数据(long data,indexed data，指标型数据)，在长数据（指标型）数据汇总，你需要看指标来找到需要变量的数值（变量x，y，z的值）。第二种称为宽数据(wide data,Cartesian data,笛卡尔型数据)，需要看行和列的交叉点来找到对应的值。我们不能简单的说哪一种格式梗优，因为两种形式都有可能是整洁的，这取决于值“A”、“B”、“C”、“D”的含义。 注意到上面的确实值：在一种形式下显示存在的缺失值在另一种格式下不一定能直接看得出来。NA代表了一种缺失情况，但有时数值确实单纯是因为那里没有值。（而不是因为记录失误，没有获取到等原因） 数据整理常需要化宽为长，称为聚集(gathering)，但偶尔也需要化长为宽，称为扩散(spreading)。tidyr包分别提供了gather()和spread()函数来实现以上操作。 6.2.1 gather() gather()函数用来处理messy data 的一个常见症状：部分列名不是变量的名子，而是变量的值(some of the column names are not names of variables, but values of a variale)，或者说一行中有多个观测。例如，在table4a中，1999和2000不是某个变量的名字，而是一个表示年份的变量的不同取值： table4a #&gt; # A tibble: 3 x 3 #&gt; country `1999` `2000` #&gt; * &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 745 2666 #&gt; 2 Brazil 37737 80488 #&gt; 3 China 212258 213766 可以将之与清洁数据table1相比对，不难看出，在table4a中的3行数据在table1中需要6行来表示，这就需要“化宽为长”的gather()函数。 table1 #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 gather()有四个主要参数： data: 需要调用的数据集 key： 存放原来各列名的新变量的变量名（键列） value 存放原来单元格中的值的新变量的变量名（值列） ...: 指定的要聚集（融合）的变量，可以通过枚举指定: A,B,C 或者通过范围进行指定A:D,也可以同过-号 指定不需要聚集的列：-E,-F。不管要聚集多少列，gather()函数都把它们聚集为一个键列和一个值列。 接下来我们整理table4a数据集，这里需要聚集的列是1999和2000: ## 注意这里`1999`和`2000`的引用方法 gather(table4a,key = year,value = cases,`1999`,`2000`) #&gt; # A tibble: 6 x 3 #&gt; country year cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 #&gt; 2 Brazil 1999 37737 #&gt; 3 China 1999 212258 #&gt; 4 Afghanistan 2000 2666 #&gt; 5 Brazil 2000 80488 #&gt; 6 China 2000 213766 图示变换过程： 另一个例子：美国劳工市场的月度数据，首先创建一个messy data： library(lubridate) ec2 &lt;- economics %&gt;% as_tibble() %&gt;% transmute(year = year(date), month = month(date), rate = unemploy) %&gt;% filter(year &gt; 2005) %&gt;% spread(year,rate) ec2 #&gt; # A tibble: 12 x 11 #&gt; month `2006` `2007` `2008` `2009` `2010` `2011` `2012` `2013` `2014` `2015` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 7064 7116 7685 12058 15046 14013 12797 12471 10202 8903 #&gt; 2 2 7184 6927 7497 12898 15113 13820 12813 11950 10349 8610 #&gt; 3 3 7072 6731 7822 13426 15202 13737 12713 11689 10380 8504 #&gt; 4 4 7120 6850 7637 13853 15325 13957 12646 11760 9702 8526 #&gt; 5 5 6980 6766 8395 14499 14849 13855 12660 11654 9859 NA #&gt; 6 6 7001 6979 8575 14707 14474 13962 12692 11751 9460 NA #&gt; # … with 6 more rows 下面，将除了month列的所有列聚集为一个键列和一个值列 ec2 %&gt;% gather(-month,key = year,value = unemploy) #&gt; # A tibble: 120 x 3 #&gt; month year unemploy #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2006 7064 #&gt; 2 2 2006 7184 #&gt; 3 3 2006 7072 #&gt; 4 4 2006 7120 #&gt; 5 5 2006 6980 #&gt; 6 6 2006 7001 #&gt; # … with 114 more rows 为了让数据更好用，我们还可以增加两个额外的参数： economics_2 &lt;- ec2 %&gt;% gather(key = year,value = unemploy,`2006`:`2015`,convert = T,na.rm = T) convert = TRUE将键列year变量从字符串转换为数值型（在练习里会谈到为什么year变成了字符串），na.rm = TRUE则可以自动移除没有值的月份（其实这个确实并不是数据的丢失，而只是因为那个时间还有到而已）。 以上数据整理好之后，就很容易用ggplot2作的。如我们可以关注长期趋势，或者查看季节性变化： ## x轴为季度 ggplot(economics_2,aes(x=(year+(month-1)/12),y=unemploy))+ geom_line() ggplot(economics_2,aes(month,unemploy))+ geom_line(aes(group = year,color = factor(year)),size = 1) 6.2.2 spread() spread()函数是gather()的逆运算，当某个变量的值实际上是其他变量的名字，就需要将数据集化长为宽，也可以说这种“错误”的表现形式是一个观测分散到了多行中（an observation is scattered across multiple rows）。例如table2(): table2 #&gt; # A tibble: 12 x 4 #&gt; country year type count #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 1999 population 19987071 #&gt; 3 Afghanistan 2000 cases 2666 #&gt; 4 Afghanistan 2000 population 20595360 #&gt; 5 Brazil 1999 cases 37737 #&gt; 6 Brazil 1999 population 172006362 #&gt; # … with 6 more rows 例如，前两列结合起来，才能得到对1999年阿富汗在cases和population两个变量上的观测。 在spread()中，你只需要指定两个参数（除了data以外），key和value，这里分别是type和count: table2 %&gt;% spread(key = type,value = count) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 观察table2经过扩散的结果，不难看出spread(key,value)其实是构造透视表的过程。key列将被用作列字段，value列被用作透视表中的值字段，其他列将被当做行字段。 变换的图示： 6.2.3 练习 在下面的例子中，研究为什么spread()和gather()不是完美对称的。 (stocks &lt;- tibble( year = c(2015, 2015, 2016, 2016), half = c(1, 2, 1, 2), return = c(1.88, 0.59, 0.92, 0.17) )) #&gt; # A tibble: 4 x 3 #&gt; year half return #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2015 1 1.88 #&gt; 2 2015 2 0.59 #&gt; 3 2016 1 0.92 #&gt; 4 2016 2 0.17 stocks %&gt;% spread(year, return) %&gt;% gather(`2015`:`2016`, key = &quot;year&quot;, value = &quot;return&quot;) #&gt; # A tibble: 4 x 3 #&gt; half year return #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 1 2016 0.92 #&gt; 4 2 2016 0.17 先后使用spread()和gather()无法得到一个相同的数据集（除了列的顺序）是因为，数据整理有时会丢失列的类型信息。当spread()将变量year的值2015和2016用作列的名字时，它们自然被转化为了字符串\"2015\"和\"2016\"；随后gather()把列名用作键列year的值，从而year自然变成了一个字符向量。 如果想要复原这个数据集，可以在gather()中使用convert = T，不过这时返回的数据类型是R经过猜测的结果，并不总保证和原数据一致，数据整理带来的不可避免的信息损耗。 stocks %&gt;% spread(year, return) %&gt;% gather(`2015`:`2016`, key = &quot;year&quot;, value = &quot;return&quot;,convert = T) #&gt; # A tibble: 4 x 3 #&gt; half year return #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 1 2016 0.92 #&gt; 4 2 2016 0.17 2.为什么下面的数据框不能应用spread()？可以添加一列解决这个问题吗？ people &lt;- tribble( ~name, ~key, ~value, &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Phillip Woods&quot;, &quot;age&quot;, 50, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156 ) 因为这个数据集里有两个对于“Phillip Woods”在变量age上年龄的观测，spread()就要把由(Phillips Woods,age)确定的单元格里“塞进两个值”。本质上因为name和key这两个变量上的值不能唯一确定一行，所以我们只要添加一列，让name、key和新列可以唯一确定一行即可： people2 &lt;- people %&gt;% group_by(name, key) %&gt;% mutate(obs = row_number()) people2 #&gt; # A tibble: 5 x 4 #&gt; # Groups: name, key [4] #&gt; name key value obs #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 Phillip Woods age 45 1 #&gt; 2 Phillip Woods height 186 1 #&gt; 3 Phillip Woods age 50 2 #&gt; 4 Jessica Cordero age 37 1 #&gt; 5 Jessica Cordero height 156 1 spread(people2,key,value) #&gt; # A tibble: 3 x 4 #&gt; # Groups: name [2] #&gt; name obs age height #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Jessica Cordero 1 37 156 #&gt; 2 Phillip Woods 1 45 186 #&gt; 3 Phillip Woods 2 50 NA 6.3 separate()和untie() spread()函数和gather()函数可以帮你解决数据中的变量放错了位置的问题。而separate()和untie()函数则是为了解决以下问题：多个变量挤在了同一列中，或者一个变量分散到了不同列中。 6.3.1 separate() 现在我们知道了如何用spread()和gather()将table2和table4整理为tidy data，现在要学会如何用separate()处理table3了： table3 #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745/19987071 #&gt; 2 Afghanistan 2000 2666/20595360 #&gt; 3 Brazil 1999 37737/172006362 #&gt; 4 Brazil 2000 80488/174504898 #&gt; 5 China 1999 212258/1272915272 #&gt; 6 China 2000 213766/1280428583 在table3中，rate同时包含了cases和population两个变量，我们需要把它拆分(separate)为两列，separate()函数可以将这一混杂的列拆分成多个变量，它包含以下四个主要参数： data: 需要调整的数据框 col: 需要进行拆分的列的列名 into: 拆分后新生成变量的列名，格式为字符串向量 sep: 对如何拆分原变量的描述，其可以是正则表达式，如_表示通过下划线拆分，或[^a-z]表示通过任意非字符字母拆分，或一个指定位置的整数。默认情况下，sep将认定一个非字符字母进行划分 ## 这个例子里，sep不是必需的 table3 %&gt;% separate(col = rate,into = c(&quot;cases&quot;,&quot;population&quot;)) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 整理的图示： 注意，以上输出的tibble中，cases和population被设定为字符串类型，使用convert = T将其转换为数值变量 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), convert = T) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 6.3.2 unite() unite()函数是separate()的逆运算——它可以将多列合并为一列。尽管它不太常用，但是知道这个函数还是很重要的。 在table5中，原来的year变量被拆成了两个列，可以用unite()，只需要指定要合并后的列名和要合并的列。默认情况下，新列中将用_分隔符 table5 #&gt; # A tibble: 6 x 4 #&gt; country century year rate #&gt; * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19 99 745/19987071 #&gt; 2 Afghanistan 20 00 2666/20595360 #&gt; 3 Brazil 19 99 37737/172006362 #&gt; 4 Brazil 20 00 80488/174504898 #&gt; 5 China 19 99 212258/1272915272 #&gt; 6 China 20 00 213766/1280428583 unite(table5,col = year, century,year) #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19_99 745/19987071 #&gt; 2 Afghanistan 20_00 2666/20595360 #&gt; 3 Brazil 19_99 37737/172006362 #&gt; 4 Brazil 20_00 80488/174504898 #&gt; 5 China 19_99 212258/1272915272 #&gt; 6 China 20_00 213766/1280428583 设置sep参数可以取消分隔符： unite(table5,col = year,century,year,sep=&quot;&quot;) #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745/19987071 #&gt; 2 Afghanistan 2000 2666/20595360 #&gt; 3 Brazil 1999 37737/172006362 #&gt; 4 Brazil 2000 80488/174504898 #&gt; 5 China 1999 212258/1272915272 #&gt; 6 China 2000 213766/1280428583 整理的图示： table6 &lt;- unite(table5,col = year,century,year,sep=&quot;&quot;) table5 #&gt; # A tibble: 6 x 4 #&gt; country century year rate #&gt; * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19 99 745/19987071 #&gt; 2 Afghanistan 20 00 2666/20595360 #&gt; 3 Brazil 19 99 37737/172006362 #&gt; 4 Brazil 20 00 80488/174504898 #&gt; 5 China 19 99 212258/1272915272 #&gt; 6 China 20 00 213766/1280428583 6.3.3 练习 separate()中的extra和fill参数的作用是什么？用下面两个数据框进行实验： tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, into = c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b c #&gt; 2 d e f #&gt; 3 h i j tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, into = c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;)) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b c #&gt; 2 d e &lt;NA&gt; #&gt; 3 f g i extra用来告诉separate()函数如何处理分列过程中多出来的元素(too many pieces，即into指定的列数小于原数据中某行可分的元素个数)，fill负责如何处理元素不够的情况(not enough pieces，即into指定的列数大于原数据中某行可分的元素个数)。默认情况下，extra = \"drop\"，separate()将丢弃多余的元素，并生成一条警告信息： tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, into = c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;),extra = &quot;drop&quot;) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b c #&gt; 2 d e f #&gt; 3 h i j extra = \"merge\"将把多余的元素和前一个元素当做一个整体： tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;),extra = &quot;merge&quot;) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b c #&gt; 2 d e f,g #&gt; 3 h i j 对于元素过少的情况，默认的fill = \"warn\"将会用NA进行填充，但会生成一条警告。fill = \"right\"会尽可能让靠左的列拥有可用的元素，用NA填充右边的列；fill = \"left\"正好相反。这两种手动设置都不会产生warning: tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;),fill = &quot;left&quot;) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b &quot;c&quot; #&gt; 2 d e &quot;&quot; #&gt; 3 h i &quot;j&quot; tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;),fill = &quot;right&quot;) #&gt; # A tibble: 3 x 3 #&gt; one two three #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a b &quot;c&quot; #&gt; 2 d e &quot;&quot; #&gt; 3 h i &quot;j&quot; 2.unite()和separate()均有一个remove参数，它的作用是什么？ remove控制是否在unite()或separate()输出的数据框中保留原来的列，默认remove = T。如果想保留原来未合并/分离的格列，可以设置remove = F table5 #&gt; # A tibble: 6 x 4 #&gt; country century year rate #&gt; * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19 99 745/19987071 #&gt; 2 Afghanistan 20 00 2666/20595360 #&gt; 3 Brazil 19 99 37737/172006362 #&gt; 4 Brazil 20 00 80488/174504898 #&gt; 5 China 19 99 212258/1272915272 #&gt; 6 China 20 00 213766/1280428583 table5 %&gt;% unite(col = year_unite,century,year,sep = &quot;&quot;,remove = F) #&gt; # A tibble: 6 x 5 #&gt; country year_unite century year rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 19 99 745/19987071 #&gt; 2 Afghanistan 2000 20 00 2666/20595360 #&gt; 3 Brazil 1999 19 99 37737/172006362 #&gt; 4 Brazil 2000 20 00 80488/174504898 #&gt; 5 China 1999 19 99 212258/1272915272 #&gt; 6 China 2000 20 00 213766/1280428583 探究tidyr中一个与separate()类似的函数extract()的用法 separate()函数的分列操作是基于参数sep的，无论是给sep传入字符串指定分隔符，还是用数值指定分隔的位置，separate()必须要有一个分隔符才能正常运作（可以把sep = n看做第n个和第n+1个元素之间的一个空白分隔符） extract()用一个正则表达式regex描述要分隔的列col中存在的模式，在正则表达式中的每个子表达式(用()定义)将被认为是into中的一个元素，因此，extract()比separate()使用起来更加广泛灵活。例如下面的数据集无法用separate()分列，因为无法用一个各行的分隔符(的位置)不一样，但用extract()中的正则表达式就很简单： tibble(x = c(&quot;X1&quot;, &quot;X20&quot;, &quot;AA11&quot;, &quot;AA2&quot;)) %&gt;% extract(x, c(&quot;variable&quot;, &quot;id&quot;), regex = &quot;([A-Z]+)([0-9]+)&quot;) #&gt; # A tibble: 4 x 2 #&gt; variable id #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 X 1 #&gt; 2 X 20 #&gt; 3 AA 11 #&gt; 4 AA 2 适当设计regex，实现的效果可以与设置sep完全一致： # example with separators tibble(x = c(&quot;X_1&quot;, &quot;X_2&quot;, &quot;AA_1&quot;, &quot;AA_2&quot;)) %&gt;% extract(x, c(&quot;variable&quot;, &quot;id&quot;), regex = &quot;([A-Z]+)_([0-9])&quot;) #&gt; # A tibble: 4 x 2 #&gt; variable id #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 X 1 #&gt; 2 X 2 #&gt; 3 AA 1 #&gt; 4 AA 2 # example with position tibble(x = c(&quot;X1&quot;, &quot;X2&quot;, &quot;Y1&quot;, &quot;Y2&quot;)) %&gt;% extract(x, c(&quot;variable&quot;, &quot;id&quot;), regex = &quot;([A-Z])([0-9])&quot;) #&gt; # A tibble: 4 x 2 #&gt; variable id #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 X 1 #&gt; 2 X 2 #&gt; 3 Y 1 #&gt; 4 Y 2 6.4 缺失值 数据整理改变了数据的呈现方式，随之而来的一个话题便是缺失值。通常当我们泛泛地使用“缺失值 (missing value)” 这个名词的时候，其实是指以下两种“缺失”方式中的某一种： 显式缺失(Explicitly missing): 在数据中用NA标识 隐式缺失(Implicitly missing): 未出现在数据中的值 R for Data Science中对这两种缺失的概括： An explicit missing value is the presence of an absence; an implicit missing value is the absence of a presence. 通过一个简单的数据框区分两种数据缺失的方式： stocks &lt;- tibble( year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016), qtr = c( 1, 2, 3, 4, 2, 3, 4), return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66) ) stocks #&gt; # A tibble: 7 x 3 #&gt; year qtr return #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2015 1 1.88 #&gt; 2 2015 2 0.59 #&gt; 3 2015 3 0.35 #&gt; 4 2015 4 NA #&gt; 5 2016 2 0.92 #&gt; 6 2016 3 0.17 #&gt; # … with 1 more row 我们很容易找到stocks第四条观测在变量return上的一个NA，因为它是显式缺失的。另一个隐式缺失的值是(year = 2016,qtr = 1)对应的观测，它没有出现在数据集中。 数据呈现方式上的改变可以将隐式缺失值变成显式。比如，用spread()函数构造以year为行字段，以return为值的透视表,这样就会产生一个属于水平(year = 2016,qtr = 1)的单元格： stocks %&gt;% spread(key = year,value = return) #&gt; # A tibble: 4 x 3 #&gt; qtr `2015` `2016` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1.88 NA #&gt; 2 2 0.59 0.92 #&gt; 3 3 0.35 0.17 #&gt; 4 4 NA 2.66 现在，再使用gather()不能得到原来的数据框，因为将比原来多出一行显示的缺失值 stocks %&gt;% spread(key = year,value = return) %&gt;% gather(key = year,value = return,`2015`:`2016`) #&gt; # A tibble: 8 x 3 #&gt; qtr year return #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 3 2015 0.35 #&gt; 4 4 2015 NA #&gt; 5 1 2016 NA #&gt; 6 2 2016 0.92 #&gt; # … with 2 more rows 如果研究者认为这些缺失值是无足轻重的,na.rm = T将在gather()生成的数据框中移除含有缺失值的行： ## 现在输出数据框比原来少一行 stocks %&gt;% spread(key = year,value = return) %&gt;% gather(key = year,value = return,`2015`:`2016`,na.rm = T) #&gt; # A tibble: 6 x 3 #&gt; qtr year return #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 3 2015 0.35 #&gt; 4 2 2016 0.92 #&gt; 5 3 2016 0.17 #&gt; 6 4 2016 2.66 另一个用于处理确实值的有用工具是complete()函数，它将生成一个指定列集合里面所有的水平组合，并自动将原本隐式的缺失值填充为NA stocks %&gt;% complete(year, qtr) #&gt; # A tibble: 8 x 3 #&gt; year qtr return #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2015 1 1.88 #&gt; 2 2015 2 0.59 #&gt; 3 2015 3 0.35 #&gt; 4 2015 4 NA #&gt; 5 2016 1 NA #&gt; 6 2016 2 0.92 #&gt; # … with 2 more rows fill() 函数专门用来填充缺失值,它接受一些需要填充缺失值的列，并用最近的值调换 NA，.direction 参数控制用填充的方向：direction = “up\" 将由下往上填充，NA 将被替换为它下面那一列的值；direction = \"donw\" 反之 treatment &lt;- tribble( ~ person, ~ treatment, ~response, &quot;Derrick Whitmore&quot;, 1, 7, NA, 2, 10, NA, 3, 9, &quot;Katherine Burke&quot;, 1, 4 ) treatment %&gt;% fill(person,.direction = &quot;up&quot;) #&gt; # A tibble: 4 x 3 #&gt; person treatment response #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Derrick Whitmore 1 7 #&gt; 2 Katherine Burke 2 10 #&gt; 3 Katherine Burke 3 9 #&gt; 4 Katherine Burke 1 4 treatment %&gt;% fill(person,.direction = &quot;down&quot;) #&gt; # A tibble: 4 x 3 #&gt; person treatment response #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Derrick Whitmore 1 7 #&gt; 2 Derrick Whitmore 2 10 #&gt; 3 Derrick Whitmore 3 9 #&gt; 4 Katherine Burke 1 4 6.5 Case Study To finish off the chapter, let’s pull together everything you’ve learned to tackle a realistic data tidying problem. The tidyr::who dataset contains tuberculosis (TB) cases broken down by year, country, age, gender, and diagnosis method. The data comes from the 2014 World Health Organization Global Tuberculosis Report, available at http://www.who.int/tb/country/data/download/en/. There’s a wealth of epidemiological information in this dataset, but it’s challenging to work with the data in the form that it’s provided: who #&gt; # A tibble: 7,240 x 60 #&gt; country iso2 iso3 year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghan… AF AFG 1980 NA NA NA NA #&gt; 2 Afghan… AF AFG 1981 NA NA NA NA #&gt; 3 Afghan… AF AFG 1982 NA NA NA NA #&gt; 4 Afghan… AF AFG 1983 NA NA NA NA #&gt; 5 Afghan… AF AFG 1984 NA NA NA NA #&gt; 6 Afghan… AF AFG 1985 NA NA NA NA #&gt; # … with 7,234 more rows, and 52 more variables: new_sp_m4554 &lt;int&gt;, #&gt; # new_sp_m5564 &lt;int&gt;, new_sp_m65 &lt;int&gt;, new_sp_f014 &lt;int&gt;, #&gt; # new_sp_f1524 &lt;int&gt;, new_sp_f2534 &lt;int&gt;, new_sp_f3544 &lt;int&gt;, #&gt; # new_sp_f4554 &lt;int&gt;, new_sp_f5564 &lt;int&gt;, new_sp_f65 &lt;int&gt;, #&gt; # new_sn_m014 &lt;int&gt;, new_sn_m1524 &lt;int&gt;, new_sn_m2534 &lt;int&gt;, #&gt; # new_sn_m3544 &lt;int&gt;, new_sn_m4554 &lt;int&gt;, new_sn_m5564 &lt;int&gt;, #&gt; # new_sn_m65 &lt;int&gt;, new_sn_f014 &lt;int&gt;, new_sn_f1524 &lt;int&gt;, #&gt; # new_sn_f2534 &lt;int&gt;, new_sn_f3544 &lt;int&gt;, new_sn_f4554 &lt;int&gt;, #&gt; # new_sn_f5564 &lt;int&gt;, new_sn_f65 &lt;int&gt;, new_ep_m014 &lt;int&gt;, #&gt; # new_ep_m1524 &lt;int&gt;, new_ep_m2534 &lt;int&gt;, new_ep_m3544 &lt;int&gt;, #&gt; # new_ep_m4554 &lt;int&gt;, new_ep_m5564 &lt;int&gt;, new_ep_m65 &lt;int&gt;, #&gt; # new_ep_f014 &lt;int&gt;, new_ep_f1524 &lt;int&gt;, new_ep_f2534 &lt;int&gt;, #&gt; # new_ep_f3544 &lt;int&gt;, new_ep_f4554 &lt;int&gt;, new_ep_f5564 &lt;int&gt;, #&gt; # new_ep_f65 &lt;int&gt;, newrel_m014 &lt;int&gt;, newrel_m1524 &lt;int&gt;, #&gt; # newrel_m2534 &lt;int&gt;, newrel_m3544 &lt;int&gt;, newrel_m4554 &lt;int&gt;, #&gt; # newrel_m5564 &lt;int&gt;, newrel_m65 &lt;int&gt;, newrel_f014 &lt;int&gt;, #&gt; # newrel_f1524 &lt;int&gt;, newrel_f2534 &lt;int&gt;, newrel_f3544 &lt;int&gt;, #&gt; # newrel_f4554 &lt;int&gt;, newrel_f5564 &lt;int&gt;, newrel_f65 &lt;int&gt; This is a very typical real-life example dataset. It contains redundant columns, odd variable codes, and many missing values. In short, who is messy, and we’ll need multiple steps to tidy it. Like dplyr, tidyr is designed so that each function does one thing well. That means in real-life situations you’ll usually need to string together multiple verbs into a pipeline. The best place to start is almost always to gather together the columns that are not variables. Let’s have a look at what we’ve got: It looks like country, iso2, and iso3 are three variables that redundantly specify the country. year is also a variable We don’t know what all the other columns are yet, but given the structure in the variable names (e.g. new_sp_m014, new_ep_m014, new_ep_f014) these are likely to be values, not variables. So we need to gather together all the columns from new_sp_m014 to newrel_f65. We don’t know what those values represent yet, so we’ll give them the generic name \"key\". We know the cells represent the count of cases, so we’ll use the variable cases. There are a lot of missing values in the current representation, so for now we’ll use na.rm just so we can focus on the values that are present. who1 &lt;- who %&gt;% gather(key,value = &quot;cases&quot;,-country:-year,na.rm = T) who1 #&gt; # A tibble: 76,046 x 6 #&gt; country iso2 iso3 year key cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new_sp_m014 0 #&gt; 2 Afghanistan AF AFG 1998 new_sp_m014 30 #&gt; 3 Afghanistan AF AFG 1999 new_sp_m014 8 #&gt; 4 Afghanistan AF AFG 2000 new_sp_m014 52 #&gt; 5 Afghanistan AF AFG 2001 new_sp_m014 129 #&gt; 6 Afghanistan AF AFG 2002 new_sp_m014 90 #&gt; # … with 7.604e+04 more rows We can get some hint of the structure of the values in the new key column by counting them: who1 %&gt;% count(key) #&gt; # A tibble: 56 x 2 #&gt; key n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new_ep_f014 1032 #&gt; 2 new_ep_f1524 1021 #&gt; 3 new_ep_f2534 1021 #&gt; 4 new_ep_f3544 1021 #&gt; 5 new_ep_f4554 1017 #&gt; 6 new_ep_f5564 1017 #&gt; # … with 50 more rows You might be able to parse this out by yourself with a little thought and some experimentation, but luckily we have the data dictionary handy. It tells us: 1. The first three letters of each column denote whether the column contains new or old cases of TB. In this dataset, each column contains new cases. 2. The next two letters describe the type of TB: * rel stands for cases of relapse * ep stands for cases of extrapulmonary TB * sn stands for cases of pulmonary TB that could not be diagnosed by a pulmonary smear (smear negative) * sp stands for cases of pulmonary TB that could be diagnosed be a pulmonary smear (smear positive) The sixth letter gives the sex of TB patients. The dataset groups cases by males (m) and females (f). The remaining numbers gives the age group. The dataset groups cases into seven age groups: 014 = 0 – 14 years old 1524 = 15 – 24 years old 2534 = 25 – 34 years old 3544 = 35 – 44 years old 4554 = 45 – 54 years old 5564 = 55 – 64 years old 65 = 65 or older We need to make a minor fix to the format of the column names: unfortunately the names are slightly inconsistent because instead of new_rel we have newrel (it’s hard to spot this here but if you don’t fix it we’ll get errors in subsequent steps). You’ll learn about str_replace() in strings, but the basic idea is pretty simple: replace the characters “newrel” with “new_rel”. This makes all variable names consistent. who2 &lt;- who1 %&gt;% mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;)) who2 #&gt; # A tibble: 76,046 x 6 #&gt; country iso2 iso3 year key cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new_sp_m014 0 #&gt; 2 Afghanistan AF AFG 1998 new_sp_m014 30 #&gt; 3 Afghanistan AF AFG 1999 new_sp_m014 8 #&gt; 4 Afghanistan AF AFG 2000 new_sp_m014 52 #&gt; 5 Afghanistan AF AFG 2001 new_sp_m014 129 #&gt; 6 Afghanistan AF AFG 2002 new_sp_m014 90 #&gt; # … with 7.604e+04 more rows We can separate the values in each code with two passes of separate(). The first pass will split the codes at each underscore. who3 &lt;- who2 %&gt;% separate(key, c(&quot;new&quot;, &quot;type&quot;, &quot;sexage&quot;), sep = &quot;_&quot;) who3 #&gt; # A tibble: 76,046 x 8 #&gt; country iso2 iso3 year new type sexage cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new sp m014 0 #&gt; 2 Afghanistan AF AFG 1998 new sp m014 30 #&gt; 3 Afghanistan AF AFG 1999 new sp m014 8 #&gt; 4 Afghanistan AF AFG 2000 new sp m014 52 #&gt; 5 Afghanistan AF AFG 2001 new sp m014 129 #&gt; 6 Afghanistan AF AFG 2002 new sp m014 90 #&gt; # … with 7.604e+04 more rows Then we might as well drop the new column because it’s constant in this dataset. While we’re dropping columns, let’s also drop iso2 and iso3 since they’re redundant. who3 %&gt;% count(new) #&gt; # A tibble: 1 x 2 #&gt; new n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new 76046 who4 &lt;- who3 %&gt;% select(-new, -iso2, -iso3) Next we’ll separate sexage into sex and age by splitting after the first character: who5 &lt;- who4 %&gt;% separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) who5 #&gt; # A tibble: 76,046 x 6 #&gt; country year type sex age cases #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1997 sp m 014 0 #&gt; 2 Afghanistan 1998 sp m 014 30 #&gt; 3 Afghanistan 1999 sp m 014 8 #&gt; 4 Afghanistan 2000 sp m 014 52 #&gt; 5 Afghanistan 2001 sp m 014 129 #&gt; 6 Afghanistan 2002 sp m 014 90 #&gt; # … with 7.604e+04 more rows The who dataset is now tidy! I’ve shown you the code a piece at a time, assigning each interim result to a new variable. This typically isn’t how you’d work interactively. Instead, you’d gradually build up a complex pipe: who %&gt;% gather(key, value, new_sp_m014:newrel_f65, na.rm = TRUE) %&gt;% mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;)) %&gt;% separate(key, c(&quot;new&quot;, &quot;var&quot;, &quot;sexage&quot;)) %&gt;% select(-new, -iso2, -iso3) %&gt;% separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) #&gt; # A tibble: 76,046 x 6 #&gt; country year var sex age value #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1997 sp m 014 0 #&gt; 2 Afghanistan 1998 sp m 014 30 #&gt; 3 Afghanistan 1999 sp m 014 8 #&gt; 4 Afghanistan 2000 sp m 014 52 #&gt; 5 Afghanistan 2001 sp m 014 129 #&gt; 6 Afghanistan 2002 sp m 014 90 #&gt; # … with 7.604e+04 more rows 6.5.1 练习 在清理who数据框时，我们说iso2和iso3在有了country之后是冗余的，证明这一点 如果iso2和iso3相对于country是冗余的，则在数据集中对于变量country的每个值，仅有一个iso2和iso3的水平组合(country能唯一确定一条观测)。 这里要用到distinct()函数，它将返回数据框中某些列出现的的全部不重复的水平组合（注意complete()是”制造出“全部可能的水平组合），和unique()类似，但速度更快： who6 &lt;- who %&gt;% distinct(country,iso2,iso3) %&gt;% group_by(country) %&gt;% summarize(n = n()) who6 %&gt;% filter(n&gt;1) #&gt; # A tibble: 0 x 2 #&gt; # … with 2 variables: country &lt;chr&gt;, n &lt;int&gt; 6.6 拓展：None-tidy data Before we continue on to other topics, it’s worth talking briefly about non-tidy data. Earlier in the chapter, I used the pejorative term “messy” to refer to non-tidy data. That’s an oversimplification: there are lots of useful and well-founded data structures that are not tidy data. There are two main reasons to use other data structures: Alternative representations may have substantial performance or space advantages. Specialised fields have evolved their own conventions for storing data that may be quite different to the conventions of tidy data. Either of these reasons means you’ll need something other than a tibble (or data frame). If your data does fit naturally into a rectangular structure composed of observations and variables, I think tidy data should be your default choice. But there are good reasons to use other structures; tidy data is not the only way. If you’d like to learn more about non-tidy data, I’d highly recommend this thoughtful blog post by Jeff Leek: http://simplystatistics.org/2016/02/17/non-tidy-data/ 6.7 tidyr 1.0.0 tidyr 于 2019 年 9 月 14 日发布了版本 1.0.0，有以下重大变化： New pivot_longer() and pivot_wider() provide improved tools for reshaping, superceding spread() and gather(). New unnest_auto(), unnest_longer(), unnest_wider(), and hoist() provide new tools for rectangling, converting deeply nested lists into tidy data frames. nest() and unnest() have been changed to match an emerging principle for the design of ... interfaces. Four new functions (pack()/unpack(), and chop()/unchop()) reveal that nesting is the combination of two simpler steps. New expand_grid(), a variant of base::expand.grid(). This is a useful function to know about, but also serves as a good reason to discuss the important role that vctrs plays behind the scenes. You shouldn’t ever have to learn about vctrs, but it brings improvements to consistency and performance. 参考 https://www.tidyverse.org/articles/2019/09/tidyr-1-0-0/ 文档： vignette(\"pivot\")、vignette(\"rectangle\") and vignette(\"nest\") provide detailed documentation and case studies of pivotting, rectangling, and nesting respectively. vignette(\"in-packages\") provides best practices for using tidyr inside another package, and detailed advice on working with multiple versions of tidyr if an interface change has affected your package. library(tidyverse) 6.7.1 pivot_longer 和 pivot_wider pivot_longer() 和 pivot_wider() 分别对应原来的 gather() 和 spread()，如今 API 更加容易理解： pivot_longer(data, cols, names_to = &quot;name&quot;, values_to = &quot;value&quot;,) pivot_wider(data, names_from = name, values_from = value) 6.7.1.1 pivot_longer() 基本用法： relig_income #&gt; # A tibble: 18 x 11 #&gt; religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k` #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Agnostic 27 34 60 81 76 137 122 #&gt; 2 Atheist 12 27 37 52 35 70 73 #&gt; 3 Buddhist 27 21 30 34 33 58 62 #&gt; 4 Catholic 418 617 732 670 638 1116 949 #&gt; 5 Don’t k… 15 14 15 11 10 35 21 #&gt; 6 Evangel… 575 869 1064 982 881 1486 949 #&gt; # … with 12 more rows, and 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;, #&gt; # `Don&#39;t know/refused` &lt;dbl&gt; relig_income %&gt;% pivot_longer(cols = -religion, names_to = &quot;income&quot;, values_to = &quot;count&quot;) #&gt; # A tibble: 180 x 3 #&gt; religion income count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Agnostic &lt;$10k 27 #&gt; 2 Agnostic $10-20k 34 #&gt; 3 Agnostic $20-30k 60 #&gt; 4 Agnostic $30-40k 81 #&gt; 5 Agnostic $40-50k 76 #&gt; 6 Agnostic $50-75k 137 #&gt; # … with 174 more rows names_to 和 values_to 参数相当于原来 gather() 中的 key 和 value，其中 “键” 列的默认名称变为 “name” Numeric data in column names pivot_longer() 现在提供了 names_ptype 和 values_ptypes 两个参数调整数据集变长后键列和值列的数据类别。看一下 billboard 数据集： billboard #&gt; # A tibble: 317 x 79 #&gt; artist track date.entered wk1 wk2 wk3 wk4 wk5 wk6 wk7 wk8 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 Pac Baby… 2000-02-26 87 82 72 77 87 94 99 NA #&gt; 2 2Ge+h… The … 2000-09-02 91 87 92 NA NA NA NA NA #&gt; 3 3 Doo… Kryp… 2000-04-08 81 70 68 67 66 57 54 53 #&gt; 4 3 Doo… Loser 2000-10-21 76 76 72 69 67 65 55 59 #&gt; 5 504 B… Wobb… 2000-04-15 57 34 25 17 17 31 36 49 #&gt; 6 98^0 Give… 2000-08-19 51 39 34 26 26 19 2 2 #&gt; # … with 311 more rows, and 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, #&gt; # wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;, wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, #&gt; # wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;, wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, #&gt; # wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;, wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, #&gt; # wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;, wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, #&gt; # wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;, wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, #&gt; # wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;, wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, #&gt; # wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, wk49 &lt;dbl&gt;, wk50 &lt;dbl&gt;, wk51 &lt;dbl&gt;, wk52 &lt;dbl&gt;, #&gt; # wk53 &lt;dbl&gt;, wk54 &lt;dbl&gt;, wk55 &lt;dbl&gt;, wk56 &lt;dbl&gt;, wk57 &lt;dbl&gt;, wk58 &lt;dbl&gt;, #&gt; # wk59 &lt;dbl&gt;, wk60 &lt;dbl&gt;, wk61 &lt;dbl&gt;, wk62 &lt;dbl&gt;, wk63 &lt;dbl&gt;, wk64 &lt;dbl&gt;, #&gt; # wk65 &lt;dbl&gt;, wk66 &lt;lgl&gt;, wk67 &lt;lgl&gt;, wk68 &lt;lgl&gt;, wk69 &lt;lgl&gt;, wk70 &lt;lgl&gt;, #&gt; # wk71 &lt;lgl&gt;, wk72 &lt;lgl&gt;, wk73 &lt;lgl&gt;, wk74 &lt;lgl&gt;, wk75 &lt;lgl&gt;, wk76 &lt;lgl&gt; 显然，我们希望将所有以 \"wk\"开头的列聚合以得到整洁数据，键列和值列分别命名为 “week” 和 “rank”。另外要考虑的一点是，我们很可能之后想计算歌曲保持在榜单上的周数，故需要将 “week” 列转换为数值类型： billboard_tidy &lt;- billboard %&gt;% pivot_longer(cols = starts_with(&quot;wk&quot;), names_to = &quot;week&quot;, values_to = &quot;rank&quot;, names_prefix = &quot;wk&quot;, names_ptypes = list(week = integer()), values_drop_na = T) billboard_tidy #&gt; # A tibble: 5,307 x 5 #&gt; artist track date.entered week rank #&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 1 87 #&gt; 2 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 2 82 #&gt; 3 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 3 72 #&gt; 4 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 4 77 #&gt; 5 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 5 87 #&gt; 6 2 Pac Baby Don&#39;t Cry (Keep... 2000-02-26 6 94 #&gt; # … with 5,301 more rows names_prefix 去除前缀 \"wk\"，names_ptype 以列表的形式转换键列的数据类型 ## 计算保持周数 billboard_tidy %&gt;% group_by(track) %&gt;% summarise(stay = max(week) - min(week) + 1) %&gt;% arrange(stay) #&gt; # A tibble: 316 x 2 #&gt; track stay #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Cherchez LaGhost 1 #&gt; 2 No Me Dejes De Quere... 1 #&gt; 3 Souljas 1 #&gt; 4 Toca&#39;s Miracle 1 #&gt; 5 Deck The Halls 2 #&gt; 6 Got Beef 2 #&gt; # … with 310 more rows Many variables in column names pivot_longer() 现在可以方便地拆分键列，之前曾处理过 who 数据集： who #&gt; # A tibble: 7,240 x 60 #&gt; country iso2 iso3 year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghan… AF AFG 1980 NA NA NA NA #&gt; 2 Afghan… AF AFG 1981 NA NA NA NA #&gt; 3 Afghan… AF AFG 1982 NA NA NA NA #&gt; 4 Afghan… AF AFG 1983 NA NA NA NA #&gt; 5 Afghan… AF AFG 1984 NA NA NA NA #&gt; 6 Afghan… AF AFG 1985 NA NA NA NA #&gt; # … with 7,234 more rows, and 52 more variables: new_sp_m4554 &lt;int&gt;, #&gt; # new_sp_m5564 &lt;int&gt;, new_sp_m65 &lt;int&gt;, new_sp_f014 &lt;int&gt;, #&gt; # new_sp_f1524 &lt;int&gt;, new_sp_f2534 &lt;int&gt;, new_sp_f3544 &lt;int&gt;, #&gt; # new_sp_f4554 &lt;int&gt;, new_sp_f5564 &lt;int&gt;, new_sp_f65 &lt;int&gt;, #&gt; # new_sn_m014 &lt;int&gt;, new_sn_m1524 &lt;int&gt;, new_sn_m2534 &lt;int&gt;, #&gt; # new_sn_m3544 &lt;int&gt;, new_sn_m4554 &lt;int&gt;, new_sn_m5564 &lt;int&gt;, #&gt; # new_sn_m65 &lt;int&gt;, new_sn_f014 &lt;int&gt;, new_sn_f1524 &lt;int&gt;, #&gt; # new_sn_f2534 &lt;int&gt;, new_sn_f3544 &lt;int&gt;, new_sn_f4554 &lt;int&gt;, #&gt; # new_sn_f5564 &lt;int&gt;, new_sn_f65 &lt;int&gt;, new_ep_m014 &lt;int&gt;, #&gt; # new_ep_m1524 &lt;int&gt;, new_ep_m2534 &lt;int&gt;, new_ep_m3544 &lt;int&gt;, #&gt; # new_ep_m4554 &lt;int&gt;, new_ep_m5564 &lt;int&gt;, new_ep_m65 &lt;int&gt;, #&gt; # new_ep_f014 &lt;int&gt;, new_ep_f1524 &lt;int&gt;, new_ep_f2534 &lt;int&gt;, #&gt; # new_ep_f3544 &lt;int&gt;, new_ep_f4554 &lt;int&gt;, new_ep_f5564 &lt;int&gt;, #&gt; # new_ep_f65 &lt;int&gt;, newrel_m014 &lt;int&gt;, newrel_m1524 &lt;int&gt;, #&gt; # newrel_m2534 &lt;int&gt;, newrel_m3544 &lt;int&gt;, newrel_m4554 &lt;int&gt;, #&gt; # newrel_m5564 &lt;int&gt;, newrel_m65 &lt;int&gt;, newrel_f014 &lt;int&gt;, #&gt; # newrel_f1524 &lt;int&gt;, newrel_f2534 &lt;int&gt;, newrel_f3544 &lt;int&gt;, #&gt; # newrel_f4554 &lt;int&gt;, newrel_f5564 &lt;int&gt;, newrel_f65 &lt;int&gt; ## tidyr 一章中使用的方法 who %&gt;% gather(starts_with(&quot;new&quot;), key = key, value = value, na.rm = T) %&gt;% extract(key, into = c(&quot;diagnosis&quot;, &quot;gender&quot;, &quot;age&quot;), regex = &quot;new_?(.*)_(.)(.*)&quot;) #&gt; # A tibble: 76,046 x 8 #&gt; country iso2 iso3 year diagnosis gender age value #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 sp m 014 0 #&gt; 2 Afghanistan AF AFG 1998 sp m 014 30 #&gt; 3 Afghanistan AF AFG 1999 sp m 014 8 #&gt; 4 Afghanistan AF AFG 2000 sp m 014 52 #&gt; 5 Afghanistan AF AFG 2001 sp m 014 129 #&gt; 6 Afghanistan AF AFG 2002 sp m 014 90 #&gt; # … with 7.604e+04 more rows 由于聚合后的键列包含了多个变量，还要再用一次 extract() 使之分离，现在可以直接在 names_to 中传入一个向量表示分裂后的各个键列，并在 names_pattern 中用正则表达式指定分裂的模式： who %&gt;% pivot_longer(cols = starts_with(&quot;new&quot;), names_to = c(&quot;diagonosis&quot;, &quot;gender&quot;, &quot;age&quot;), names_pattern = &quot;new_?(.*)_(.)(.*)&quot;, values_to = &quot;count&quot;, values_drop_na = T) #&gt; # A tibble: 76,046 x 8 #&gt; country iso2 iso3 year diagonosis gender age count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 sp m 014 0 #&gt; 2 Afghanistan AF AFG 1997 sp m 1524 10 #&gt; 3 Afghanistan AF AFG 1997 sp m 2534 6 #&gt; 4 Afghanistan AF AFG 1997 sp m 3544 3 #&gt; 5 Afghanistan AF AFG 1997 sp m 4554 5 #&gt; 6 Afghanistan AF AFG 1997 sp m 5564 2 #&gt; # … with 7.604e+04 more rows 更进一步，顺便设定好整理后 gender 和 age 的类型： who %&gt;% pivot_longer(cols = starts_with(&quot;new&quot;), names_to = c(&quot;diagonosis&quot;, &quot;gender&quot;, &quot;age&quot;), names_pattern = &quot;new_?(.*)_(.)(.*)&quot;, names_ptypes = list( gender = factor(levels = c(&quot;f&quot;, &quot;m&quot;)), age = factor( levels = c(&quot;014&quot;, &quot;1524&quot;, &quot;2534&quot;, &quot;3544&quot;, &quot;4554&quot;, &quot;5564&quot;, &quot;65&quot;), ordered = TRUE) ), values_to = &quot;count&quot;, values_drop_na = T) #&gt; # A tibble: 76,046 x 8 #&gt; country iso2 iso3 year diagonosis gender age count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;fct&gt; &lt;ord&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 sp m 014 0 #&gt; 2 Afghanistan AF AFG 1997 sp m 1524 10 #&gt; 3 Afghanistan AF AFG 1997 sp m 2534 6 #&gt; 4 Afghanistan AF AFG 1997 sp m 3544 3 #&gt; 5 Afghanistan AF AFG 1997 sp m 4554 5 #&gt; 6 Afghanistan AF AFG 1997 sp m 5564 2 #&gt; # … with 7.604e+04 more rows Multiple observations per row (多个值列) So far, we have been working with data frames that have one observation per row, but many important pivotting problems involve multiple observations per row. You can usually recognise this case because name of the column that you want to appear in the output is part of the column name in the input. In this section, you’ll learn how to pivot this sort of data. family &lt;- tribble( ~family, ~dob_child1, ~dob_child2, ~gender_child1, ~gender_child2, 1L, &quot;1998-11-26&quot;, &quot;2000-01-29&quot;, 1L, 2L, 2L, &quot;1996-06-22&quot;, NA, 2L, NA, 3L, &quot;2002-07-11&quot;, &quot;2004-04-05&quot;, 2L, 2L, 4L, &quot;2004-10-10&quot;, &quot;2009-08-27&quot;, 1L, 1L, 5L, &quot;2000-12-05&quot;, &quot;2005-02-28&quot;, 2L, 1L, ) family &lt;- family %&gt;% mutate_at(vars(starts_with(&quot;dob&quot;)), parse_date) family #&gt; # A tibble: 5 x 5 #&gt; family dob_child1 dob_child2 gender_child1 gender_child2 #&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 1998-11-26 2000-01-29 1 2 #&gt; 2 2 1996-06-22 NA 2 NA #&gt; 3 3 2002-07-11 2004-04-05 2 2 #&gt; 4 4 2004-10-10 2009-08-27 1 1 #&gt; 5 5 2000-12-05 2005-02-28 2 1 理想中的数据格式 family child dob gender 1 1 1998-11-26 1 1 2 2000-01-29 2 2 1 1996-06-22 2 3 1 2002-07-11 2 3 2 2004-04-05 2 4 1 2004-10-10 1 4 2 2009-08-27 1 5 1 2000-12-05 2 5 2 2005-02-28 1 Note that we have two pieces of information (or values) for each child: their gender and their dob (date of birth). These need to go into separate columns in the result. Again we supply multiple variables to names_to, using names_sep to split up each variable name. Note the special name .value: this tells pivot_longer() that that part of the column name specifies the “value” being measured (which will become a variable in the output) family %&gt;% pivot_longer( -family, names_to = c(&quot;.value&quot;, &quot;child&quot;), ## child 为每个 family 中的标识变量 names_sep = &quot;_&quot;, values_drop_na = TRUE ) #&gt; # A tibble: 9 x 4 #&gt; family child dob gender #&gt; &lt;int&gt; &lt;chr&gt; &lt;date&gt; &lt;int&gt; #&gt; 1 1 child1 1998-11-26 1 #&gt; 2 1 child2 2000-01-29 2 #&gt; 3 2 child1 1996-06-22 2 #&gt; 4 3 child1 2002-07-11 2 #&gt; 5 3 child2 2004-04-05 2 #&gt; 6 4 child1 2004-10-10 1 #&gt; # … with 3 more rows 在这里，dob_child1、dob_child2、gender_child1、gender_child2四个列名的后半部分被当做键列的值。例如，可以认为对于 family == 1的观测，首先生成了如下的结构： family child dob dob gender gender 1 child1 1998-11-16 2000-01-29 1 2 2 child2 而后名称相同的值列合并： family child dob gender 1 child1 1998-11-26 1 1 child2 2000-01-29 2 另一个例子： anscombe #&gt; x1 x2 x3 x4 y1 y2 y3 y4 #&gt; 1 10 10 10 8 8.04 9.14 7.46 6.58 #&gt; 2 8 8 8 8 6.95 8.14 6.77 5.76 #&gt; 3 13 13 13 8 7.58 8.74 12.74 7.71 #&gt; 4 9 9 9 8 8.81 8.77 7.11 8.84 #&gt; 5 11 11 11 8 8.33 9.26 7.81 8.47 #&gt; 6 14 14 14 8 9.96 8.10 8.84 7.04 #&gt; 7 6 6 6 8 7.24 6.13 6.08 5.25 #&gt; 8 4 4 4 19 4.26 3.10 5.39 12.50 #&gt; 9 12 12 12 8 10.84 9.13 8.15 5.56 #&gt; 10 7 7 7 8 4.82 7.26 6.42 7.91 #&gt; 11 5 5 5 8 5.68 4.74 5.73 6.89 anscombe %&gt;% pivot_longer(everything(), names_to = c(&quot;.value&quot;, &quot;set&quot;), names_pattern = &quot;([xy])([1234])&quot;) #&gt; # A tibble: 44 x 3 #&gt; set x y #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 10 8.04 #&gt; 2 2 10 9.14 #&gt; 3 3 10 7.46 #&gt; 4 4 8 6.58 #&gt; 5 1 8 6.95 #&gt; 6 2 8 8.14 #&gt; # … with 38 more rows 叕一个例子： pnl &lt;- tibble( x = 1:4, a = c(1, 1,0, 0), b = c(0, 1, 1, 1), y1 = rnorm(4), y2 = rnorm(4), z1 = rep(3, 4), z2 = rep(-2, 4), ) pnl #&gt; # A tibble: 4 x 7 #&gt; x a b y1 y2 z1 z2 #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 0 0.788 -1.59 3 -2 #&gt; 2 2 1 1 -0.422 0.597 3 -2 #&gt; 3 3 0 1 0.0569 1.22 3 -2 #&gt; 4 4 0 1 0.711 -0.312 3 -2 pnl %&gt;% pivot_longer(-(x:b), names_to = c(&quot;.value&quot;, &quot;time&quot;), names_pattern = &quot;([yz])([12])&quot;) #&gt; # A tibble: 8 x 6 #&gt; x a b time y z #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 0 1 0.788 3 #&gt; 2 1 1 0 2 -1.59 -2 #&gt; 3 2 1 1 1 -0.422 3 #&gt; 4 2 1 1 2 0.597 -2 #&gt; 5 3 0 1 1 0.0569 3 #&gt; 6 3 0 1 2 1.22 -2 #&gt; # … with 2 more rows Duplicated column names 如果某个数据框中的变量有重复的名字，用 gather()聚合这些变量所在的列时会返回一条错误： Error: Can&#39;t bind data because some arguments have the same name 这是因为被聚合的列名被当做 key 列的值，又因这些值是重复的，故不能唯一标识一条记录。pivot_longer 针对这一点做了优化，尝试聚合这些列时，会自动生成一个标识列： # To create a tibble with duplicated names # you have to explicitly opt out of the name repair # that usually prevents you from creating such a dataset: df &lt;- tibble(x = 1:3, y = 4:6, y = 5:7, y = 7:9, .name_repair = &quot;minimal&quot;) df #&gt; # A tibble: 3 x 4 #&gt; x y y y #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 4 5 7 #&gt; 2 2 5 6 8 #&gt; 3 3 6 7 9 df %&gt;% pivot_longer(-x, names_to = &quot;y&quot;) #&gt; # A tibble: 9 x 4 #&gt; x y .copy value #&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 y 1 4 #&gt; 2 1 y 2 5 #&gt; 3 1 y 3 7 #&gt; 4 2 y 1 5 #&gt; 5 2 y 2 6 #&gt; 6 2 y 3 8 #&gt; # … with 3 more rows 6.7.2 pivot_wider() The fish_encounters dataset, contributed by Myfanwy Johnston, describes when fish swimming down a river are detected by automatic monitoring stations: fish_encounters #&gt; # A tibble: 114 x 3 #&gt; fish station seen #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 4842 Release 1 #&gt; 2 4842 I80_1 1 #&gt; 3 4842 Lisbon 1 #&gt; 4 4842 Rstr 1 #&gt; 5 4842 Base_TD 1 #&gt; 6 4842 BCE 1 #&gt; # … with 108 more rows fish_encounters %&gt;% pivot_wider(names_from = station, values_from = seen, ) #&gt; # A tibble: 19 x 12 #&gt; fish Release I80_1 Lisbon Rstr Base_TD BCE BCW BCE2 BCW2 MAE MAW #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 4842 1 1 1 1 1 1 1 1 1 1 1 #&gt; 2 4843 1 1 1 1 1 1 1 1 1 1 1 #&gt; 3 4844 1 1 1 1 1 1 1 1 1 1 1 #&gt; 4 4845 1 1 1 1 1 NA NA NA NA NA NA #&gt; 5 4847 1 1 1 NA NA NA NA NA NA NA NA #&gt; 6 4848 1 1 1 1 NA NA NA NA NA NA NA #&gt; # … with 13 more rows "],
["relational-data.html", "7 relational data 7.1 introduction 7.2 mutating joins 7.3 filtering join 7.4 fuzzy join", " 7 relational data 7.1 introduction 7.2 mutating joins 7.3 filtering join 7.4 fuzzy join "],
["broom.html", "8 broom", " 8 broom library(broom) https://broom.tidyverse.org/index.html broom and updated dplyr https://broom.tidyverse.org/articles/broom_and_dplyr.html "],
["purrr.html", "9 purrr 9.1 map() family 9.2 Producing atomic vectors 9.3 Predicate functions 9.4 group_", " 9 purrr purrr tutorial : https://jennybc.github.io/purrr-tutorial/ 9.1 map() family mtcars %&gt;% map(mean) %&gt;% str() #&gt; List of 11 #&gt; $ mpg : num 20.1 #&gt; $ cyl : num 6.19 #&gt; $ disp: num 231 #&gt; $ hp : num 147 #&gt; $ drat: num 3.6 #&gt; $ wt : num 3.22 #&gt; $ qsec: num 17.8 #&gt; $ vs : num 0.438 #&gt; $ am : num 0.406 #&gt; $ gear: num 3.69 #&gt; $ carb: num 2.81 simple_map &lt;- function(x, fun, ...) { output &lt;- vector(&quot;list&quot;, length = length(x)) for (i in seq_along(x)) { output[[i]] &lt;- fun(x[[i]], ...) } output } 9.2 Producing atomic vectors # map_chr() always returns a character vector mtcars %&gt;% map_chr(typeof) #&gt; mpg cyl disp hp drat wt qsec vs #&gt; &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; #&gt; am gear carb #&gt; &quot;double&quot; &quot;double&quot; &quot;double&quot; # map_lgl() always returns a logical vector mtcars %&gt;% map_lgl(is.double) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE # map_int() always returns a integer vector mtcars %&gt;% map_int(function(x) length(unique(x))) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 25 3 27 22 22 29 30 2 2 3 6 # map_dbl() always returns a double vector mtcars %&gt;% map_dbl(mean) #&gt; mpg cyl disp hp drat wt qsec vs am gear #&gt; 20.091 6.188 230.722 146.688 3.597 3.217 17.849 0.438 0.406 3.688 #&gt; carb #&gt; 2.812 pair &lt;- function(x) c(x, x) map_dbl(1:2, pair) #&gt; Error: Result 1 must be a single double, not an integer vector of length 2 1:2 %&gt;% map(pair) #&gt; [[1]] #&gt; [1] 1 1 #&gt; #&gt; [[2]] #&gt; [1] 2 2 1:2 %&gt;% map_dbl(as.character) #&gt; Error: Can&#39;t coerce element 1 from a character to a double 1:2 %&gt;% map_chr(as.character) #&gt; [1] &quot;1&quot; &quot;2&quot; 9.2.1 purrr-style anonymous functions mtcars %&gt;% map_dbl(function(x) length(unique(x))) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 25 3 27 22 22 29 30 2 2 3 6 mtcars %&gt;% map_dbl(~ length(unique(.x))) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 25 3 27 22 22 29 30 2 2 3 6 mtcars %&gt;% map_dbl(~ length(unique(.))) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 25 3 27 22 22 29 30 2 2 3 6 This shortcut is particularly useful for generating random data: 1:5 %&gt;% map(~ rnorm(mean = .x, n = 5)) %&gt;% str() #&gt; List of 5 #&gt; $ : num [1:5] 1.788 0.578 1.057 1.711 -0.587 #&gt; $ : num [1:5] 2.6 3.22 1.69 1.79 1.63 #&gt; $ : num [1:5] 3.33 4.88 2.52 4.74 3.32 #&gt; $ : num [1:5] 3.9 3.22 4.1 3.95 3.73 #&gt; $ : num [1:5] 5.65 3.43 2.95 6.02 5.6 x &lt;- list( list(-1, x = 1, y = c(2), z = &quot;a&quot;), list(-2, x = 4, y = c(5, 6), z = &quot;b&quot;), list(-3, x = 8, y = c(9, 10, 11)) ) # select by position x %&gt;% map(2) #&gt; [[1]] #&gt; [1] 1 #&gt; #&gt; [[2]] #&gt; [1] 4 #&gt; #&gt; [[3]] #&gt; [1] 8 # select by name x %&gt;% map(&quot;x&quot;) #&gt; [[1]] #&gt; [1] 1 #&gt; #&gt; [[2]] #&gt; [1] 4 #&gt; #&gt; [[3]] #&gt; [1] 8 # select by both position and name x %&gt;% map(list(&quot;y&quot;, 2)) #&gt; [[1]] #&gt; NULL #&gt; #&gt; [[2]] #&gt; [1] 6 #&gt; #&gt; [[3]] #&gt; [1] 10 9.3 Predicate functions 9.3.1 Basics df &lt;- data.frame(x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) df %&gt;% keep(is.numeric) #&gt; x #&gt; 1 1 #&gt; 2 2 #&gt; 3 3 df %&gt;% discard(is.numeric) #&gt; y #&gt; 1 a #&gt; 2 b #&gt; 3 c df %&gt;% mutate(new_col = LETTERS[1:3]) %&gt;% detect(is.factor) #&gt; [1] a b c #&gt; Levels: a b c df %&gt;% detect_index(is.factor) #&gt; [1] 2 9.3.2 Map variants df &lt;- data.frame( num1 = c(0, 10, 20), num2 = c(5, 6, 7), chr1 = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), stringsAsFactors = FALSE ) df %&gt;% map_if(is.numeric, mean, na.rm = T) %&gt;% str() #&gt; List of 3 #&gt; $ num1: num 10 #&gt; $ num2: num 6 #&gt; $ chr1: chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot; df %&gt;% modify_if(is.character, str_to_upper) %&gt;% str() #&gt; &#39;data.frame&#39;: 3 obs. of 3 variables: #&gt; $ num1: num 0 10 20 #&gt; $ num2: num 5 6 7 #&gt; $ chr1: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; 9.4 group_ 9.4.1 group_map、group_modify group_map(), group_modify() and group_walk() are purrr-style functions that can be used to iterate on grouped tibbles. iris %&gt;% group_by(Species) %&gt;% group_map(~ broom::tidy(lm(Sepal.Length ~ Sepal.Width, data = .x))) %&gt;% bind_rows() #&gt; # A tibble: 6 x 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 2.64 0.310 8.51 3.74e-11 #&gt; 2 Sepal.Width 0.690 0.0899 7.68 6.71e-10 #&gt; 3 (Intercept) 3.54 0.563 6.29 9.07e- 8 #&gt; 4 Sepal.Width 0.865 0.202 4.28 8.77e- 5 #&gt; 5 (Intercept) 3.91 0.757 5.16 4.66e- 6 #&gt; 6 Sepal.Width 0.902 0.253 3.56 8.43e- 4 iris %&gt;% group_by(Species) %&gt;% group_modify(~ broom::tidy(lm(Sepal.Length ~ Sepal.Width, data = .x))) #&gt; # A tibble: 6 x 6 #&gt; # Groups: Species [3] #&gt; Species term estimate std.error statistic p.value #&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 setosa (Intercept) 2.64 0.310 8.51 3.74e-11 #&gt; 2 setosa Sepal.Width 0.690 0.0899 7.68 6.71e-10 #&gt; 3 versicolor (Intercept) 3.54 0.563 6.29 9.07e- 8 #&gt; 4 versicolor Sepal.Width 0.865 0.202 4.28 8.77e- 5 #&gt; 5 virginica (Intercept) 3.91 0.757 5.16 4.66e- 6 #&gt; 6 virginica Sepal.Width 0.902 0.253 3.56 8.43e- 4 This is similar to split() and then map(): iris %&gt;% split(.$Species) %&gt;% map_dfr(~ broom::tidy(lm(Sepal.Length ~ Sepal.Length, data = .x))) #&gt; # A tibble: 3 x 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 5.01 0.0498 100. 2.11e-58 #&gt; 2 (Intercept) 5.94 0.0730 81.3 6.14e-54 #&gt; 3 (Intercept) 6.59 0.0899 73.3 9.80e-52 9.4.2 group_split、group_keys、group_data iris %&gt;% as_tibble() %&gt;% group_split(Species) #&gt; [[1]] #&gt; # A tibble: 50 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; # … with 44 more rows #&gt; #&gt; [[2]] #&gt; # A tibble: 50 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 7 3.2 4.7 1.4 versicolor #&gt; 2 6.4 3.2 4.5 1.5 versicolor #&gt; 3 6.9 3.1 4.9 1.5 versicolor #&gt; 4 5.5 2.3 4 1.3 versicolor #&gt; 5 6.5 2.8 4.6 1.5 versicolor #&gt; 6 5.7 2.8 4.5 1.3 versicolor #&gt; # … with 44 more rows #&gt; #&gt; [[3]] #&gt; # A tibble: 50 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 6.3 3.3 6 2.5 virginica #&gt; 2 5.8 2.7 5.1 1.9 virginica #&gt; 3 7.1 3 5.9 2.1 virginica #&gt; 4 6.3 2.9 5.6 1.8 virginica #&gt; 5 6.5 3 5.8 2.2 virginica #&gt; 6 7.6 3 6.6 2.1 virginica #&gt; # … with 44 more rows #&gt; #&gt; attr(,&quot;ptype&quot;) #&gt; # A tibble: 0 x 5 #&gt; # … with 5 variables: Sepal.Length &lt;dbl&gt;, Sepal.Width &lt;dbl&gt;, #&gt; # Petal.Length &lt;dbl&gt;, Petal.Width &lt;dbl&gt;, Species &lt;fct&gt; iris %&gt;% as_tibble() %&gt;% group_by(Species) %&gt;% group_data() #&gt; # A tibble: 3 x 2 #&gt; Species .rows #&gt; &lt;fct&gt; &lt;list&gt; #&gt; 1 setosa &lt;int [50]&gt; #&gt; 2 versicolor &lt;int [50]&gt; #&gt; 3 virginica &lt;int [50]&gt; only grouping variables: iris %&gt;% as_tibble() %&gt;% group_keys(Species) #&gt; # A tibble: 3 x 1 #&gt; Species #&gt; &lt;fct&gt; #&gt; 1 setosa #&gt; 2 versicolor #&gt; 3 virginica only rows: iris %&gt;% as_tibble() %&gt;% group_by(Species) %&gt;% group_rows() #&gt; [[1]] #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #&gt; #&gt; [[2]] #&gt; [1] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #&gt; [20] 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 #&gt; [39] 89 90 91 92 93 94 95 96 97 98 99 100 #&gt; #&gt; [[3]] #&gt; [1] 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 #&gt; [20] 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #&gt; [39] 139 140 141 142 143 144 145 146 147 148 149 150 "],
["vroom.html", "10 vroom", " 10 vroom vroom(Hester and Wickham 2019) https://vroom.r-lib.org/ library(vroom) file_path &lt;- vroom_example(&quot;mtcars.csv&quot;) vroom(file_path) #&gt; # A tibble: 32 x 12 #&gt; model mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Mazda RX4 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 Mazda RX4 W… 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 Hornet 4 Dr… 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 Hornet Spor… 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; # … with 26 more rows spec(vroom(file_path)) #&gt; cols( #&gt; model = col_character(), #&gt; mpg = col_double(), #&gt; cyl = col_double(), #&gt; disp = col_double(), #&gt; hp = col_double(), #&gt; drat = col_double(), #&gt; wt = col_double(), #&gt; qsec = col_double(), #&gt; vs = col_double(), #&gt; am = col_double(), #&gt; gear = col_double(), #&gt; carb = col_double() #&gt; ) compressed &lt;- vroom_example(&quot;mtcars.csv.zip&quot;) vroom(compressed) #&gt; # A tibble: 32 x 12 #&gt; model mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Mazda RX4 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 2 Mazda RX4 W… 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 3 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 4 Hornet 4 Dr… 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 #&gt; 5 Hornet Spor… 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 #&gt; # … with 26 more rows vroom(compressed, col_select = c(model, cyl, gear)) #&gt; # A tibble: 32 x 3 #&gt; model cyl gear #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Mazda RX4 6 4 #&gt; 2 Mazda RX4 Wag 6 4 #&gt; 3 Datsun 710 4 4 #&gt; 4 Hornet 4 Drive 6 3 #&gt; 5 Hornet Sportabout 8 3 #&gt; 6 Valiant 6 3 #&gt; # … with 26 more rows mtcars #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.21 19.4 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.0 0 0 3 2 #&gt; Valiant 18.1 6 225.0 105 2.76 3.46 20.2 1 0 3 1 #&gt; Duster 360 14.3 8 360.0 245 3.21 3.57 15.8 0 0 3 4 #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 #&gt; Merc 230 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 #&gt; Merc 280 19.2 6 167.6 123 3.92 3.44 18.3 1 0 4 4 #&gt; Merc 280C 17.8 6 167.6 123 3.92 3.44 18.9 1 0 4 4 #&gt; Merc 450SE 16.4 8 275.8 180 3.07 4.07 17.4 0 0 3 3 #&gt; Merc 450SL 17.3 8 275.8 180 3.07 3.73 17.6 0 0 3 3 #&gt; Merc 450SLC 15.2 8 275.8 180 3.07 3.78 18.0 0 0 3 3 #&gt; Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.25 18.0 0 0 3 4 #&gt; Lincoln Continental 10.4 8 460.0 215 3.00 5.42 17.8 0 0 3 4 #&gt; Chrysler Imperial 14.7 8 440.0 230 3.23 5.34 17.4 0 0 3 4 #&gt; Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 #&gt; Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 #&gt; Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 #&gt; Toyota Corona 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 #&gt; Dodge Challenger 15.5 8 318.0 150 2.76 3.52 16.9 0 0 3 2 #&gt; AMC Javelin 15.2 8 304.0 150 3.15 3.44 17.3 0 0 3 2 #&gt; Camaro Z28 13.3 8 350.0 245 3.73 3.84 15.4 0 0 3 4 #&gt; Pontiac Firebird 19.2 8 400.0 175 3.08 3.85 17.1 0 0 3 2 #&gt; Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 #&gt; Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 #&gt; Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 #&gt; Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 #&gt; Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 #&gt; Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 #&gt; Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 "],
["data-apis.html", "11 Data APIs 11.1 WDI 11.2 ipumsr", " 11 Data APIs 11.1 WDI # install.packages(&quot;WDI&quot;) library(WDI) World Devevlopment Indicators(WDI)是世界银行提供的公开、高质量数据库。指标首先按照领域分类，除了一般常见的统计数据外，还包括农业、气候、贫穷、健康方面的数据。 Figure 11.1: Indicators divided by sectors 具体到某领域内，每个数据集都是各个国家在某个指标上的时间序列，时效性一般在两年之内。下面是气候变化分类中电力覆盖率指标(Access to electricity)的一个例子： knitr::include_graphics(&quot;images/20.png&quot;) 数据库中包含了超过 1600 个这样的时间序列，很多有效跨度超过了 50 年。WDI(Arel-Bundock 2019) 包提供了在 WDI 数据库中搜索、提取、格式化信息的接口。 11.1.1 WDIsearch() WDIserach() 用于在 WDI 数据库中搜索可用的指标，是之后用 WDI() 提取相关数据的基础。 WDIsearch(string = &quot;gdp&quot;, field = &quot;name&quot;, short = TRUE, cache = NULL) string = \"gdp\": 用于搜索的正则表达式 field= “name”: 搜索域，可选 “indicator”（编码）、“name”（名称）、“discription”（详细描述）、“sourceDatabase” 和 “sourceOrganization” （来源数据库或组织） short = TRUE：WDIsearch()默认只返回匹配指标的编码和名称，short = FSLE 同时返回详细描述和来源 如在名称域内中搜索与二氧化碳相关的指标： # the result of WDIsearch() is a 2D matrix WDIsearch(&quot;CO2&quot;, short = F) %&gt;% as_tibble() #&gt; # A tibble: 45 x 5 #&gt; indicator name description sourceDatabase sourceOrganization #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 EN.ATM.CO2… &quot;CO2 emis… &quot;Carbon dioxide … World Developm… &quot;Carbon Dioxide Info… #&gt; 2 EN.ATM.CO2… &quot;CO2 emis… &quot;Carbon dioxide … World Developm… &quot;Carbon Dioxide Info… #&gt; 3 EN.ATM.CO2… &quot;CO2 emis… &quot;Carbon dioxide … World Developm… &quot;Carbon Dioxide Info… #&gt; 4 EN.ATM.CO2… &quot;CO2 emis… &quot;Carbon dioxide … World Developm… &quot;Carbon Dioxide Info… #&gt; 5 EN.ATM.CO2… &quot;CO2 emis… &quot;Carbon dioxide … World Developm… &quot;Carbon Dioxide Info… #&gt; 6 EN.ATM.CO2… &quot;CO2 emis… &quot;&quot; WDI Database A… &quot;&quot; #&gt; # … with 39 more rows 改变搜索域： WDIsearch(string = &quot;mortality&quot;, field = &quot;description&quot;, short = F) %&gt;% as_tibble() #&gt; # A tibble: 383 x 5 #&gt; indicator name description sourceDatabase sourceOrganization #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 5.51.01.0… Maternal he… Births attended… Statistical Ca… World Development In… #&gt; 2 5.51.01.0… Immunization The proportion … Statistical Ca… World Development In… #&gt; 3 5.51.01.0… Child morta… Under-five mort… Statistical Ca… World Development In… #&gt; 4 PRJ.POP.1… Wittgenstei… Total populatio… Education Stat… Wittgenstein Centre … #&gt; 5 PRJ.POP.1… Wittgenstei… Total populatio… Education Stat… Wittgenstein Centre … #&gt; 6 PRJ.POP.1… Wittgenstei… Total populatio… Education Stat… Wittgenstein Centre … #&gt; # … with 377 more rows WDIsearch() 中的正则表达式背后用 base R 中的 grep() 实现，所以无视大小写。 搜索人均不变价 GDP ： WDIsearch(string = &#39;gdp.*capita.*constant&#39;) %&gt;% as_tibble() #&gt; # A tibble: 5 x 2 #&gt; indicator name #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 6.0.GDPpc_constant &quot;GDP per capita, PPP (constant 2011 international $) &quot; #&gt; 2 NY.GDP.PCAP.PP.KD.87 &quot;GDP per capita, PPP (constant 1987 international $)&quot; #&gt; 3 NY.GDP.PCAP.PP.KD &quot;GDP per capita, PPP (constant 2011 international $)&quot; #&gt; 4 NY.GDP.PCAP.KN &quot;GDP per capita (constant LCU)&quot; #&gt; 5 NY.GDP.PCAP.KD &quot;GDP per capita (constant 2010 US$)&quot; 11.1.2 WDI WDIsearch() 得到了指标的编码之后，就可以用 WDI() 下载相关数据： WDI(country = &quot;all&quot;, indicator = &quot;NY.GNS.ICTR.GN.ZS&quot;, start = NULL, end = NULL, extra = FALSE, cache = NULL) country: 筛选国家或地区。使用 “ISO 3166-1” 两位字母编码，具体可见 mapdata::iso3166。（中国 CN, 美国 US，德国 DE，日本 JP，英国 GB） indicator: 指标的编码。具名向量可以在重命名该指标 start 和 end：时间序列的起始和结束。默认为 1950 年和今年 extra = FALSE： 若 extra = RTUE，返回首都经纬度、地区、收入水平等更多信息 WDI(indicator = &quot;5.51.01.03.mortal&quot;, country = c(&quot;US&quot;, &quot;CN&quot;), start = 2005, end = 2015) %&gt;% as_tibble() #&gt; # A tibble: 11 x 4 #&gt; iso2c country `5.51.01.03.mortal` year #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 CN China 1 2015 #&gt; 2 CN China 1 2014 #&gt; 3 CN China 1 2013 #&gt; 4 CN China 1 2012 #&gt; 5 CN China 1 2011 #&gt; 6 CN China 1 2010 #&gt; # … with 5 more rows # renaming and extra = TRUE WDI(indicator = c(child_motality = &quot;5.51.01.03.mortal&quot;), country = c(&quot;US&quot;, &quot;CN&quot;), start = 2005, end = 2015, extra = TRUE) %&gt;% as_tibble() #&gt; # A tibble: 11 x 11 #&gt; iso2c country child_motality year iso3c region capital longitude latitude #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; #&gt; 1 CN China 1 2015 CHN East … Beijing 116.286 40.0495 #&gt; 2 CN China 1 2014 CHN East … Beijing 116.286 40.0495 #&gt; 3 CN China 1 2013 CHN East … Beijing 116.286 40.0495 #&gt; 4 CN China 1 2012 CHN East … Beijing 116.286 40.0495 #&gt; 5 CN China 1 2011 CHN East … Beijing 116.286 40.0495 #&gt; 6 CN China 1 2010 CHN East … Beijing 116.286 40.0495 #&gt; # … with 5 more rows, and 2 more variables: income &lt;fct&gt;, lending &lt;fct&gt; 11.2 ipumsr https://github.com/mnpopcenter/ipumsr # install.packages(&quot;ipumsr&quot;) "],
["data-table.html", "12 data.table 12.1 dtplyr 12.2 maditr 12.3 tidyfast 12.4 disk.frame", " 12 data.table data.table(Dowle and Srinivasan 2019) https://rdatatable.gitlab.io/data.table/ https://m-clark.github.io/data-processing-and-visualization/data_table.html library(data.table) dt &lt;- data.table(x = rnorm(1000), y = rnorm(1000)) dt #&gt; x y #&gt; 1: 0.7877 -0.274 #&gt; 2: -0.4220 1.587 #&gt; 3: 0.0569 0.446 #&gt; 4: 0.7106 1.885 #&gt; 5: -1.5875 -0.761 #&gt; --- #&gt; 996: 0.2178 0.101 #&gt; 997: 0.1257 1.300 #&gt; 998: 0.4027 -0.512 #&gt; 999: 1.6292 0.761 #&gt; 1000: 1.3437 -0.174 dt[, z := rnorm(1000)] dt #&gt; x y z #&gt; 1: 0.7877 -0.274 0.6987 #&gt; 2: -0.4220 1.587 0.0828 #&gt; 3: 0.0569 0.446 -0.9761 #&gt; 4: 0.7106 1.885 -0.5814 #&gt; 5: -1.5875 -0.761 0.5285 #&gt; --- #&gt; 996: 0.2178 0.101 1.4036 #&gt; 997: 0.1257 1.300 -0.8953 #&gt; 998: 0.4027 -0.512 -0.1449 #&gt; 999: 1.6292 0.761 1.5657 #&gt; 1000: 1.3437 -0.174 1.1179 dt2 &lt;- dt dt[, z := NULL] dt2 #&gt; x y #&gt; 1: 0.7877 -0.274 #&gt; 2: -0.4220 1.587 #&gt; 3: 0.0569 0.446 #&gt; 4: 0.7106 1.885 #&gt; 5: -1.5875 -0.761 #&gt; --- #&gt; 996: 0.2178 0.101 #&gt; 997: 0.1257 1.300 #&gt; 998: 0.4027 -0.512 #&gt; 999: 1.6292 0.761 #&gt; 1000: 1.3437 -0.174 12.1 dtplyr https://dtplyr.tidyverse.org/ 12.2 maditr https://github.com/gdemin/maditr 12.3 tidyfast https://github.com/TysonStanley/tidyfast 12.4 disk.frame https://diskframe.com/ # install.packages(&quot;disk.frame&quot;) "],
["rowwise-operation.html", "13 rowwise operation 13.1 do() + rowwise() 13.2 rap", " 13 rowwise operation 13.1 do() + rowwise() do(mtcars, head(., 2)) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; Mazda RX4 Wag 21 6 160 110 3.9 2.88 17.0 0 1 4 4 do(mtcars, filter(., cyl &gt; 6)) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; 1 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 2 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 #&gt; 3 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 #&gt; 4 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 #&gt; 5 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 #&gt; 6 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 #&gt; 7 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 #&gt; 8 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 #&gt; 9 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 #&gt; 10 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 #&gt; 11 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 #&gt; 12 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 #&gt; 13 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 #&gt; 14 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 by_cyl &lt;- group_by(mtcars, cyl) do(by_cyl, head(., 2)) #&gt; # A tibble: 6 x 11 #&gt; # Groups: cyl [3] #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 #&gt; 2 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 #&gt; 3 21 6 160 110 3.9 2.62 16.5 0 1 4 4 #&gt; 4 21 6 160 110 3.9 2.88 17.0 0 1 4 4 #&gt; 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 #&gt; 6 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 models &lt;- by_cyl %&gt;% do(mod = lm(mpg ~ disp, data = .)) models #&gt; Source: local data frame [3 x 2] #&gt; Groups: &lt;by row&gt; #&gt; #&gt; # A tibble: 3 x 2 #&gt; cyl mod #&gt; * &lt;dbl&gt; &lt;list&gt; #&gt; 1 4 &lt;lm&gt; #&gt; 2 6 &lt;lm&gt; #&gt; 3 8 &lt;lm&gt; models %&gt;% do(data.frame( var = names(coef(.$mod)), coef(summary(.$mod))) ) #&gt; Source: local data frame [6 x 5] #&gt; Groups: &lt;by row&gt; #&gt; #&gt; # A tibble: 6 x 5 #&gt; var Estimate Std..Error t.value Pr...t.. #&gt; * &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 40.9 3.59 11.4 0.00000120 #&gt; 2 disp -0.135 0.0332 -4.07 0.00278 #&gt; 3 (Intercept) 19.1 2.91 6.55 0.00124 #&gt; 4 disp 0.00361 0.0156 0.232 0.826 #&gt; 5 (Intercept) 22.0 3.35 6.59 0.0000259 #&gt; 6 disp -0.0196 0.00932 -2.11 0.0568 by_cyl %&gt;% group_modify(~ broom::tidy(lm(mpg ~ disp, data = .))) #&gt; # A tibble: 6 x 6 #&gt; # Groups: cyl [3] #&gt; cyl term estimate std.error statistic p.value #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 (Intercept) 40.9 3.59 11.4 0.00000120 #&gt; 2 4 disp -0.135 0.0332 -4.07 0.00278 #&gt; 3 6 (Intercept) 19.1 2.91 6.55 0.00124 #&gt; 4 6 disp 0.00361 0.0156 0.232 0.826 #&gt; 5 8 (Intercept) 22.0 3.35 6.59 0.0000259 #&gt; 6 8 disp -0.0196 0.00932 -2.11 0.0568 df &lt;- expand.grid(x = 1:3, y = 3:1) df_done &lt;- df %&gt;% rowwise() %&gt;% do(i = seq(.$x, .$y)) df_done #&gt; Source: local data frame [9 x 1] #&gt; Groups: &lt;by row&gt; #&gt; #&gt; # A tibble: 9 x 1 #&gt; i #&gt; * &lt;list&gt; #&gt; 1 &lt;int [3]&gt; #&gt; 2 &lt;int [2]&gt; #&gt; 3 &lt;int [1]&gt; #&gt; 4 &lt;int [2]&gt; #&gt; 5 &lt;int [1]&gt; #&gt; 6 &lt;int [2]&gt; #&gt; # … with 3 more rows df_done %&gt;% summarise(n = length(i)) #&gt; # A tibble: 9 x 1 #&gt; n #&gt; &lt;int&gt; #&gt; 1 3 #&gt; 2 2 #&gt; 3 1 #&gt; 4 2 #&gt; 5 1 #&gt; 6 2 #&gt; # … with 3 more rows 13.2 rap see https://github.com/romainfrancois/rap # devtools::install_github(&quot;romainfrancois/rap&quot;) library(rap) tbl &lt;- tibble(cyl_threshold = c(4, 6, 8), mpg_threshold = c(30, 25, 20)) tbl #&gt; # A tibble: 3 x 2 #&gt; cyl_threshold mpg_threshold #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 30 #&gt; 2 6 25 #&gt; 3 8 20 tbl %&gt;% rap(x = ~ filter(mtcars, cyl == cyl_threshold, mpg &lt; mpg_threshold)) #&gt; # A tibble: 3 x 3 #&gt; cyl_threshold mpg_threshold x #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 4 30 &lt;df[,11] [7 × 11]&gt; #&gt; 2 6 25 &lt;df[,11] [7 × 11]&gt; #&gt; 3 8 20 &lt;df[,11] [14 × 11]&gt; "],
["data-summary.html", "14 Data Summary 14.1 skimr 14.2 visdat 14.3 summarytools", " 14 Data Summary 14.1 skimr skimr(Waring et al. 2019) 是由 rOpenSci project 开发的用于探索性数据分析的包，可以看作增强版的 summary()，根据不同的列类型返回整洁有用的统计量。如： library(skimr) skim(iris) #&gt; -- Data Summary ------------------------ #&gt; Values #&gt; Name iris #&gt; Number of rows 150 #&gt; Number of columns 5 #&gt; _______________________ #&gt; Column type frequency: #&gt; factor 1 #&gt; numeric 4 #&gt; ________________________ #&gt; Group variables None #&gt; #&gt; -- Variable type: factor ----------------------------------------------------------------------------------------------- #&gt; skim_variable n_missing complete_rate ordered n_unique #&gt; 1 Species 0 1 FALSE 3 #&gt; top_counts #&gt; 1 set: 50, ver: 50, vir: 50 #&gt; #&gt; -- Variable type: numeric ---------------------------------------------------------------------------------------------- #&gt; skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 #&gt; 1 Sepal.Length 0 1 5.84 0.828 4.3 5.1 5.8 6.4 #&gt; 2 Sepal.Width 0 1 3.06 0.436 2 2.8 3 3.3 #&gt; 3 Petal.Length 0 1 3.76 1.77 1 1.6 4.35 5.1 #&gt; 4 Petal.Width 0 1 1.20 0.762 0.1 0.3 1.3 1.8 #&gt; p100 hist #&gt; 1 7.9 &lt;U+2586&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2582&gt; #&gt; 2 4.4 &lt;U+2581&gt;&lt;U+2586&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2581&gt; #&gt; 3 6.9 &lt;U+2587&gt;&lt;U+2581&gt;&lt;U+2586&gt;&lt;U+2587&gt;&lt;U+2582&gt; #&gt; 4 2.5 &lt;U+2587&gt;&lt;U+2581&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2583&gt; 由于 skim() 的返回结果在 bookdown 里显示效果不太好，这里只给出一个最简单的例子，关于该包的具体使用可见 Introduction to skimr 14.2 visdat # install.packages(&quot;visdata&quot;) library(visdat) https://docs.ropensci.org/visdat/ vis_dat(ggplot2::diamonds) 14.3 summarytools 由于很多 summarytools 中的函数往往直接生成 markdown 代码，为了在 rmarkdown 正确美观的呈现它们需要同时设置 summarytools 中和 knitr 中的一些全局选项：（详细可见Recommendations for Using summarytools With Rmarkdown）。 library(summarytools) st_options(bootstrap.css = FALSE, # Already part of the theme so no need for it plain.ascii = FALSE, # One of the essential settings style = &quot;rmarkdown&quot;, # Idem. dfSummary.silent = TRUE, # Suppresses messages about temporary files footnote = NA, # Keeping the results minimalistic subtitle.emphasis = FALSE) # For the vignette theme, this gives # much better results. Your mileage may vary. st_css() # This is a must; without it, expect odd layout, especially with dfSummary() #&gt; &lt;style type=&quot;text/css&quot;&gt; #&gt; img { background-color: transparent; border: 0; } .st-table td, .st-table th { padding: 8px; } .st-table &gt; thead &gt; tr { background-color: #eeeeee; } .st-cross-table td { text-align: center; } .st-descr-table td { text-align: right; } .st-small { font-size: 13px; } .st-small td, .st-small th { padding: 8px; } table.st-table th { text-align: center; } .st-small &gt; thead &gt; tr &gt; th, .st-small &gt; tbody &gt; tr &gt; th, .st-small &gt; tfoot &gt; tr &gt; th, .st-small &gt; thead &gt; tr &gt; td, .st-small &gt; tbody &gt; tr &gt; td, .st-small &gt; tfoot &gt; tr &gt; td { padding-left: 12px; padding-right: 12px; } table.st-table &gt; thead &gt; tr { background-color: #eeeeee; } table.st-table td span { display: block; } .st-container { width: 100%; padding-right: 15px; padding-left: 15px; margin-right: auto; margin-left: auto; margin-top: 15px; } .st-multiline { white-space: pre; } .st-table { width: auto; table-layout: auto; margin-top: 20px; margin-bottom: 20px; max-width: 100%; background-color: transparent; border-collapse: collapse; } .st-table &gt; thead &gt; tr &gt; th, .st-table &gt; tbody &gt; tr &gt; th, .st-table &gt; tfoot &gt; tr &gt; th, .st-table &gt; thead &gt; tr &gt; td, .st-table &gt; tbody &gt; tr &gt; td, .st-table &gt; tfoot &gt; tr &gt; td { vertical-align: middle; } .st-table-bordered { border: 1px solid #bbbbbb; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; tbody &gt; tr &gt; th, .st-table-bordered &gt; tfoot &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table-bordered &gt; tbody &gt; tr &gt; td, .st-table-bordered &gt; tfoot &gt; tr &gt; td { border: 1px solid #cccccc; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table thead &gt; tr &gt; th { border-bottom: none; } .st-freq-table &gt; thead &gt; tr &gt; th, .st-freq-table &gt; tbody &gt; tr &gt; th, .st-freq-table &gt; tfoot &gt; tr &gt; th, .st-freq-table &gt; thead &gt; tr &gt; td, .st-freq-table &gt; tbody &gt; tr &gt; td, .st-freq-table &gt; tfoot &gt; tr &gt; td, .st-freq-table-nomiss &gt; thead &gt; tr &gt; th, .st-freq-table-nomiss &gt; tbody &gt; tr &gt; th, .st-freq-table-nomiss &gt; tfoot &gt; tr &gt; th, .st-freq-table-nomiss &gt; thead &gt; tr &gt; td, .st-freq-table-nomiss &gt; tbody &gt; tr &gt; td, .st-freq-table-nomiss &gt; tfoot &gt; tr &gt; td, .st-cross-table &gt; thead &gt; tr &gt; th, .st-cross-table &gt; tbody &gt; tr &gt; th, .st-cross-table &gt; tfoot &gt; tr &gt; th, .st-cross-table &gt; thead &gt; tr &gt; td, .st-cross-table &gt; tbody &gt; tr &gt; td, .st-cross-table &gt; tfoot &gt; tr &gt; td { padding-left: 20px; padding-right: 20px; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; tbody &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table-bordered &gt; tbody &gt; tr &gt; td { border: 1px solid #cccccc; } .st-table-striped &gt; tbody &gt; tr:nth-of-type(odd) { background-color: #ffffff; } .st-table-striped &gt; tbody &gt; tr:nth-of-type(even) { background-color: #f9f9f9; } .st-descr-table &gt; thead &gt; tr &gt; th, .st-descr-table &gt; tbody &gt; tr &gt; th, .st-descr-table &gt; tfoot &gt; tr &gt; th, .st-descr-table &gt; thead &gt; tr &gt; td, .st-descr-table &gt; tbody &gt; tr &gt; td, .st-descr-table &gt; tfoot &gt; tr &gt; td { padding-left: 24px; padding-right: 24px; word-wrap: break-word; } .st-freq-table, .st-freq-table-nomiss, .st-cross-table { border: medium none; } .st-freq-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(1), .st-cross-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(1), .st-cross-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(3) { border: none; background-color: #ffffff; text-align: center; } .st-protect-top-border { border-top: 1px solid #cccccc !important; } .st-ws-char { display: inline; color: #999999; letter-spacing: 0.2em; } &lt;/style&gt; library(knitr) opts_chunk$set(comment = NA, prompt = FALSE, results=&#39;asis&#39;, collapse = FALSE) 如果之前没有设置 collpase = TRUE, collapse = FALSE 不是必要的 14.3.1 freq freq(iris$Species, plain.ascii = FALSE, style = &quot;rmarkdown&quot;, headings = FALSE) | &amp;nbsp; | Freq | % Valid | % Valid Cum. | % Total | % Total Cum. | |---------------:|-----:|--------:|-------------:|--------:|-------------:| | **setosa** | 50 | 33.33 | 33.33 | 33.33 | 33.33 | | **versicolor** | 50 | 33.33 | 66.67 | 33.33 | 66.67 | | **virginica** | 50 | 33.33 | 100.00 | 33.33 | 100.00 | | **\\&lt;NA\\&gt;** | 0 | | | 0.00 | 100.00 | | **Total** | 150 | 100.00 | 100.00 | 100.00 | 100.00 | freq(iris$Species, report.nas = FALSE, headings = FALSE) #&gt; #&gt; Freq % % Cum. #&gt; ---------------- ------ -------- -------- #&gt; setosa 50 33.33 33.33 #&gt; versicolor 50 33.33 66.67 #&gt; virginica 50 33.33 100.00 #&gt; Total 150 100.00 100.00 freq(iris$Species, report.nas = FALSE, totals = FALSE, cumul = FALSE, style = &quot;rmarkdown&quot;, headings = FALSE) #&gt; #&gt; | &amp;nbsp; | Freq | % | #&gt; |---------------:|-----:|------:| #&gt; | **setosa** | 50 | 33.33 | #&gt; | **versicolor** | 50 | 33.33 | #&gt; | **virginica** | 50 | 33.33 | 14.3.2 descr() descr(iris) #&gt; Descriptive Statistics #&gt; iris #&gt; N: 150 #&gt; #&gt; Petal.Length Petal.Width Sepal.Length Sepal.Width #&gt; ----------------- -------------- ------------- -------------- ------------- #&gt; Mean 3.76 1.20 5.84 3.06 #&gt; Std.Dev 1.77 0.76 0.83 0.44 #&gt; Min 1.00 0.10 4.30 2.00 #&gt; Q1 1.60 0.30 5.10 2.80 #&gt; Median 4.35 1.30 5.80 3.00 #&gt; Q3 5.10 1.80 6.40 3.30 #&gt; Max 6.90 2.50 7.90 4.40 #&gt; MAD 1.85 1.04 1.04 0.44 #&gt; IQR 3.50 1.50 1.30 0.50 #&gt; CV 0.47 0.64 0.14 0.14 #&gt; Skewness -0.27 -0.10 0.31 0.31 #&gt; SE.Skewness 0.20 0.20 0.20 0.20 #&gt; Kurtosis -1.42 -1.36 -0.61 0.14 #&gt; N.Valid 150.00 150.00 150.00 150.00 #&gt; Pct.Valid 100.00 100.00 100.00 100.00 "],
["janitor.html", "15 Janitor 15.1 清洗 15.2 探索", " 15 Janitor http://sfirke.github.io/janitor/articles/janitor.html Janitor(Firke 2019) 包提供了一些简单易用的函数方便数据清洗和探索流程。 library(janitor) 15.1 清洗 15.1.1 clean_names clean_names() 将输入数据框的列名转换为整洁格式，与 readxl::read_excel() 和 readr::read_csv() 等不会擅自修改原列名的函数搭配使用效果最佳。 clean_names() 的 输入输出 都是数据框，这使它很适应和管道操作符 %&gt;% 和 tidyverse 中的其他函数一同工作。 列名的转换有以下几种主要情形： 统一字母的大小写，采用一致的命名方式（默认为蛇形命名法 snake_case） 自动为重复的列名编号，填充空的列名 删除空格和某些特殊字符，如括号， œ、oe “%” 转换至 “percent”, “#” 转换至 “number” # Create a data.frame with dirty names test_df &lt;- as.data.frame(matrix(ncol = 6)) names(test_df) &lt;- c(&quot;firstName&quot;, &quot;ábc@!*&quot;, &quot;% successful (2009)&quot;, &quot;REPEAT VALUE&quot;, &quot;REPEAT VALUE&quot;, &quot;&quot;) # Clean the variable names, returning a data.frame: test_df %&gt;% clean_names() #&gt; first_name abc percent_successful_2009 repeat_value repeat_value_2 x #&gt; 1 NA NA NA NA NA NA 与 Base R 中的 make.names() 对比 (注意这个函数不是基于数据框的)： names(test_df) %&gt;% make.names() #&gt; [1] &quot;firstName&quot; &quot;ábc...&quot; &quot;X..successful..2009.&quot; #&gt; [4] &quot;REPEAT.VALUE&quot; &quot;REPEAT.VALUE&quot; &quot;X&quot; 改变命名规范： ## snake_case test_df %&gt;% clean_names() #&gt; first_name abc percent_successful_2009 repeat_value repeat_value_2 x #&gt; 1 NA NA NA NA NA NA ## lower_camel and upper_camel test_df %&gt;% clean_names(case = &quot;lower_camel&quot;) #&gt; firstName abc percentSuccessful2009 repeatValue repeatValue_2 x #&gt; 1 NA NA NA NA NA NA test_df %&gt;% clean_names(case = &quot;upper_camel&quot;) #&gt; FirstName Abc PercentSuccessful2009 RepeatValue RepeatValue_2 X #&gt; 1 NA NA NA NA NA NA make_clean_names() 是 clean_names() 的向量版本，它还可以传入 as_tibble() 中的 .name_repair 参数中： names(test_df) %&gt;% make_clean_names() #&gt; [1] &quot;first_name&quot; &quot;abc&quot; #&gt; [3] &quot;percent_successful_2009&quot; &quot;repeat_value&quot; #&gt; [5] &quot;repeat_value_2&quot; &quot;x&quot; as_tibble(iris, .name_repair = janitor::make_clean_names) #&gt; # A tibble: 150 x 5 #&gt; sepal_length sepal_width petal_length petal_width species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; # … with 144 more rows 15.1.2 compare_df_cols 使用 dplyr::bind_rows() 或者 rbind()，或者存在子集关系。compare_df_cols()` 检查多个数据框或者数据框列表，并检查其各个列是否一致： df1 &lt;- data.frame(a = 1:2, b = c(&quot;big&quot;, &quot;small&quot;)) # a factor by default df2 &lt;- data.frame(a = 10:12, b = c(&quot;medium&quot;, &quot;small&quot;, &quot;big&quot;), c = 0, stringsAsFactors = FALSE) df3 &lt;- df1 %&gt;% mutate(b = as.character(b)) compare_df_cols(df1, df2, df3) #&gt; column_name df1 df2 df3 #&gt; 1 a integer integer integer #&gt; 2 b factor character character #&gt; 3 c &lt;NA&gt; numeric &lt;NA&gt; compare_df_cols(df1, df2, df3, return = &quot;mismatch&quot;) #&gt; column_name df1 df2 df3 #&gt; 1 b factor character character dplyr::bind_rows() 比 rbind() 的合并要宽松，允许某些数据框的列集合是其余数据框的子集： compare_df_cols(df1, df2, df3, return = &quot;mismatch&quot;, bind_method = &quot;rbind&quot;) #&gt; column_name df1 df2 df3 #&gt; 1 b factor character character #&gt; 2 c &lt;NA&gt; numeric &lt;NA&gt; # default is dplyr::bind_rows compare_df_cols_same 返回 TRUE 或 FALSE: compare_df_cols_same(df1, df3) #&gt; column_name ..1 ..2 #&gt; 1 b factor character #&gt; [1] FALSE compare_df_cols_same(df2, df3) #&gt; [1] TRUE 15.2 探索 15.2.1 tabyl tabyl() 的设计初衷是替代 Base R 中 table()，后者有几个缺点： 不接受数据框输入 不返回数据框 返回的结果很难进一步修饰 tabyl() 用于构建 1 ~ 3 个变量的（交叉）频数表，它 建立在 dplyr 和 tidyr 之上，所以以数据框基本输入、输出对象（但也可以接受一维向量），janitor 还提供了 adorn_* 函数族对其返回的表格进行修饰。以 starwars的一个子集演示 tabyl() 的用法： humans &lt;- starwars %&gt;% filter(species == &quot;Human&quot;) One-way tabyl 一维频数表 t1 &lt;- humans %&gt;% tabyl(eye_color) t1 #&gt; eye_color n percent #&gt; blue 12 0.3429 #&gt; blue-gray 1 0.0286 #&gt; brown 17 0.4857 #&gt; dark 1 0.0286 #&gt; hazel 2 0.0571 #&gt; yellow 2 0.0571 tably() 可以聪明地处理数据中包含缺失值的情况： x &lt;- c(&quot;big&quot;, &quot;big&quot;, &quot;small&quot;, &quot;small&quot;, &quot;small&quot;, NA) tabyl(x) #&gt; x n percent valid_percent #&gt; big 2 0.333 0.4 #&gt; small 3 0.500 0.6 #&gt; &lt;NA&gt; 1 0.167 NA tabyl(x, show_na = F) #&gt; x n percent #&gt; big 2 0.4 #&gt; small 3 0.6 大部分 adorn_* 函数主要用于二维列联表，但也可以适用一维频数表： t1 %&gt;% adorn_pct_formatting() #&gt; eye_color n percent #&gt; blue 12 34.3% #&gt; blue-gray 1 2.9% #&gt; brown 17 48.6% #&gt; dark 1 2.9% #&gt; hazel 2 5.7% #&gt; yellow 2 5.7% Two-way tabyl df %&gt;% tabyl(var_1, var_2) 等同于 df %&gt;% count(var_1, var_2) 后 pivot_wider() 展开其中的某一列，生成列联表： t2 &lt;- humans %&gt;% tabyl(gender, eye_color) t2 #&gt; gender blue blue-gray brown dark hazel yellow #&gt; female 3 0 5 0 1 0 #&gt; male 9 1 12 1 1 2 # count() + pivot_wider() humans %&gt;% count(gender, eye_color) %&gt;% pivot_wider(names_from = eye_color, values_from = n) #&gt; # A tibble: 2 x 7 #&gt; gender blue brown hazel `blue-gray` dark yellow #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 female 3 5 1 NA NA NA #&gt; 2 male 9 12 1 1 1 2 用于修饰的 adorn_* 函数有： adorn_totals(c(\"row\", \"col\")): 添加行列汇总 adorn_percentages(c(\"row\", \"col\"))： 将交叉表的指替换为行或列百分比 adorn_pct_formatting(digits, rounding): 决定百分比的格式 adorn_rounding(): Round a data.frame of numbers (usually the result of adorn_percentages), either using the base R round() function or using janitor’s round_half_up() to round all ties up (thanks, StackOverflow). e.g., round 10.5 up to 11, consistent with Excel’s tie-breaking behavior. This contrasts with rounding 10.5 down to 10 as in base R’s round(10.5). adorn_rounding() returns columns of class numeric, allowing for graphing, sorting, etc. It’s a less-aggressive substitute for adorn_pct_formatting(); these two functions should not be called together. adorn_ns(): add Ns to a tabyl. These can be drawn from the tabyl’s underlying counts, which are attached to the tabyl as metadata, or they can be supplied by the user. adorn_title(placement, row_name, col_name): “combined” 或者 “top”，调整行变量名称的位置 注意在应用这些帮助函数时要遵从一定的逻辑顺序。例如，adorn_ns() 和 adorn_percent_fomatting() 应该在调用 adorn_percentages() 之后。 对 t2 应用 adorn_* 函数： t2 %&gt;% adorn_totals(&quot;col&quot;) %&gt;% adorn_percentages(&quot;row&quot;) %&gt;% adorn_pct_formatting(digits = 2) %&gt;% adorn_ns() %&gt;% adorn_title(&quot;combined&quot;) #&gt; gender/eye_color blue blue-gray brown dark hazel #&gt; female 33.33% (3) 0.00% (0) 55.56% (5) 0.00% (0) 11.11% (1) #&gt; male 34.62% (9) 3.85% (1) 46.15% (12) 3.85% (1) 3.85% (1) #&gt; yellow Total #&gt; 0.00% (0) 100.00% (9) #&gt; 7.69% (2) 100.00% (26) tabyl 对象最终可以传入 knitr::kabel() 中呈现 t2 %&gt;% adorn_totals(&quot;row&quot;) %&gt;% adorn_percentages(&quot;col&quot;) %&gt;% adorn_pct_formatting(digits = 1) %&gt;% adorn_ns() %&gt;% adorn_title(&quot;top&quot;, row_name = &quot;gender&quot;, col_name = &quot;color&quot;) %&gt;% knitr::kable() color gender blue blue-gray brown dark hazel yellow female 25.0% (3) 0.0% (0) 29.4% (5) 0.0% (0) 50.0% (1) 0.0% (0) male 75.0% (9) 100.0% (1) 70.6% (12) 100.0% (1) 50.0% (1) 100.0% (2) Total 100.0% (12) 100.0% (1) 100.0% (17) 100.0% (1) 100.0% (2) 100.0% (2) Three-way tabyl 在 tabyl() 中传入三个变量时，返回一个二维 tabyl 的列表： t3 &lt;- humans %&gt;% tabyl(eye_color, skin_color, gender) t3 #&gt; $female #&gt; eye_color dark fair light pale tan white #&gt; blue 0 2 1 0 0 0 #&gt; blue-gray 0 0 0 0 0 0 #&gt; brown 0 1 4 0 0 0 #&gt; dark 0 0 0 0 0 0 #&gt; hazel 0 0 1 0 0 0 #&gt; yellow 0 0 0 0 0 0 #&gt; #&gt; $male #&gt; eye_color dark fair light pale tan white #&gt; blue 0 7 2 0 0 0 #&gt; blue-gray 0 1 0 0 0 0 #&gt; brown 3 4 3 0 2 0 #&gt; dark 1 0 0 0 0 0 #&gt; hazel 0 1 0 0 0 0 #&gt; yellow 0 0 0 1 0 1 这时的 adorn_* 函数将会应用于列表中的每个 tabyl 元素： t3 %&gt;% adorn_percentages(&quot;row&quot;) %&gt;% adorn_pct_formatting(digits = 0) %&gt;% adorn_ns() #&gt; $female #&gt; eye_color dark fair light pale tan white #&gt; blue 0% (0) 67% (2) 33% (1) 0% (0) 0% (0) 0% (0) #&gt; blue-gray - (0) - (0) - (0) - (0) - (0) - (0) #&gt; brown 0% (0) 20% (1) 80% (4) 0% (0) 0% (0) 0% (0) #&gt; dark - (0) - (0) - (0) - (0) - (0) - (0) #&gt; hazel 0% (0) 0% (0) 100% (1) 0% (0) 0% (0) 0% (0) #&gt; yellow - (0) - (0) - (0) - (0) - (0) - (0) #&gt; #&gt; $male #&gt; eye_color dark fair light pale tan white #&gt; blue 0% (0) 78% (7) 22% (2) 0% (0) 0% (0) 0% (0) #&gt; blue-gray 0% (0) 100% (1) 0% (0) 0% (0) 0% (0) 0% (0) #&gt; brown 25% (3) 33% (4) 25% (3) 0% (0) 17% (2) 0% (0) #&gt; dark 100% (1) 0% (0) 0% (0) 0% (0) 0% (0) 0% (0) #&gt; hazel 0% (0) 100% (1) 0% (0) 0% (0) 0% (0) 0% (0) #&gt; yellow 0% (0) 0% (0) 0% (0) 50% (1) 0% (0) 50% (1) 15.2.2 get_dupes get_dupes(dat, ...) 返回数据框dat中在变量...上重复的观测，以及重复的次数： mtcars %&gt;% get_dupes(wt, cyl) #&gt; # A tibble: 4 x 12 #&gt; wt cyl dupe_count mpg disp hp drat qsec vs am gear carb #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 3.44 6 2 19.2 168. 123 3.92 18.3 1 0 4 4 #&gt; 2 3.44 6 2 17.8 168. 123 3.92 18.9 1 0 4 4 #&gt; 3 3.57 8 2 14.3 360 245 3.21 15.8 0 0 3 4 #&gt; 4 3.57 8 2 15 301 335 3.54 14.6 0 1 5 8 15.2.3 remove_ 15.2.3.1 remove_empty remove_empty(c(\"rows\", \"cols\")) 移除行或列（或行和列）上全为 NA 值的观测： q &lt;- data.frame(v1 = c(1, NA, 3), v2 = c(NA, NA, NA), v3 = c(&quot;a&quot;, NA, &quot;b&quot;)) q %&gt;% remove_empty(c(&quot;rows&quot;, &quot;cols&quot;)) #&gt; v1 v3 #&gt; 1 1 a #&gt; 3 3 b q %&gt;% remove_empty(&quot;rows&quot;) #&gt; v1 v2 v3 #&gt; 1 1 NA a #&gt; 3 3 NA b q %&gt;% remove_empty(&quot;cols&quot;) #&gt; v1 v3 #&gt; 1 1 a #&gt; 2 NA &lt;NA&gt; #&gt; 3 3 b remove_empty 的实现原理很简单，以移除空的行观测为例：如果某行全为 NA，则该行对应的 rowSums(is.na(dat)) = ncol(dat): function (dat, which = c(&quot;rows&quot;, &quot;cols&quot;)) { if (missing(which) &amp;&amp; !missing(dat)) { message(&quot;value for \\&quot;which\\&quot; not specified, defaulting to c(\\&quot;rows\\&quot;, \\&quot;cols\\&quot;)&quot;) which &lt;- c(&quot;rows&quot;, &quot;cols&quot;) } if ((sum(which %in% c(&quot;rows&quot;, &quot;cols&quot;)) != length(which)) &amp;&amp; !missing(dat)) { stop(&quot;\\&quot;which\\&quot; must be one of \\&quot;rows\\&quot;, \\&quot;cols\\&quot;, or c(\\&quot;rows\\&quot;, \\&quot;cols\\&quot;)&quot;) } if (&quot;rows&quot; %in% which) { dat &lt;- dat[rowSums(is.na(dat)) != ncol(dat), , drop = FALSE] } if (&quot;cols&quot; %in% which) { dat &lt;- dat[, colSums(!is.na(dat)) &gt; 0, drop = FALSE] } dat } 15.2.3.2 remove_constant remove_constant() 移除数据框中的常数列： a &lt;- data.frame(good = 1:3, boring = &quot;the same&quot;) a %&gt;% remove_constant() #&gt; good #&gt; 1 1 #&gt; 2 2 #&gt; 3 3 15.2.4 round_half_up Base R 中的取整函数 round() 采取的规则是 “四舍六入五留双”（Banker’s Rounding，当小数位是 .5 时，若前一位是奇数，则进 1 ； 若前一位数偶数，则退一）： nums &lt;- c(2.5, 3.5) round(nums) #&gt; [1] 2 4 round_half_up 遵循最简单的四舍五入规则: round_half_up(nums) #&gt; [1] 3 4 若希望取整到特定的小数位，例如 0, 0.25, 0.5, 0.75, 1。可以用 round_half_fraction() 并指定除数 15.2.5 excel_numeric_to_date excel_numeric_to_date() 按照 Excel 编码日期的规则(1989/12/31 = 1) 将整数转换为数字： excel_numeric_to_date(41103) #&gt; [1] &quot;2012-07-13&quot; excel_numeric_to_date(41103.01) # ignores decimal places, returns Date object #&gt; [1] &quot;2012-07-13&quot; 15.2.6 top_levels 在李克特量表数据的分析中，常需要知道某个态度变量中占比最高的几个水平，这样的变量在 R 中以有序因子的方式储存，top_levels() 将有序因子的所有水平分为三组（左，中间，右），并分别呈现各组的频数： f &lt;- factor(c(&quot;strongly agree&quot;, &quot;agree&quot;, &quot;neutral&quot;, &quot;neutral&quot;, &quot;disagree&quot;, &quot;strongly agree&quot;), levels = c(&quot;strongly agree&quot;, &quot;agree&quot;, &quot;neutral&quot;, &quot;disagree&quot;, &quot;strongly disagree&quot;)) top_levels(f) #&gt; f n percent #&gt; strongly agree, agree 3 0.500 #&gt; neutral 2 0.333 #&gt; disagree, strongly disagree 1 0.167 top_levels(as.factor(mtcars$hp)) #&gt; as.factor(mtcars$hp) n percent #&gt; 52, 62 2 0.0625 #&gt; &lt;&lt;&lt; Middle Group (18 categories) &gt;&gt;&gt; 28 0.8750 #&gt; 264, 335 2 0.0625 改变两侧分组包含水平的个数： top_levels(as.factor(mtcars$hp), n = 4) #&gt; as.factor(mtcars$hp) n percent #&gt; 52, 62, 65, 66 5 0.156 #&gt; &lt;&lt;&lt; Middle Group (14 categories) &gt;&gt;&gt; 22 0.688 #&gt; 230, 245, 264, 335 5 0.156 15.2.7 row_to_names row_to_names() 将某个观测行提升至列名： dirt &lt;- data.frame(X_1 = c(NA, &quot;ID&quot;, 1:3), X_2 = c(NA, &quot;Value&quot;, 4:6)) dirt #&gt; X_1 X_2 #&gt; 1 &lt;NA&gt; &lt;NA&gt; #&gt; 2 ID Value #&gt; 3 1 4 #&gt; 4 2 5 #&gt; 5 3 6 dirt %&gt;% row_to_names(row_number = 2, remove_rows_above = F) #&gt; ID Value #&gt; 1 &lt;NA&gt; &lt;NA&gt; #&gt; 3 1 4 #&gt; 4 2 5 #&gt; 5 3 6 dirt %&gt;% row_to_names(row_number = 2, remove_rows_above = T) #&gt; ID Value #&gt; 3 1 4 #&gt; 4 2 5 #&gt; 5 3 6 "],
["missing-values.html", "16 处理缺失值 16.1 探索 16.2 填充", " 16 处理缺失值 16.1 探索 drop_na() 根据列去除带有缺失值的观测： df &lt;- tibble(x = c(1, 2, NA), y = c(&quot;a&quot;, NA, &quot;b&quot;)) df %&gt;% drop_na() # df %&gt;% drop_na(x, y) #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 a df %&gt;% drop_na(x) #&gt; # A tibble: 2 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 a #&gt; 2 2 &lt;NA&gt; 16.2 填充 https://jiangjun.link/post/2018/12/r-missing-data 用中位数或均值填补缺失值 library(tidyverse) df &lt;- tibble(x = c(1, 2, NA, 5, 9, NA), y = c(NA, 20, 1, NA, 5, NA), z = 5:10) df %&gt;% mutate_all( ~ ifelse(is.na(.x), median(.x, na.rm = T), .)) #&gt; # A tibble: 6 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 1 5 5 #&gt; 2 2 20 6 #&gt; 3 3.5 1 7 #&gt; 4 5 5 8 #&gt; 5 9 5 9 #&gt; 6 3.5 5 10 16 中的 fill(): df &lt;- data.frame(Month = c(1:8, NA, 10), Year = c(2000, rep(NA, 9)), values = c(NA, 12:20)) df #&gt; Month Year values #&gt; 1 1 2000 NA #&gt; 2 2 NA 12 #&gt; 3 3 NA 13 #&gt; 4 4 NA 14 #&gt; 5 5 NA 15 #&gt; 6 6 NA 16 #&gt; 7 7 NA 17 #&gt; 8 8 NA 18 #&gt; 9 NA NA 19 #&gt; 10 10 NA 20 df %&gt;% fill(starts_with(&quot;Y&quot;), .direction = &quot;down&quot;) #&gt; Month Year values #&gt; 1 1 2000 NA #&gt; 2 2 2000 12 #&gt; 3 3 2000 13 #&gt; 4 4 2000 14 #&gt; 5 5 2000 15 #&gt; 6 6 2000 16 #&gt; 7 7 2000 17 #&gt; 8 8 2000 18 #&gt; 9 NA 2000 19 #&gt; 10 10 2000 20 或者 janitor::remove_empty() full_seq()，得到完整的序列： full_seq(c(1, 2, 4, 5, 10), 1) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 replace_na() replace missing values: df &lt;- tibble(x = c(1, 2, NA), y = c(&quot;a&quot;, NA, &quot;b&quot;), z = list(1:5, NULL, 10:20)) df %&gt;% mutate(x = replace_na(x, 0)) #&gt; # A tibble: 3 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;list&gt; #&gt; 1 1 a &lt;int [5]&gt; #&gt; 2 2 &lt;NA&gt; &lt;NULL&gt; #&gt; 3 0 b &lt;int [11]&gt; df %&gt;% replace_na(list(x = 0, y = &quot;unknown&quot;)) #&gt; # A tibble: 3 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;list&gt; #&gt; 1 1 a &lt;int [5]&gt; #&gt; 2 2 unknown &lt;NULL&gt; #&gt; 3 0 b &lt;int [11]&gt; # NULL are the list-col equivalent of NAs df %&gt;% replace_na(list(z = list(5))) #&gt; # A tibble: 3 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;list&gt; #&gt; 1 1 a &lt;int [5]&gt; #&gt; 2 2 &lt;NA&gt; &lt;dbl [1]&gt; #&gt; 3 NA b &lt;int [11]&gt; df$x %&gt;% replace_na(0) #&gt; [1] 1 2 0 df$y %&gt;% replace_na(&quot;unknown&quot;) #&gt; [1] &quot;a&quot; &quot;unknown&quot; &quot;b&quot; visdat::vis_missing() library(visdat) vis_miss(df) more advanced: mice 或 Amelia "],
["tidymodels.html", "17 tidymodels", " 17 tidymodels https://www.tidyverse.org/blog/2018/08/tidymodels-0-0-1/ "],
["caret.html", "18 caret", " 18 caret https://github.com/topepo/caret "],
["vtreat.html", "19 vtreat", " 19 vtreat https://winvector.github.io/vtreat/ "],
["references.html", "References", " References Arel-Bundock, Vincent. 2019. WDI: World Development Indicators (World Bank). https://CRAN.R-project.org/package=WDI. Dowle, Matt, and Arun Srinivasan. 2019. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table. Firke, Sam. 2019. Janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor. Hester, Jim, and Hadley Wickham. 2019. Vroom: Read and Write Rectangular Text Data Quickly. https://CRAN.R-project.org/package=vroom. R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Waring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2019. Skimr: Compact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr. Wickham, Hadley, and Garrett Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. \" O’Reilly Media, Inc.\". "]
]
