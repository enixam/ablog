<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Qiushi Yan">

  
  
  
    
  
  <meta name="description" content="Practice on data cleaning, text analysis and multicategory logistic models with penalization">

  
  <link rel="alternate" hreflang="en-us" href="/post/2020-05-07-analyzing-animal-crossing-reviews/">

  


  
  
  
  <meta name="theme-color" content="#328cc1">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Arapey:400,400i%7CKarla:400,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-165703248-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-165703248-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/2020-05-07-analyzing-animal-crossing-reviews/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@qiushizzzz">
  <meta property="twitter:creator" content="@qiushizzzz">
  
  <meta property="og:site_name" content="Qiushi Yan">
  <meta property="og:url" content="/post/2020-05-07-analyzing-animal-crossing-reviews/">
  <meta property="og:title" content="Analyzing Animal Crossing Reviews | Qiushi Yan">
  <meta property="og:description" content="Practice on data cleaning, text analysis and multicategory logistic models with penalization"><meta property="og:image" content="/post/2020-05-07-analyzing-animal-crossing-reviews/featured.jpg">
  <meta property="twitter:image" content="/post/2020-05-07-analyzing-animal-crossing-reviews/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-05-07T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-05-07T00:00:00&#43;00:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/2020-05-07-analyzing-animal-crossing-reviews/"
  },
  "headline": "Analyzing Animal Crossing Reviews",
  
  "image": [
    "/post/2020-05-07-analyzing-animal-crossing-reviews/featured.jpg"
  ],
  
  "datePublished": "2020-05-07T00:00:00Z",
  "dateModified": "2020-05-07T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Qiushi Yan"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Qiushi Yan",
    "logo": {
      "@type": "ImageObject",
      "url": "/img/icon-512.png"
    }
  },
  "description": "Practice on data cleaning, text analysis and multicategory logistic models with penalization"
}
</script>

  

  


  


  





  <title>Analyzing Animal Crossing Reviews | Qiushi Yan</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">Qiushi Yan</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#post"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/about"><span>About / Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Analyzing Animal Crossing Reviews</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    May 7, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    16 min read
  </span>
  

  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/data-analysis/">Data Analysis</a>, <a href="/categories/machine-learning/">Machine Learning</a>, <a href="/categories/r/">R</a></span>
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      

<div id="TOC">
<ul>
<li><a href="#eda-and-data-cleaning">EDA and data cleaning</a></li>
<li><a href="#text-analysis-of-user-reviews">Text analysis of user reviews</a></li>
<li><a href="#predictive-modeling-for-rating">Predictive modeling for rating</a></li>
</ul>
</div>

<p>In this post I analyzed reviews for the life simulation video game, Animal Crossing. The data came from <a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-05-05/readme.md">this weeks’s <code>#TidyTuesday</code></a>, scraped from <a href="https://github.com/jefflomacy/villagerdb">VillagerDB</a> and <a href="https://www.metacritic.com/game/switch/animal-crossing-new-horizons/critic-reviews">Metacritic</a>. I used only the <code>reviews</code> table, but there are a lot more to analyze such as characters and items in the game.</p>
<p>The data appeared a bit messy after some EDA, and regular expressions played a major role in data cleaning. After that I made some plots concerning the review text, such as common words or high score words from an algorithm. Highly correlated words in user reviews were shown with nodes and edges. Then I built a multicategory logit model to predict ratings (low, medium or high) with predictors including the reviewing date and usage of specific words.</p>
<pre class="r"><code>library(tidyverse)
library(tidytext)</code></pre>
<div id="eda-and-data-cleaning" class="section level1">
<h1>EDA and data cleaning</h1>
<p>The reviews data contains four columns:</p>
<ul>
<li><code>grade</code>: 0-100 score given by the critic (missing for some) where higher score = better.</li>
<li><code>user_name</code>: user name of the reviewer</li>
<li><code>text</code>: review of the reviewer</li>
<li><code>date</code>: when the review is published</li>
</ul>
<pre class="r"><code>reviews &lt;- readr::read_tsv(&quot;D:/RProjects/data/blog/animal-crossing-reviews.tsv&quot;)
glimpse(reviews)
#&gt; Rows: 1,473
#&gt; Columns: 4
#&gt; $ grade     &lt;dbl&gt; 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...
#&gt; $ user_name &lt;chr&gt; &quot;mds27272&quot;, &quot;lolo2178&quot;, &quot;Roachant&quot;, &quot;Houndf&quot;, &quot;ProfessorF...
#&gt; $ text      &lt;chr&gt; &quot;My gf started playing before me. No option to create my ...
#&gt; $ date      &lt;date&gt; 2020-03-20, 2020-03-20, 2020-03-20, 2020-03-20, 2020-03-...</code></pre>
<p>A bar plot of all grades show a bimodal distribution. This is perhaps not that astonishing when it comes to reviewing, since people tend to go to extremes and give polarized opinions. This may suggest that we cut <code>grades</code> into discrete levels and build a classification model afterwards, rather than modeling bare grades itself with regression models.</p>
<pre class="r"><code>reviews %&gt;% 
  count(grade) %&gt;% 
  ggplot() + 
  geom_col(aes(x = factor(grade), 
               y = n),
           fill = &quot;midnightblue&quot;, alpha = 0.6) + 
  labs(x = &quot;grade&quot;, y = NULL)</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-5-1.png" width="768" /></p>
<p>The data is messy in several ways (I have chosen 3 observations from the <code>text</code> column for example):</p>
<ul>
<li>Review contains repetition. the following review where the first 4.5 lines are repeated in the following lines</li>
</ul>
<blockquote>
<p>“While the game itself is great, really relaxing and gorgeous, i can’t ignore one thing that ruins the whole experience for me and a lot of other people as seen by the different user reviews.That thing is that you only have 1 island per console. This decision limits to one person being able to enjoy the full experience. It also nukes any creative control of the island, since you haveWhile the game itself is great, really relaxing and gorgeous, i can’t ignore one thing that ruins the whole experience for me and a lot of other people as seen by the different user reviews.That thing is that you only have 1 island per console. This decision limits to one person being able to enjoy the full experience. It also nukes any creative control of the island, since you have the other usershouse and furniture. I hope nintendo can soon fix this big issue, because for now, this killed any intentions i had to play the game.… Expand”</p>
</blockquote>
<ul>
<li>Reviews that exceed certian length are incomplete and end with “Expand”. The following review also contains repeated lines.</li>
</ul>
<blockquote>
<p>“One island per console is a design decision that is, at best, in poor taste, and at worst, straight-up predatory behavior.Per console, only one player gets to experience the game at its fullest. The other players see less dialogue, experience less events, and are locked out entirely from certain parts of the game.No matter how good a game is, I cannot stand behind a company thatOne island per console is a design decision that is, at best, in poor taste, and at worst, straight-up predatory behavior.Per console, only one player gets to experience the game at its fullest. The other players see less dialogue, experience less events, and are locked out entirely from certain parts of the game.No matter how good a game is, I cannot stand behind a company that sees fit to make such decisions.… Expand”</p>
</blockquote>
<ul>
<li>non-English reviews</li>
</ul>
<blockquote>
<p>“Una sola isla , es un asco . No puedes seguir avanzando, solo te queda recoger madera”</p>
</blockquote>
<p>I use regular expressions to remove repeated lines as well as “Expand” at the end. Repetitions happen when the review is long, and the repetition part often takes up 4 to 5 lines (here I use 350 or more characters to indicate the repetition part).</p>
<p><code>clr::detect_language</code> is used to exclude non-English text. This a R wrapper around Google’s Compact Language Detector 3, a neural network model for language identification. There will be misclassifications, though. As the proportion of exclusion is fairly low, we’re OK. Lastyly, et’s split <code>grade</code> 3 ordered categories, low, medium and high.</p>
<pre class="r"><code>library(cld3)

# most text are detected as English
reviews %&gt;% 
  mutate(language = detect_language(text)) %&gt;% 
  count(language, sort = TRUE)
#&gt; # A tibble: 11 x 2
#&gt;    language     n
#&gt;    &lt;chr&gt;    &lt;int&gt;
#&gt;  1 en        1394
#&gt;  2 es          48
#&gt;  3 ru           7
#&gt;  4 it           6
#&gt;  5 fr           5
#&gt;  6 pt           5
#&gt;  7 de           3
#&gt;  8 &lt;NA&gt;         2
#&gt;  9 ja           1
#&gt; 10 pl           1
#&gt; 11 th           1</code></pre>
<pre class="r"><code>reviews_en &lt;- reviews %&gt;% 
  filter(detect_language(text) == &quot;en&quot;)


repetition_clean &lt;- reviews_en %&gt;% 
  filter(str_detect(text, &quot;(.{350,})\\1.+&quot;)) %&gt;% 
  mutate(text = str_replace(text, &quot;(.{350,})\\1(.+)Expand$&quot;, &quot;\\1\\2&quot;))

reviews_clean &lt;- anti_join(reviews_en, repetition_clean, 
                           by = c(&quot;user_name&quot; = &quot;user_name&quot;)) %&gt;% 
  bind_rows(repetition_clean) %&gt;% 
  mutate(rating = case_when(
    grade &lt;= 2 ~ &quot;low&quot;,
    grade &gt; 2 &amp; grade &lt; 8 ~ &quot;medium&quot;,
    grade &gt;= 8 ~ &quot;high&quot;,
  ) %&gt;% factor(levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;)))</code></pre>
<p>Now, <code>rating</code> is a factor with 3 levels. Low and high ratings are rougly the same size, and medium ratings are relatively rare.</p>
<pre class="r"><code>reviews_clean %&gt;% 
  count(rating)
#&gt; # A tibble: 3 x 2
#&gt;   rating     n
#&gt;   &lt;fct&gt;  &lt;int&gt;
#&gt; 1 low      626
#&gt; 2 medium   136
#&gt; 3 high     632</code></pre>
<p>We can examine how this cleaning process works by comparing the distribution of review length, before and after. The cleaning should reduce the amount of medium long and long reviews, in exchange for shorter ones.</p>
<pre class="r"><code>reviews %&gt;%
  transmute(length = str_length(text),
            type = &quot;before&quot;) %&gt;% 
  bind_rows(reviews_clean %&gt;%
              transmute(length = str_length(text), type = &quot;after&quot;)) %&gt;%
  ggplot() + 
  geom_density(aes(length, fill = type), alpha = 0.2) + 
  scale_fill_discrete(name = NULL) + 
  labs(title = &quot;Distribution of review length (characters) before and after cleaning&quot;,
       x = NULL,
       y = NULL)</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-9-1.png" width="768" /></p>
</div>
<div id="text-analysis-of-user-reviews" class="section level1">
<h1>Text analysis of user reviews</h1>
<p>Our text analysis begin by tokenizing review text to find out what are the most common words (by term frequency) for each category of reviews.</p>
<pre class="r"><code>words &lt;- reviews_clean %&gt;% 
  select(rating, text) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &quot;^\\d+$&quot;))
 

common_words &lt;- words %&gt;% 
  count(rating, word, sort = TRUE, name = &quot;term_count&quot;) %&gt;% 
  add_count(rating, wt = term_count, name = &quot;total_count&quot;) %&gt;% 
  mutate(term_freq = term_count / total_count)  %&gt;% 
  group_by(rating) %&gt;% 
  top_n(30, term_freq)</code></pre>
<pre class="r"><code>ggplot(common_words, 
       aes(y = reorder_within(word, term_freq, rating),
           x = term_freq,
           fill = rating)) + 
  geom_col(show.legend = FALSE, alpha = 0.6) + 
  scale_y_reordered() + 
  scale_x_continuous(label = scales::label_percent()) + 
  nord::scale_fill_nord(palette = &quot;afternoon_prarie&quot;) +
  facet_wrap(~ rating, scales = &quot;free_y&quot;, strip.position = &quot;bottom&quot;) + 
  labs(title = &quot;Most common words in different levels of reviews&quot;,
       x = &quot;term frequency&quot;,
       y = NULL) + 
  hrbrthemes::theme_modern_rc() + 
  theme(panel.grid.major.y = element_blank(),
        plot.title = element_text(face = &quot;bold&quot;, size = 28),
        plot.title.position = &quot;plot&quot;,
        axis.text.y = element_text(size = 16),
        axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 16), 
        strip.text = element_text(size = 20, color = &quot;white&quot;)) </code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-11-1.png" width="1344" /></p>
<p>As it is, this plot aren’t that helpful for all categories share a very similar set of words. For this reason I turn to two other algorithms developed for information retrieval: tf-idf and weighted log odds.</p>
<pre class="r"><code>library(tidylo)

key_words &lt;- words %&gt;% 
  count(rating, word, sort = TRUE) %&gt;% 
  bind_tf_idf(term = word, document = rating, n = n) %&gt;%
  left_join(words %&gt;% 
              count(rating, word, sort = TRUE) %&gt;% 
              bind_log_odds(set = rating, feature = word, n = n),
            by = c(&quot;rating&quot; = &quot;rating&quot;, &quot;word&quot;, &quot;word&quot;, &quot;n&quot; = &quot;n&quot;)) %&gt;% 
  select(rating, word, tf_idf, log_odds)

key_words
#&gt; # A tibble: 9,162 x 4
#&gt;    rating word     tf_idf log_odds
#&gt;    &lt;fct&gt;  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;
#&gt;  1 low    game          0   -0.392
#&gt;  2 high   game          0    1.25 
#&gt;  3 low    island        0    3.60 
#&gt;  4 low    switch        0    5.25 
#&gt;  5 low    play          0    5.24 
#&gt;  6 low    player        0    7.31 
#&gt;  7 high   island        0   -3.44 
#&gt;  8 low    nintendo      0    6.54 
#&gt;  9 medium game          0   -0.882
#&gt; 10 high   animal        0    7.55 
#&gt; # ... with 9,152 more rows</code></pre>
<p>Make separate plot for two measures and then combine them togther.</p>
<pre class="r"><code>tf_idf &lt;- key_words %&gt;% 
  group_by(rating) %&gt;% 
  arrange(-tf_idf) %&gt;% 
  slice(1:20) %&gt;% 
  ggplot(aes(
    y = reorder_within(word, tf_idf, rating),
    x = tf_idf,
    fill = rating)) + 
  geom_col(show.legend = FALSE, alpha = 0.6) + 
  scale_y_reordered() + 
  scale_x_continuous(position = &quot;top&quot;) + 
  nord::scale_fill_nord(palette = &quot;afternoon_prarie&quot;) +
  facet_wrap(~ rating, scales = &quot;free_y&quot;, strip.position = &quot;bottom&quot;) + 
  labs(title = &quot;High tf-idf words&quot;,
       x = NULL,
       y = NULL) + 
  hrbrthemes::theme_modern_rc() + 
  theme(panel.grid.major.y = element_blank(),
        plot.title = element_text(face = &quot;bold&quot;, size = 28),
        plot.title.position = &quot;plot&quot;,
        axis.text.y = element_text(size = 16),
        axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 16), 
        strip.text = element_text(size = 24, color = &quot;white&quot;)) 

log_odds &lt;- key_words %&gt;% 
  group_by(rating) %&gt;% 
  top_n(20, log_odds) %&gt;%
  ggplot(aes(
    y = reorder_within(word, log_odds, rating),
    x = log_odds,
    fill = rating)) + 
  geom_col(show.legend = FALSE, alpha = 0.6) + 
  scale_y_reordered() + 
  scale_x_continuous(position = &quot;top&quot;) +  
  nord::scale_fill_nord(palette = &quot;afternoon_prarie&quot;) +
  facet_wrap(~ rating, scales = &quot;free_y&quot;, strip.position = &quot;bottom&quot;) + 
  labs(title = &quot;High log-odds words&quot;,
       x = NULL,
       y = NULL) + 
  hrbrthemes::theme_modern_rc() + 
  theme(panel.grid.major.y = element_blank(),
        plot.title = element_text(face = &quot;bold&quot;, size = 28),
        plot.title.position = &quot;plot&quot;,
        axis.text.y = element_text(size = 16),
        axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 16), 
        strip.text = element_blank()) 

patchwork::wrap_plots(tf_idf, log_odds, nrow = 2)</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-13-1.png" width="1344" /></p>
<p>Emmm… this is a little better, isn’t it 😅? The <code>tf_idf</code> plot performed well in identifying characteristic words in low ratings like “unacceptable”, “wtf” and “boring”, While the <code>log_odds</code> plo shows a somewhat dominance of words like “fun”, “cute” and “relaxing” in high ratings.</p>
<p>Additionally, we may also be interested in words that tend to co-occur within a particular review. For simplicity I focus on long reivews only (more than 800 characters).</p>
<pre class="r"><code>library(widyr)

word_cors &lt;- reviews_clean %&gt;%  
  filter(str_length(text) &gt; 800) %&gt;%
  select(user_name, text) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &quot;^\\d+$&quot;)) %&gt;% 
  group_by(word) %&gt;% 
  filter(n() &gt; 10) %&gt;% 
  count(user_name, word) %&gt;% 
  pairwise_cor(item = word, feature = user_name, value = n)

word_cors
#&gt; # A tibble: 102,720 x 3
#&gt;    item1      item2 correlation
#&gt;    &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;
#&gt;  1 ability    3ds       -0.0402
#&gt;  2 absolutely 3ds       -0.0125
#&gt;  3 ac         3ds        0.158 
#&gt;  4 access     3ds       -0.0457
#&gt;  5 account    3ds        0.170 
#&gt;  6 accounts   3ds        0.271 
#&gt;  7 activities 3ds        0.0348
#&gt;  8 add        3ds        0.0216
#&gt;  9 addition   3ds        0.0770
#&gt; 10 additional 3ds       -0.0414
#&gt; # ... with 102,710 more rows</code></pre>
<pre class="r"><code>library(ggraph)
library(tidygraph)

word_cors %&gt;%
  filter(correlation &gt; 0.4) %&gt;% 
  as_tbl_graph() %&gt;% 
  ggraph(layout = &quot;fr&quot;) + 
  geom_edge_link(aes(alpha = correlation), show.legend = FALSE) + 
  geom_node_point(color = &quot;lightblue&quot;, size = 6.5) + 
  geom_node_text(aes(label = name), repel = TRUE, size = 5.5)</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-15-1.png" width="960" /></p>
</div>
<div id="predictive-modeling-for-rating" class="section level1">
<h1>Predictive modeling for rating</h1>
<p>It takes some steps to derive from <code>reviews_clean</code> a design matrix for modeling. The <a href="https://tidymodels.github.io/textrecipes/index.html"><code>textrecipes</code></a> package contains extra steps for <code>recipes</code> for preprocessing text data that could have replaced my manual wrangling. But I havn’t digged into that now.</p>
<pre class="r"><code>library(lubridate)

model_df &lt;- reviews_clean %&gt;% 
  filter_all(all_vars(!is.na(.))) %&gt;% 
  transmute(rating, 
            user_name, 
            text,
            t = as.numeric(date - ymd(&quot;2020-03-20&quot;))) %&gt;%
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;%
  count(user_name, t, rating, word, name = &quot;word_count&quot;) %&gt;% 
  group_by(word) %&gt;% 
  filter(n() &gt; 20, word != &quot;rating&quot;, !str_detect(word, &quot;^\\d+$&quot;)) %&gt;% 
  ungroup() %&gt;% 
  pivot_wider(names_from = word, values_from = word_count, 
              values_fill = list(word_count = 0), names_repair = &quot;minimal&quot;)
  

model_df
#&gt; # A tibble: 1,392 x 320
#&gt;    user_name     t rating playing  stop ability accounts   buy `can’t` console
#&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;fct&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt;
#&gt;  1 000PLAYE~     0 high         1     1       0        0     0       0       0
#&gt;  2 11_11         4 low          1     0       1        3     2       1       2
#&gt;  3 12hwilso      4 low          0     0       0        1     0       0       2
#&gt;  4 3nd3r02       6 low          0     0       0        0     0       0       0
#&gt;  5 425_Flex      3 low          0     0       0        0     0       0       0
#&gt;  6 486eHyMy      2 low          0     0       0        0     0       0       0
#&gt;  7 4Plants       5 high         0     0       0        0     0       0       0
#&gt;  8 8bheotap~     6 low          0     0       0        0     0       0       2
#&gt;  9 A_Mighty~     6 medium       3     0       0        1     3       0       0
#&gt; 10 a0972354      4 high         0     0       0        0     0       0       0
#&gt; # ... with 1,382 more rows, and 310 more variables: consoles &lt;int&gt;,
#&gt; #   `don’t` &lt;int&gt;, excited &lt;int&gt;, extremely &lt;int&gt;, families &lt;int&gt;,
#&gt; #   forcing &lt;int&gt;, fun &lt;int&gt;, game &lt;int&gt;, games &lt;int&gt;, greedy &lt;int&gt;,
#&gt; #   household &lt;int&gt;, island &lt;int&gt;, money &lt;int&gt;, multiple &lt;int&gt;, nintendo &lt;int&gt;,
#&gt; #   play &lt;int&gt;, purchase &lt;int&gt;, saves &lt;int&gt;, separate &lt;int&gt;, sister &lt;int&gt;,
#&gt; #   spent &lt;int&gt;, stupid &lt;int&gt;, true &lt;int&gt;, account &lt;int&gt;, broken &lt;int&gt;,
#&gt; #   fix &lt;int&gt;, people &lt;int&gt;, progress &lt;int&gt;, `1st` &lt;int&gt;, animal &lt;int&gt;,
#&gt; #   crossing &lt;int&gt;, experience &lt;int&gt;, gorgeous &lt;int&gt;, idea &lt;int&gt;, love &lt;int&gt;,
#&gt; #   makes &lt;int&gt;, player &lt;int&gt;, reason &lt;int&gt;, score &lt;int&gt;, worth &lt;int&gt;,
#&gt; #   control &lt;int&gt;, family &lt;int&gt;, giving &lt;int&gt;, grab &lt;int&gt;, kids &lt;int&gt;,
#&gt; #   negative &lt;int&gt;, resources &lt;int&gt;, review &lt;int&gt;, switch &lt;int&gt;,
#&gt; #   unacceptable &lt;int&gt;, user &lt;int&gt;, users &lt;int&gt;, girlfriend &lt;int&gt;,
#&gt; #   players &lt;int&gt;, time &lt;int&gt;, wait &lt;int&gt;, day &lt;int&gt;, horizons &lt;int&gt;,
#&gt; #   house &lt;int&gt;, leaf &lt;int&gt;, past &lt;int&gt;, played &lt;int&gt;, view &lt;int&gt;,
#&gt; #   allowing &lt;int&gt;, designed &lt;int&gt;, gamecube &lt;int&gt;, real &lt;int&gt;, single &lt;int&gt;,
#&gt; #   version &lt;int&gt;, bought &lt;int&gt;, buying &lt;int&gt;, choice &lt;int&gt;, community &lt;int&gt;,
#&gt; #   decision &lt;int&gt;, expected &lt;int&gt;, features &lt;int&gt;, feel &lt;int&gt;, feels &lt;int&gt;,
#&gt; #   fine &lt;int&gt;, forced &lt;int&gt;, future &lt;int&gt;, gameplay &lt;int&gt;, huge &lt;int&gt;,
#&gt; #   issue &lt;int&gt;, left &lt;int&gt;, lot &lt;int&gt;, mechanics &lt;int&gt;, multiplayer &lt;int&gt;,
#&gt; #   op &lt;int&gt;, person &lt;int&gt;, plays &lt;int&gt;, reviews &lt;int&gt;, shame &lt;int&gt;,
#&gt; #   sharing &lt;int&gt;, started &lt;int&gt;, system &lt;int&gt;, bombing &lt;int&gt;, dont &lt;int&gt;,
#&gt; #   hate &lt;int&gt;, islands &lt;int&gt;, ...</code></pre>
<p>After tokenizing, filtering and some other steps, I have a ready-for-modeling design matrix at hand. <code>user_name</code> is an ID variable, <code>t</code> indicates the number of days after 2020-03-20 when the first review was made. All other columns, besides the response <code>rating</code>, are word counts used as term weighting.</p>
<p>Next I split the data into training and testing test with stratified sampling on <code>rating</code>.</p>
<pre class="r"><code>library(tidymodels)

set.seed(2020)
reviews_split &lt;- initial_split(model_df, strata = rating)
reviews_train &lt;- training(reviews_split)
reviews_test &lt;- testing(reviews_split)</code></pre>
<p>I choose to fit a multinomial logisitic regression model run by the <code>glmnet</code> package, with L1 regularization as in the lasso model. To detect medium ratings more accurately, the minority class, <code>step_upsample</code> will bring the number of meidum and high ratings up to the same (<code>over_ratio = 1</code> ) as that of low ratings. And <code>tune_gird()</code> will calculate model performance metrics averaged over 25 bootstrap resamples for 100 choices of lambda.</p>
<pre class="r"><code>multinom_spec &lt;- multinom_reg(mixture = 1, penalty = tune()) %&gt;% 
  set_engine(&quot;glmnet&quot;) %&gt;% 
  set_mode(&quot;classification&quot;) 

library(themis)
rec &lt;- recipe(rating ~ ., data = reviews_train) %&gt;%
  update_role(user_name, new_role = &quot;ID&quot;) %&gt;% 
  step_upsample(rating, over_ratio = 1) %&gt;% 
  step_normalize(all_predictors())

lambda_grid &lt;- grid_regular(penalty(), levels = 100)
  
reviews_folds &lt;- bootstraps(reviews_train, strata = rating)

wf &lt;- workflow() %&gt;% 
  add_model(multinom_spec) %&gt;% 
  add_recipe(rec)

doParallel::registerDoParallel()

multinom_search &lt;- tune_grid(wf, 
                    resamples = reviews_folds,
                    grid = lambda_grid,
                    metrics = metric_set(roc_auc, accuracy, kap))</code></pre>
<p>Available metrics are ROC AUC, accuracy and Kappa. In multiclass cases, accuracy and Kappa use the same definitions as their binary counterpart, with accuracy counting up the number of correctly predicted true values out of the total number of true values, and Kappa being a linear combination of two accuracy values, sensitivity and specificity. Multiclass ROC AUC, however, is implemented as the “hand_till” method which I won’t venture to interpret now.</p>
<pre class="r"><code>multinom_search %&gt;%
  collect_metrics() %&gt;% 
  ggplot(aes(penalty, mean, color = .metric)) + 
  geom_line() + 
  geom_errorbar(aes(ymax = mean + std_err, ymin = mean - std_err)) + 
  scale_x_log10(labels = scales::label_number_auto()) + 
  facet_wrap(~ .metric, scales = &quot;free_y&quot;) + 
  labs(y = NULL, x = expression(lambda)) + 
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-19-1.png" width="960" /></p>
<p>It’s clear from the plot that all 3 metrics benefit from appropriate regularization, and we can identify a local maximum in all penals at rougly the same lambda. Here I use the “one-standard error rule” that selects model with largest lambda that is within one standard error of the numerically optimal Kappa metric.</p>
<pre class="r"><code>best_lambda &lt;- multinom_search %&gt;% 
  select_by_one_std_err(metric = &quot;kap&quot;, desc(penalty))

best_lambda
#&gt; # A tibble: 1 x 8
#&gt;   penalty .metric .estimator  mean     n std_err .best .bound
#&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1  0.0192 kap     multiclass 0.527    25 0.00685 0.533  0.526</code></pre>
<p>We can finalize and fill the model with this lambda.</p>
<pre class="r"><code>wf_final &lt;- finalize_workflow(wf, best_lambda)

final_model &lt;- last_fit(wf_final, split = reviews_split, 
                        metrics = metric_set(roc_auc, accuracy, kap))</code></pre>
<p>For our model, the confusion matrix becomes 3 x 3.</p>
<pre class="r"><code>final_model %&gt;% 
  collect_predictions() %&gt;% 
  conf_mat(rating, estimate = .pred_class)
#&gt;           Truth
#&gt; Prediction low medium high
#&gt;     low    104     17    7
#&gt;     medium  31      8   12
#&gt;     high    18      7  143</code></pre>
<p>Thanks to downsmapling, the classifier performs quite consistently in predicting these 3 categories. Detection for low ratings may leave some room for improvement.</p>
<p>Then we could examine these metrics on the model applied to testing set.</p>
<pre class="r"><code>final_model %&gt;% 
  collect_metrics()
#&gt; # A tibble: 3 x 3
#&gt;   .metric  .estimator .estimate
#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 accuracy multiclass     0.735
#&gt; 2 kap      multiclass     0.556
#&gt; 3 roc_auc  hand_till      0.746</code></pre>
<p>These number may not look so nice in terms of accuracy and ROC AUC, but there is a tradeoff happening. When I was still experimenting on different models I trained one that would miss all the medium ratings in the testing set, but did achieve relatively high predictive metrics. Then I decided to add the <code>step_upsampling</code> step to enhance detection towards medium ratings. Although the game campany may not actually care about those mild people as much as they do about those go to extremes. For another, the best penality is judged by the Kappa statistic, which shows reasonable agreement.</p>
<p>Varible importance plot could help us to identify useful features. For multiclass logit models, importance is defined as the sum of absolute value of coef of a variable. For example, in our baseline logit models:</p>
<p><span class="math display">\[
\begin{aligned}
\log(\frac{P(medium)}{P(low)}) &amp;= \beta_20 + \beta_{21}x_1 + \cdots + \beta_{2p}x_p \\
\log(\frac{P(high)}{P(low)}) &amp;= \beta_30 + \beta_{31}x_1 + \cdots + \beta_{3p}x_p
\end{aligned}
\]</span></p>
<p>The absolute value of variable importance for predictor <span class="math inline">\(x_1\)</span> is <span class="math inline">\(|\hat{\beta}_{21}| + |\hat{\beta}_{31}|\)</span>.</p>
<p>Now I inspect predictors with top absolute variable importance to conclude this minimal project. If a predictor has high positive / negative importance, then it help us to judge whether a user is more intended to give higher ratings or otherwise, similar to sentiment analysis.</p>
<pre class="r"><code>final_fit &lt;- wf_final %&gt;% fit(data = reviews_train)</code></pre>
<pre class="r"><code>library(vip)

final_fit %&gt;% 
  pull_workflow_fit() %&gt;% 
  vi(lambda = best_lambda$penalty) %&gt;%
  group_by(Sign) %&gt;% 
  top_n(30, wt = abs(Importance)) %&gt;% 
  ungroup() %&gt;%
  mutate(Sign = if_else(Sign == &quot;NEG&quot;, &quot;lower ratings&quot;, &quot;higher ratings&quot;)) %&gt;% 
  ggplot(aes(y = reorder_within(Variable, abs(Importance), Sign),
             x = Importance,
             fill = Sign)) + 
  geom_col(show.legend = FALSE, alpha = 0.5) +
  scale_y_reordered() + 
  facet_wrap(~ Sign, scales = &quot;free&quot;) + 
  labs(y = NULL) + 
  theme(axis.text = element_text(size = 20),
        panel.grid.major.y = element_blank(),
        strip.text = element_text(size = 24, face = &quot;bold&quot;))</code></pre>
<p><img src="/post/2020-05-07-analyzing-animal-crossing-reviews/index_files/figure-html/unnamed-chunk-25-1.png" width="1152" /></p>
</div>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/2020-05-07-analyzing-animal-crossing-reviews/&amp;text=Analyzing%20Animal%20Crossing%20Reviews" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/2020-05-07-analyzing-animal-crossing-reviews/&amp;t=Analyzing%20Animal%20Crossing%20Reviews" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Analyzing%20Animal%20Crossing%20Reviews&amp;body=/post/2020-05-07-analyzing-animal-crossing-reviews/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/2020-05-07-analyzing-animal-crossing-reviews/&amp;title=Analyzing%20Animal%20Crossing%20Reviews" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Analyzing%20Animal%20Crossing%20Reviews%20/post/2020-05-07-analyzing-animal-crossing-reviews/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/2020-05-07-analyzing-animal-crossing-reviews/&amp;title=Analyzing%20Animal%20Crossing%20Reviews" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/qiushi/avatar_hu2833603c9957d65d4c6e6cf5762ee973_72134_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/">Qiushi Yan</a></h5>
      <h6 class="card-subtitle">Junior student, Data Journalism</h6>
      <p class="card-text">Yet another object of type closure</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/enixam" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/qiushizzzz" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/%E6%B1%82%E8%AF%86-%E9%97%AB-893a48194/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/about" >
        <i class="fas fa-address-card"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>




<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "qiushiyan" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>




<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/post/programmer-word-choice/" rel="next">Programmers and Their Choice of Words</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/post/international-debt-sql/" rel="prev">Analyzing International Debt Statistics</a>
  </div>
  
</div>

</div>



  
  



  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.3.1/mermaid.min.js" integrity="sha256-vOIuDSYDirTfyr+S2MjFnhOz6Rgiz4ODFAHATG0rFxw=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/bash.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/sql.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/http.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/javascript.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/json.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/markdown.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/xml.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/yaml.min.js"></script>
        
      

      
      
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.0e040a4c8b8532fc173c2fe4328906d0.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/license/">LICENSE: CC-BY-NC <br> <i class="fab fa-creative-commons fa-2x"></i><i class="fab fa-creative-commons-by fa-2x"></i><i class="fab fa-creative-commons-nc fa-2x"></i> </a><br>
  </p>
  

  <p class="powered-by">
    Qiushi Yan © 2020 &middot; 

    Made with the <a href="https://cran.r-project.org/" target="_blank" rel="noopener"><i class="fab fa-r-project"></i></a><a href="https://github.com/rstudio/blogdown" target="_blank" rel="noopener">blogdown</a> package, and the 
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>
  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
