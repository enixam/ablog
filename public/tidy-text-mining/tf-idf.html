<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.1 tf-idf | Text Mining with R — Notes</title>
  <meta name="description" content="3.1 tf-idf | Text Mining with R — Notes" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="3.1 tf-idf | Text Mining with R — Notes" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="enixam/tidy-text-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.1 tf-idf | Text Mining with R — Notes" />
  
  
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-04-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyzing-word-and-document-frequency.html"/>
<link rel="next" href="weighted-log-odds-ratio.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes for Text Mining with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Text Mining with R</b></span></li>
<li class="chapter" data-level="1" data-path="tidy-text-format.html"><a href="tidy-text-format.html"><i class="fa fa-check"></i><b>1</b> Tidy text format</a><ul>
<li class="chapter" data-level="1.1" data-path="the-unnest-tokens-function.html"><a href="the-unnest-tokens-function.html"><i class="fa fa-check"></i><b>1.1</b> The <code>unnest_tokens()</code> function</a></li>
<li class="chapter" data-level="1.2" data-path="the-gutenbergr-package.html"><a href="the-gutenbergr-package.html"><i class="fa fa-check"></i><b>1.2</b> The <code>gutenbergr</code> package</a></li>
<li class="chapter" data-level="1.3" data-path="compare-word-frequency.html"><a href="compare-word-frequency.html"><i class="fa fa-check"></i><b>1.3</b> Compare word frequency</a></li>
<li class="chapter" data-level="1.4" data-path="other-tokenization-methods.html"><a href="other-tokenization-methods.html"><i class="fa fa-check"></i><b>1.4</b> Other tokenization methods</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sentiment-analysis-with-tidy-data.html"><a href="sentiment-analysis-with-tidy-data.html"><i class="fa fa-check"></i><b>2</b> Sentiment analysis with tidy data</a><ul>
<li class="chapter" data-level="2.1" data-path="the-sentiments-dataset.html"><a href="the-sentiments-dataset.html"><i class="fa fa-check"></i><b>2.1</b> The <code>sentiments</code> dataset</a></li>
<li class="chapter" data-level="2.2" data-path="sentiment-analysis-with-inner-join.html"><a href="sentiment-analysis-with-inner-join.html"><i class="fa fa-check"></i><b>2.2</b> Sentiment analysis with inner join</a></li>
<li class="chapter" data-level="2.3" data-path="comparing-3-different-dictionaries.html"><a href="comparing-3-different-dictionaries.html"><i class="fa fa-check"></i><b>2.3</b> Comparing 3 different dictionaries</a></li>
<li class="chapter" data-level="2.4" data-path="most-common-positive-and-negative-words.html"><a href="most-common-positive-and-negative-words.html"><i class="fa fa-check"></i><b>2.4</b> Most common positive and negative words</a></li>
<li class="chapter" data-level="2.5" data-path="wordclouds.html"><a href="wordclouds.html"><i class="fa fa-check"></i><b>2.5</b> Wordclouds</a></li>
<li class="chapter" data-level="2.6" data-path="units-other-than-words.html"><a href="units-other-than-words.html"><i class="fa fa-check"></i><b>2.6</b> Units other than words</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analyzing-word-and-document-frequency.html"><a href="analyzing-word-and-document-frequency.html"><i class="fa fa-check"></i><b>3</b> Analyzing word and document frequency</a><ul>
<li class="chapter" data-level="3.1" data-path="tf-idf.html"><a href="tf-idf.html"><i class="fa fa-check"></i><b>3.1</b> tf-idf</a><ul>
<li class="chapter" data-level="3.1.1" data-path="tf-idf.html"><a href="tf-idf.html#term-frequency-in-jane-austens-novels"><i class="fa fa-check"></i><b>3.1.1</b> Term frequency in Jane Austen’s novels</a></li>
<li class="chapter" data-level="3.1.2" data-path="tf-idf.html"><a href="tf-idf.html#zipfs-law"><i class="fa fa-check"></i><b>3.1.2</b> Zipf’s law</a></li>
<li class="chapter" data-level="3.1.3" data-path="tf-idf.html"><a href="tf-idf.html#word-rank-slope-chart"><i class="fa fa-check"></i><b>3.1.3</b> Word rank slope chart</a></li>
<li class="chapter" data-level="3.1.4" data-path="tf-idf.html"><a href="tf-idf.html#the-bind_tf_idf-function"><i class="fa fa-check"></i><b>3.1.4</b> The <code>bind_tf_idf()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="weighted-log-odds-ratio.html"><a href="weighted-log-odds-ratio.html"><i class="fa fa-check"></i><b>3.2</b> Weighted log odds ratio</a><ul>
<li class="chapter" data-level="3.2.1" data-path="weighted-log-odds-ratio.html"><a href="weighted-log-odds-ratio.html#log-odds-ratio"><i class="fa fa-check"></i><b>3.2.1</b> Log odds ratio</a></li>
<li class="chapter" data-level="3.2.2" data-path="weighted-log-odds-ratio.html"><a href="weighted-log-odds-ratio.html#model-based-approach-weighted-log-odds-ratio"><i class="fa fa-check"></i><b>3.2.2</b> Model-based approach: Weighted log odds ratio</a></li>
<li class="chapter" data-level="3.2.3" data-path="weighted-log-odds-ratio.html"><a href="weighted-log-odds-ratio.html#discussions"><i class="fa fa-check"></i><b>3.2.3</b> Discussions</a></li>
<li class="chapter" data-level="3.2.4" data-path="weighted-log-odds-ratio.html"><a href="weighted-log-odds-ratio.html#bind_log_odds"><i class="fa fa-check"></i><b>3.2.4</b> <code>bind_log_odds()</code></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="a-corpus-of-physics-texts.html"><a href="a-corpus-of-physics-texts.html"><i class="fa fa-check"></i><b>3.3</b> A corpus of physics texts</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="relationships-between-words-n-grams-and-correlations.html"><a href="relationships-between-words-n-grams-and-correlations.html"><i class="fa fa-check"></i><b>4</b> Relationships between words: n-grams and correlations</a><ul>
<li class="chapter" data-level="4.1" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html"><i class="fa fa-check"></i><b>4.1</b> Tokenizing by n-gram</a><ul>
<li class="chapter" data-level="4.1.1" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html#filtering-n-grams"><i class="fa fa-check"></i><b>4.1.1</b> Filtering n-grams</a></li>
<li class="chapter" data-level="4.1.2" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html#analyzing-bigrams"><i class="fa fa-check"></i><b>4.1.2</b> Analyzing bigrams</a></li>
<li class="chapter" data-level="4.1.3" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html#using-bigrams-to-provide-context-in-sentiment-analysis"><i class="fa fa-check"></i><b>4.1.3</b> Using bigrams to provide context in sentiment analysis</a></li>
<li class="chapter" data-level="4.1.4" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html#visualizing-a-network-of-bigrams-with-ggraph"><i class="fa fa-check"></i><b>4.1.4</b> Visualizing a network of bigrams with <code>ggraph</code></a></li>
<li class="chapter" data-level="4.1.5" data-path="tokenizing-by-n-gram.html"><a href="tokenizing-by-n-gram.html#visualizing-friends"><i class="fa fa-check"></i><b>4.1.5</b> Visualizing “friends”</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="counting-and-correlating-pairs-of-words-with-widyr.html"><a href="counting-and-correlating-pairs-of-words-with-widyr.html"><i class="fa fa-check"></i><b>4.2</b> Counting and correlating pairs of words with <code>widyr</code></a><ul>
<li class="chapter" data-level="4.2.1" data-path="counting-and-correlating-pairs-of-words-with-widyr.html"><a href="counting-and-correlating-pairs-of-words-with-widyr.html#counting-and-correlating-among-sections"><i class="fa fa-check"></i><b>4.2.1</b> Counting and correlating among sections</a></li>
<li class="chapter" data-level="4.2.2" data-path="counting-and-correlating-pairs-of-words-with-widyr.html"><a href="counting-and-correlating-pairs-of-words-with-widyr.html#pairwise-correlation"><i class="fa fa-check"></i><b>4.2.2</b> Pairwise correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="converting-to-and-from-non-tidy-formats.html"><a href="converting-to-and-from-non-tidy-formats.html"><i class="fa fa-check"></i><b>5</b> Converting to and from non-tidy formats</a><ul>
<li class="chapter" data-level="5.1" data-path="tidying-a-document-term-matrix.html"><a href="tidying-a-document-term-matrix.html"><i class="fa fa-check"></i><b>5.1</b> Tidying a document-term matrix</a></li>
<li class="chapter" data-level="5.2" data-path="casting-tidy-text-data-into-a-matrix.html"><a href="casting-tidy-text-data-into-a-matrix.html"><i class="fa fa-check"></i><b>5.2</b> Casting tidy text data into a matrix</a></li>
<li class="chapter" data-level="5.3" data-path="tidying-corpus-objects-with-metadata.html"><a href="tidying-corpus-objects-with-metadata.html"><i class="fa fa-check"></i><b>5.3</b> Tidying corpus objects with metadata</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="topic-modeling.html"><a href="topic-modeling.html"><i class="fa fa-check"></i><b>6</b> Topic modeling</a><ul>
<li class="chapter" data-level="6.1" data-path="latent-dirichlet-allocation.html"><a href="latent-dirichlet-allocation.html"><i class="fa fa-check"></i><b>6.1</b> Latent Dirichlet Allocation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="latent-dirichlet-allocation.html"><a href="latent-dirichlet-allocation.html#example-associated-press"><i class="fa fa-check"></i><b>6.1.1</b> Example: Associated Press</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="example-the-great-library-heist.html"><a href="example-the-great-library-heist.html"><i class="fa fa-check"></i><b>6.2</b> Example: the great library heist</a><ul>
<li class="chapter" data-level="6.2.1" data-path="example-the-great-library-heist.html"><a href="example-the-great-library-heist.html#lda-on-chapters"><i class="fa fa-check"></i><b>6.2.1</b> LDA on chapters</a></li>
<li class="chapter" data-level="6.2.2" data-path="example-the-great-library-heist.html"><a href="example-the-great-library-heist.html#per-document-classification"><i class="fa fa-check"></i><b>6.2.2</b> Per-document classification</a></li>
<li class="chapter" data-level="6.2.3" data-path="example-the-great-library-heist.html"><a href="example-the-great-library-heist.html#by-word-assignments-augment"><i class="fa fa-check"></i><b>6.2.3</b> By word assignments: <code>augment()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="reviews-on-regular-expressions.html"><a href="reviews-on-regular-expressions.html"><i class="fa fa-check"></i><b>A</b> Reviews on regular expressions</a><ul>
<li class="chapter" data-level="A.1" data-path="posix-character-classes.html"><a href="posix-character-classes.html"><i class="fa fa-check"></i><b>A.1</b> POSIX Character Classes</a></li>
<li class="chapter" data-level="A.2" data-path="greedy-and-lazy-quantifiers.html"><a href="greedy-and-lazy-quantifiers.html"><i class="fa fa-check"></i><b>A.2</b> Greedy and lazy quantifiers</a></li>
<li class="chapter" data-level="A.3" data-path="looking-ahead-and-back.html"><a href="looking-ahead-and-back.html"><i class="fa fa-check"></i><b>A.3</b> Looking ahead and back</a></li>
<li class="chapter" data-level="A.4" data-path="backreferences.html"><a href="backreferences.html"><i class="fa fa-check"></i><b>A.4</b> Backreferences</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="text-processing-examples-in-r.html"><a href="text-processing-examples-in-r.html"><i class="fa fa-check"></i><b>B</b> Text processing examples in R</a><ul>
<li class="chapter" data-level="B.1" data-path="replacing-and-removing.html"><a href="replacing-and-removing.html"><i class="fa fa-check"></i><b>B.1</b> Replacing and removing</a></li>
<li class="chapter" data-level="B.2" data-path="combining-and-splitting.html"><a href="combining-and-splitting.html"><i class="fa fa-check"></i><b>B.2</b> Combining and splitting</a></li>
<li class="chapter" data-level="B.3" data-path="extracting-text-from-pdf-and-other-files.html"><a href="extracting-text-from-pdf-and-other-files.html"><i class="fa fa-check"></i><b>B.3</b> Extracting text from pdf and other files</a><ul>
<li class="chapter" data-level="B.3.1" data-path="extracting-text-from-pdf-and-other-files.html"><a href="extracting-text-from-pdf-and-other-files.html#office-documents"><i class="fa fa-check"></i><b>B.3.1</b> Office documents</a></li>
<li class="chapter" data-level="B.3.2" data-path="extracting-text-from-pdf-and-other-files.html"><a href="extracting-text-from-pdf-and-other-files.html#images"><i class="fa fa-check"></i><b>B.3.2</b> Images</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Written with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Text Mining with R — Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tf-idf" class="section level2">
<h2><span class="header-section-number">3.1</span> tf-idf</h2>
<p>The logic of tf-idf is that the words containing the greatest information about a particular document are the words that <strong>appear many times in that document, but in relatively few others</strong>. Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common. It is widely used in document search and information retrieval tasks. 14 To the extent tf.idf reliably captures what is distinctive about a particular document, it could be interpreted as a feature evaluation technique.</p>
<p>Let <span class="math inline">\(w = 1, 2, ..., W\)</span> index words and <span class="math inline">\(\boldsymbol{y}\)</span> denots the W-vector of word counts in the corpus. Let <span class="math inline">\(i \in I\)</span> index documents in the corpus, let <span class="math inline">\(\boldsymbol{y^i}\)</span> denotes the W-vector of word counts of document <span class="math inline">\(i\)</span>， <span class="math inline">\(y_w^i\)</span> the count of word <span class="math inline">\(w\)</span> in document <span class="math inline">\(i\)</span>, and <span class="math inline">\(n^i\)</span> the total count of words in document <span class="math inline">\(i\)</span>.</p>
<p>Term frequency (tf) of a word <span class="math inline">\(w\)</span> in document <span class="math inline">\(i\)</span> is defined as its proprotions</p>
<p><span class="math display">\[
f_{w}^{i} = \frac{y_{w}^{i}}{n^{i}}
\]</span></p>
<p>We can see that <span class="math inline">\(\text{tf}_{ij}\)</span> is essentially a scaling of term counts <span class="math inline">\(n^{i}\)</span>, so that the metric will not be biased against words in lengthy documents.</p>
<p>.Inverse document frequency (idf) of word <span class="math inline">\(w\)</span> in the corpus is defined as</p>
<p><span class="math display">\[
\text{idf}_i = \log{\frac{|D|}{|{j:t_i \in d_j}|}}
\]</span>
where <span class="math inline">\(|D|\)</span> is the number of documents in the corpus, and <span class="math inline">\(|{j:t_i \in d_j}|\)</span> the number of documents containing word <span class="math inline">\(i\)</span>. We can let <span class="math inline">\(df_w\)</span> denote the fraction of documents that contain word <span class="math inline">\(w\)</span> at least once, then idf can be stated as</p>
<p><span class="math display">\[
\text{idf}_i = \log{\frac{1}{df_{w}}}
\]</span>
and tf-idf, the production of term frequency and document frequency, as</p>
<p><span class="math display">\[
tf.idf_w^i = f_w^i \log{\frac{1}{df_{w}}}
\]</span></p>
<div id="term-frequency-in-jane-austens-novels" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Term frequency in Jane Austen’s novels</h3>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">library</span>(janeaustenr)</a>
<a class="sourceLine" id="cb45-2" title="2"></a>
<a class="sourceLine" id="cb45-3" title="3">book_words &lt;-<span class="st"> </span><span class="kw">austen_books</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb45-4" title="4"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-5" title="5"><span class="st">  </span><span class="kw">add_count</span>(book, <span class="dt">name =</span> <span class="st">&quot;total_words&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb45-6" title="6"><span class="st">  </span><span class="kw">group_by</span>(book, total_words) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-7" title="7"><span class="st">  </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-8" title="8"><span class="st">  </span><span class="kw">ungroup</span>()</a>
<a class="sourceLine" id="cb45-9" title="9"></a>
<a class="sourceLine" id="cb45-10" title="10">book_words</a>
<a class="sourceLine" id="cb45-11" title="11"><span class="co">#&gt; # A tibble: 40,379 x 4</span></a>
<a class="sourceLine" id="cb45-12" title="12"><span class="co">#&gt;   book           total_words word      n</span></a>
<a class="sourceLine" id="cb45-13" title="13"><span class="co">#&gt;   &lt;fct&gt;                &lt;int&gt; &lt;chr&gt; &lt;int&gt;</span></a>
<a class="sourceLine" id="cb45-14" title="14"><span class="co">#&gt; 1 Mansfield Park      160460 the    6206</span></a>
<a class="sourceLine" id="cb45-15" title="15"><span class="co">#&gt; 2 Mansfield Park      160460 to     5475</span></a>
<a class="sourceLine" id="cb45-16" title="16"><span class="co">#&gt; 3 Mansfield Park      160460 and    5438</span></a>
<a class="sourceLine" id="cb45-17" title="17"><span class="co">#&gt; 4 Emma                160996 to     5239</span></a>
<a class="sourceLine" id="cb45-18" title="18"><span class="co">#&gt; 5 Emma                160996 the    5201</span></a>
<a class="sourceLine" id="cb45-19" title="19"><span class="co">#&gt; 6 Emma                160996 and    4896</span></a>
<a class="sourceLine" id="cb45-20" title="20"><span class="co">#&gt; # ... with 4.037e+04 more rows</span></a></code></pre></div>
<p>There is one row in this book_words data frame for each word-book combination; <code>n</code> is the number of times that word is used in that book and <code>total_words</code> is the total words in that book. The usual suspects are here with the highest <code>n</code>, “the”, “and”, “to”, and so forth.</p>
<p>let’s look at the distribution of <code>n / total</code> for each novel, which is the predefined term frequency:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="kw">ggplot</span>(book_words) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb46-2" title="2"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(n <span class="op">/</span><span class="st"> </span>total_words, <span class="dt">fill =</span> book), <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb46-3" title="3"><span class="st">  </span><span class="kw">xlim</span>(<span class="ot">NA</span>, <span class="fl">0.0009</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb46-4" title="4"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>book, <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tf-distribution"></span>
<img src="analyzing-word-and-document-frequency_files/figure-html/tf-distribution-1.png" alt="Term Frequency Distribution in Jane Austen’s Novels" width="672" />
<p class="caption">
Figure 3.1: Term Frequency Distribution in Jane Austen’s Novels
</p>
</div>
</div>
<div id="zipfs-law" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Zipf’s law</h3>
<p>In Figure <a href="tf-idf.html#fig:tf-distribution">3.1</a> we see the characteristic long-tailed distribution of term frequency. In fact, those types of long-tailed distributions are so common in any given corpus of natural language (like a book, or a lot of text from a website, or spoken words) that the relationship between the frequency that a word is used and its rank has been the subject of study; a classic version of this relationship is called Zipf’s law, after George Zipf, a 20th century American linguist, which can be stated as.</p>
<p><span class="math display">\[
\text{word rank} \times \text{term frequency} = c
\]</span></p>
<p>where <span class="math inline">\(c\)</span> is a constant.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1">freq_by_rank &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb47-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(book) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb47-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">row_number</span>(), </a>
<a class="sourceLine" id="cb47-4" title="4">         <span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span> =<span class="st"> </span>n <span class="op">/</span><span class="st"> </span>total_words)</a>
<a class="sourceLine" id="cb47-5" title="5"></a>
<a class="sourceLine" id="cb47-6" title="6">freq_by_rank</a>
<a class="sourceLine" id="cb47-7" title="7"><span class="co">#&gt; # A tibble: 40,379 x 6</span></a>
<a class="sourceLine" id="cb47-8" title="8"><span class="co">#&gt; # Groups:   book [6]</span></a>
<a class="sourceLine" id="cb47-9" title="9"><span class="co">#&gt;   book           total_words word      n  rank `term frequency`</span></a>
<a class="sourceLine" id="cb47-10" title="10"><span class="co">#&gt;   &lt;fct&gt;                &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;            &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb47-11" title="11"><span class="co">#&gt; 1 Mansfield Park      160460 the    6206     1           0.0387</span></a>
<a class="sourceLine" id="cb47-12" title="12"><span class="co">#&gt; 2 Mansfield Park      160460 to     5475     2           0.0341</span></a>
<a class="sourceLine" id="cb47-13" title="13"><span class="co">#&gt; 3 Mansfield Park      160460 and    5438     3           0.0339</span></a>
<a class="sourceLine" id="cb47-14" title="14"><span class="co">#&gt; 4 Emma                160996 to     5239     1           0.0325</span></a>
<a class="sourceLine" id="cb47-15" title="15"><span class="co">#&gt; 5 Emma                160996 the    5201     2           0.0323</span></a>
<a class="sourceLine" id="cb47-16" title="16"><span class="co">#&gt; 6 Emma                160996 and    4896     3           0.0304</span></a>
<a class="sourceLine" id="cb47-17" title="17"><span class="co">#&gt; # ... with 4.037e+04 more rows</span></a></code></pre></div>
<p>Zipf’s law is often visualized by plotting rank on the x-axis and term frequency on the y-axis, on <strong>logarithmic scales</strong>. Plotting this way, an inversely proportional relationship will have a constant, negative slope.</p>
<p><span class="math display">\[
\lg{(\text{term frequency})} = - \lg{(\text{term frequency})} + \lg{c} 
\]</span></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1">freq_by_rank <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb48-2" title="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rank, <span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span>, <span class="dt">color =</span> book)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb48-3" title="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.1</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb48-4" title="4"><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb48-5" title="5"><span class="st">  </span><span class="kw">scale_y_log10</span>()</a></code></pre></div>
<p><img src="analyzing-word-and-document-frequency_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The slope is not quite constant, though; perhaps we could view this as a broken power law with, say, three sections. Let’s see what the exponent of the power law is for the middle section of the rank range.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" title="1">rank_subset &lt;-<span class="st"> </span>freq_by_rank <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb49-2" title="2"><span class="st">  </span><span class="kw">filter</span>(rank <span class="op">&lt;</span><span class="st"> </span><span class="dv">500</span>, rank <span class="op">&gt;</span><span class="st"> </span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb49-3" title="3"></a>
<a class="sourceLine" id="cb49-4" title="4">rank_subset <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb49-5" title="5"><span class="st">  </span><span class="kw">lm</span>(<span class="kw">log10</span>(<span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span>) <span class="op">~</span><span class="st"> </span><span class="kw">log10</span>(rank), <span class="dt">data =</span> .) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb49-6" title="6"><span class="st">  </span><span class="kw">summary</span>()</a>
<a class="sourceLine" id="cb49-7" title="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb49-8" title="8"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb49-9" title="9"><span class="co">#&gt; lm(formula = log10(`term frequency`) ~ log10(rank), data = .)</span></a>
<a class="sourceLine" id="cb49-10" title="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb49-11" title="11"><span class="co">#&gt; Residuals:</span></a>
<a class="sourceLine" id="cb49-12" title="12"><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></a>
<a class="sourceLine" id="cb49-13" title="13"><span class="co">#&gt; -0.11814 -0.01011 -0.00217  0.00928  0.08181 </span></a>
<a class="sourceLine" id="cb49-14" title="14"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb49-15" title="15"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb49-16" title="16"><span class="co">#&gt;              Estimate Std. Error t value            Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb49-17" title="17"><span class="co">#&gt; (Intercept) -0.622569   0.002218    -281 &lt;0.0000000000000002 ***</span></a>
<a class="sourceLine" id="cb49-18" title="18"><span class="co">#&gt; log10(rank) -1.112522   0.000953   -1168 &lt;0.0000000000000002 ***</span></a>
<a class="sourceLine" id="cb49-19" title="19"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb49-20" title="20"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb49-21" title="21"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb49-22" title="22"><span class="co">#&gt; Residual standard error: 0.0184 on 2932 degrees of freedom</span></a>
<a class="sourceLine" id="cb49-23" title="23"><span class="co">#&gt; Multiple R-squared:  0.998,  Adjusted R-squared:  0.998 </span></a>
<a class="sourceLine" id="cb49-24" title="24"><span class="co">#&gt; F-statistic: 1.36e+06 on 1 and 2932 DF,  p-value: &lt;0.0000000000000002</span></a></code></pre></div>
<p>The <span class="math inline">\(R^2\)</span> is approximately <span class="math inline">\(1\)</span>, so that we consider the relationship between log word rank and log tf to be <span class="math inline">\(\lg{\text{tf}} = -1.11\lg{\text{rank}} - 0. 62\)</span>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" title="1">freq_by_rank <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb50-2" title="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rank, <span class="st">`</span><span class="dt">term frequency</span><span class="st">`</span>, <span class="dt">color =</span> book)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb50-3" title="3"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="fl">-0.62</span>, <span class="dt">slope =</span> <span class="fl">-1.1</span>, <span class="dt">color =</span> <span class="st">&quot;gray50&quot;</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb50-4" title="4"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.1</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb50-5" title="5"><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb50-6" title="6"><span class="st">  </span><span class="kw">scale_y_log10</span>()</a></code></pre></div>
<p><img src="analyzing-word-and-document-frequency_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We have found a result close to the classic version of Zipf’s law for the corpus of Jane Austen’s novels. The deviations we see here at high rank are not uncommon for many kinds of language; <strong>a corpus of language often contains fewer rare words than predicted by a single power law</strong>. The deviations at low rank are more unusual. Jane Austen uses a lower percentage of the most common words than many collections of language. This kind of analysis could be extended to compare authors, or to compare any other collections of text; it can be implemented simply using tidy data principles.</p>
</div>
<div id="word-rank-slope-chart" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Word rank slope chart</h3>
<p><a href="https://www.hvitfeldt.me/">Emil Hvitfeldt</a> had a great <a href="https://www.hvitfeldt.me/blog/word-rank-slope-charts/">blog post</a> on how to make a word rank slope chart. This plot is generally designed to visualize the word rank difference of a set of paired words. If a writer is more comfortable using masculine words, then we could expect that “he” has a lower word rank than “she” (words are ranked in an descending order based on counts, as in <code>book_words</code>).</p>
<p>In Jane Austen’s novels, suppose we decide to compare word rank on a set of words related to gender</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" title="1">gender_words &lt;-<span class="st"> </span><span class="kw">tribble</span>(</a>
<a class="sourceLine" id="cb51-2" title="2">  <span class="op">~</span>Men, <span class="op">~</span>Women,</a>
<a class="sourceLine" id="cb51-3" title="3">  <span class="st">&quot;he&quot;</span>, <span class="st">&quot;she&quot;</span>,</a>
<a class="sourceLine" id="cb51-4" title="4">  <span class="st">&quot;his&quot;</span>, <span class="st">&quot;her&quot;</span>,</a>
<a class="sourceLine" id="cb51-5" title="5">  <span class="st">&quot;man&quot;</span>, <span class="st">&quot;woman&quot;</span>,</a>
<a class="sourceLine" id="cb51-6" title="6">  <span class="st">&quot;men&quot;</span>, <span class="st">&quot;women&quot;</span>,</a>
<a class="sourceLine" id="cb51-7" title="7">  <span class="st">&quot;boy&quot;</span>, <span class="st">&quot;girl&quot;</span>,</a>
<a class="sourceLine" id="cb51-8" title="8">  <span class="st">&quot;himself&quot;</span>, <span class="st">&quot;herself&quot;</span></a>
<a class="sourceLine" id="cb51-9" title="9">)</a></code></pre></div>
<p>We unnest 6 books into separate words as usual, and <code>pull()</code> them out as a vector.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">ordered_words &lt;-<span class="st"> </span><span class="kw">austen_books</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb52-2" title="2"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb52-3" title="3"><span class="st">  </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb52-4" title="4"><span class="st">  </span><span class="kw">pull</span>(word)</a></code></pre></div>
<p>We then use <code>match()</code> to match individual words to its word rank. The trick is using the logged rank rather the rank itself, otherwise the y scale will be heavily extended by large word rank. <code>scale_y_log10()</code> is not the best option in this case, since we need <code>scale_y_reverse()</code> to put the most frequent words on the top of our plot, and labels on the y axis can be fixed by passing a function to <code>label</code></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" title="1">gender_words &lt;-<span class="st"> </span>gender_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">male_rank_log10 =</span> <span class="kw">match</span>(Men, ordered_words) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log10</span>(),</a>
<a class="sourceLine" id="cb53-3" title="3">         <span class="dt">female_rank_log10 =</span> <span class="kw">match</span>(Women, ordered_words) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log10</span>(),</a>
<a class="sourceLine" id="cb53-4" title="4">         <span class="dt">rank_diff_log10 =</span> male_rank_log10 <span class="op">-</span><span class="st"> </span>female_rank_log10) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-5" title="5"><span class="st">  </span><span class="kw">pivot_longer</span>(male_rank_log10<span class="op">:</span>female_rank_log10, </a>
<a class="sourceLine" id="cb53-6" title="6">               <span class="dt">names_to =</span> <span class="st">&quot;index&quot;</span>, </a>
<a class="sourceLine" id="cb53-7" title="7">               <span class="dt">values_to =</span> <span class="st">&quot;rank&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-8" title="8"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">label =</span> <span class="kw">if_else</span>(index <span class="op">==</span><span class="st"> &quot;male_rank_log10&quot;</span>, Men, Women)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb53-9" title="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">index =</span> <span class="kw">fct_recode</span>(index,</a>
<a class="sourceLine" id="cb53-10" title="10">                            <span class="st">&quot;male&quot;</span> =<span class="st"> &quot;male_rank_log10&quot;</span>,</a>
<a class="sourceLine" id="cb53-11" title="11">                            <span class="st">&quot;female&quot;</span> =<span class="st"> &quot;female_rank_log10&quot;</span>))</a>
<a class="sourceLine" id="cb53-12" title="12"></a>
<a class="sourceLine" id="cb53-13" title="13">limits &lt;-<span class="st">  </span><span class="kw">max</span>(<span class="kw">abs</span>(gender_words<span class="op">$</span>rank_diff_log10)) <span class="op">*</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb53-14" title="14"></a>
<a class="sourceLine" id="cb53-15" title="15"><span class="kw">library</span>(ggrepel)</a>
<a class="sourceLine" id="cb53-16" title="16">gender_words <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb53-17" title="17"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(index, rank, <span class="dt">group =</span> Men)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-18" title="18"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> rank_diff_log10), <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-19" title="19"><span class="st">  </span><span class="kw">geom_text_repel</span>(<span class="kw">aes</span>(<span class="dt">label =</span> label)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-20" title="20"><span class="st">  </span><span class="kw">scale_y_reverse</span>(<span class="dt">label =</span> <span class="cf">function</span>(x) <span class="dv">10</span> <span class="op">^</span><span class="st"> </span>x, <span class="dt">breaks =</span> scales<span class="op">::</span><span class="kw">breaks_pretty</span>(<span class="dt">n =</span> <span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb53-21" title="21"><span class="st">  </span><span class="kw">scale_color_fermenter</span>(<span class="dt">type =</span> <span class="st">&quot;div&quot;</span>, <span class="dt">palette =</span> <span class="st">&quot;Spectral&quot;</span>, <span class="dt">limits =</span> limits) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb53-22" title="22"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="analyzing-word-and-document-frequency_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="the-bind_tf_idf-function" class="section level3">
<h3><span class="header-section-number">3.1.4</span> The <code>bind_tf_idf()</code> function</h3>
<p>The <code>bind_tf_idf()</code> function in the tidytext package takes a tidy text dataset as input with one row per token (term), per document. One column (<code>word</code> here) contains the terms/tokens, one column contains the documents (<code>book</code> in this case), and the last necessary column contains the counts, how many times each document contains each term (<code>n</code> in this example).</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1">book_words &lt;-<span class="st"> </span>book_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb54-2" title="2"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>total_words) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-3" title="3"><span class="st">  </span><span class="kw">bind_tf_idf</span>(<span class="dt">term =</span> word, <span class="dt">document =</span> book, <span class="dt">n =</span> n)</a>
<a class="sourceLine" id="cb54-4" title="4"></a>
<a class="sourceLine" id="cb54-5" title="5">book_words</a>
<a class="sourceLine" id="cb54-6" title="6"><span class="co">#&gt; # A tibble: 40,379 x 6</span></a>
<a class="sourceLine" id="cb54-7" title="7"><span class="co">#&gt;   book           word      n     tf   idf tf_idf</span></a>
<a class="sourceLine" id="cb54-8" title="8"><span class="co">#&gt;   &lt;fct&gt;          &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb54-9" title="9"><span class="co">#&gt; 1 Mansfield Park the    6206 0.0387     0      0</span></a>
<a class="sourceLine" id="cb54-10" title="10"><span class="co">#&gt; 2 Mansfield Park to     5475 0.0341     0      0</span></a>
<a class="sourceLine" id="cb54-11" title="11"><span class="co">#&gt; 3 Mansfield Park and    5438 0.0339     0      0</span></a>
<a class="sourceLine" id="cb54-12" title="12"><span class="co">#&gt; 4 Emma           to     5239 0.0325     0      0</span></a>
<a class="sourceLine" id="cb54-13" title="13"><span class="co">#&gt; 5 Emma           the    5201 0.0323     0      0</span></a>
<a class="sourceLine" id="cb54-14" title="14"><span class="co">#&gt; 6 Emma           and    4896 0.0304     0      0</span></a>
<a class="sourceLine" id="cb54-15" title="15"><span class="co">#&gt; # ... with 4.037e+04 more rows</span></a></code></pre></div>
<p>Notice that idf and thus tf-idf are zero for these extremely common words. These are all words that appear in all six of Jane Austen’s novels, so the idf term (which will then be the natural log of <span class="math inline">\(1\)</span>) is zero.</p>

<div class="rmdnote">
Although it is often not necessary to remove stopwords when extracting tf-idf on the ground that stop words will generally have zero idf, it is good practice, in most cases, to focus on non-stop words only (I do not anti-join here because I want to compare the results on common words between tf-idf and weighted log odds ratio). There are circumstances under which which some stop words could have a meaning worth capturing, e.g., “her” in abortion debates), and tf-idf is not a good option in such cases, see <a href="weighted-log-odds-ratio.html#weighted-log-odds-ratio">3.2</a>.
</div>

<p>Let’s look at terms with high tf-idf in Jane Austen’s works.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" title="1">book_words <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb55-2" title="2"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(tf_idf))</a>
<a class="sourceLine" id="cb55-3" title="3"><span class="co">#&gt; # A tibble: 40,379 x 6</span></a>
<a class="sourceLine" id="cb55-4" title="4"><span class="co">#&gt;   book                word         n      tf   idf  tf_idf</span></a>
<a class="sourceLine" id="cb55-5" title="5"><span class="co">#&gt;   &lt;fct&gt;               &lt;chr&gt;    &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb55-6" title="6"><span class="co">#&gt; 1 Sense &amp; Sensibility elinor     623 0.00519  1.79 0.00931</span></a>
<a class="sourceLine" id="cb55-7" title="7"><span class="co">#&gt; 2 Sense &amp; Sensibility marianne   492 0.00410  1.79 0.00735</span></a>
<a class="sourceLine" id="cb55-8" title="8"><span class="co">#&gt; 3 Mansfield Park      crawford   493 0.00307  1.79 0.00551</span></a>
<a class="sourceLine" id="cb55-9" title="9"><span class="co">#&gt; 4 Pride &amp; Prejudice   darcy      373 0.00305  1.79 0.00547</span></a>
<a class="sourceLine" id="cb55-10" title="10"><span class="co">#&gt; 5 Persuasion          elliot     254 0.00304  1.79 0.00544</span></a>
<a class="sourceLine" id="cb55-11" title="11"><span class="co">#&gt; 6 Emma                emma       786 0.00488  1.10 0.00536</span></a>
<a class="sourceLine" id="cb55-12" title="12"><span class="co">#&gt; # ... with 4.037e+04 more rows</span></a></code></pre></div>
<p>Proper nouns are often favoured by tf-idf, in this case names of important characters in each novel will generally have high tf-idf value. None of them occur in all of novels, and they are important, characteristic words for each text within the corpus of Jane Austen’s novels.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1">book_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb56-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(book) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb56-3" title="3"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb56-4" title="4"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb56-5" title="5"><span class="st">  </span><span class="kw">facet_bar</span>(<span class="dt">y =</span> word, <span class="dt">x =</span> tf_idf, <span class="dt">by =</span> book, <span class="dt">nrow =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="analyzing-word-and-document-frequency_files/figure-html/unnamed-chunk-14-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyzing-word-and-document-frequency.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="weighted-log-odds-ratio.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/tidy-text-mining/edit/master/book/analyzing-word-and-document-frequency.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
