[
["index.html", "Text Mining with R — Notes Preface", " Text Mining with R — Notes Qiushi Yan 2020-04-05 Preface This is a notebook concerning Text Mining with R: A Tidy Approach(Silge and Robinson 2017). tidyverse and tidytext are automatically loaded before each chapter: library(tidyverse) library(tidytext) I have defined a simiple function, facet_bar() to meet the frequent need in this book to make a facetted bar plot, with the y variable reordered by x in each facet by: facet_bar &lt;- function(df, y, x, by, nrow = 2, ncol = 2, scales = &quot;free&quot;) { mapping &lt;- aes(y = reorder_within({{ y }}, {{ x }}, {{ by }}), x = {{ x }}, fill = {{ by }}) facet &lt;- facet_wrap(vars({{ by }}), nrow = nrow, ncol = ncol, scales = scales) ggplot(df, mapping = mapping) + geom_col(show.legend = FALSE) + scale_y_reordered() + facet + ylab(&quot;&quot;) } As a quick demostration of this function, we can plot the top 10 common words in Jane Austen’s six books: austen_common &lt;- janeaustenr::austen_books() %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% count(book, word) %&gt;% group_by(book) %&gt;% top_n(10) %&gt;% ungroup() austen_common #&gt; # A tibble: 60 x 3 #&gt; book word n #&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Sense &amp; Sensibility dashwood 231 #&gt; 2 Sense &amp; Sensibility edward 220 #&gt; 3 Sense &amp; Sensibility elinor 623 #&gt; 4 Sense &amp; Sensibility jennings 199 #&gt; 5 Sense &amp; Sensibility marianne 492 #&gt; 6 Sense &amp; Sensibility miss 210 #&gt; # ... with 54 more rows # make a bar plot facet_bar(austen_common, y = word, x = n, by = book, nrow = 3) + labs(title = &quot;Top 10 common words in Jane Austen&#39;s novels&quot;, x = &quot;&quot;) "],
["tidy-text-format.html", "Chapter 1 Tidy text format", " Chapter 1 Tidy text format A “tidy” text format is defined as a per-token-per row data frame. This one-token-per-row structure is in contrast to the ways text is often stored in current analyses, perhaps as strings or in a document-term matrix (Chapter 5). For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph. In the tidytext package, we provide functionality to tokenize by commonly used units of text like these and convert to a one-term-per-row format. "],
["the-unnest-tokens-function.html", "1.1 The unnest_tokens() function", " 1.1 The unnest_tokens() function library(janeaustenr) austen_books() #&gt; # A tibble: 73,422 x 2 #&gt; text book #&gt; * &lt;chr&gt; &lt;fct&gt; #&gt; 1 &quot;SENSE AND SENSIBILITY&quot; Sense &amp; Sensibility #&gt; 2 &quot;&quot; Sense &amp; Sensibility #&gt; 3 &quot;by Jane Austen&quot; Sense &amp; Sensibility #&gt; 4 &quot;&quot; Sense &amp; Sensibility #&gt; 5 &quot;(1811)&quot; Sense &amp; Sensibility #&gt; 6 &quot;&quot; Sense &amp; Sensibility #&gt; # ... with 7.342e+04 more rows original_books &lt;- austen_books() %&gt;% group_by(book) %&gt;% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE)))) %&gt;% ungroup() original_books #&gt; # A tibble: 73,422 x 4 #&gt; text book linenumber chapter #&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 &quot;SENSE AND SENSIBILITY&quot; Sense &amp; Sensibility 1 0 #&gt; 2 &quot;&quot; Sense &amp; Sensibility 2 0 #&gt; 3 &quot;by Jane Austen&quot; Sense &amp; Sensibility 3 0 #&gt; 4 &quot;&quot; Sense &amp; Sensibility 4 0 #&gt; 5 &quot;(1811)&quot; Sense &amp; Sensibility 5 0 #&gt; 6 &quot;&quot; Sense &amp; Sensibility 6 0 #&gt; # ... with 7.342e+04 more rows original_books %&gt;% unnest_tokens(word, text) #&gt; # A tibble: 725,055 x 4 #&gt; book linenumber chapter word #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensibility 1 0 sense #&gt; 2 Sense &amp; Sensibility 1 0 and #&gt; 3 Sense &amp; Sensibility 1 0 sensibility #&gt; 4 Sense &amp; Sensibility 3 0 by #&gt; 5 Sense &amp; Sensibility 3 0 jane #&gt; 6 Sense &amp; Sensibility 3 0 austen #&gt; # ... with 7.25e+05 more rows stop_words #&gt; # A tibble: 1,149 x 2 #&gt; word lexicon #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 a SMART #&gt; 2 a&#39;s SMART #&gt; 3 able SMART #&gt; 4 about SMART #&gt; 5 above SMART #&gt; 6 according SMART #&gt; # ... with 1,143 more rows tidy_books &lt;- original_books %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) tidy_books #&gt; # A tibble: 217,609 x 4 #&gt; book linenumber chapter word #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensibility 1 0 sense #&gt; 2 Sense &amp; Sensibility 1 0 sensibility #&gt; 3 Sense &amp; Sensibility 3 0 jane #&gt; 4 Sense &amp; Sensibility 3 0 austen #&gt; 5 Sense &amp; Sensibility 5 0 1811 #&gt; 6 Sense &amp; Sensibility 10 1 chapter #&gt; # ... with 2.176e+05 more rows "],
["the-gutenbergr-package.html", "1.2 The gutenbergr package", " 1.2 The gutenbergr package library(gutenbergr) The gutenbergr package provides access to the public domain works from the Project Gutenberg collection. The package includes tools both for downloading books (stripping out the unhelpful header/footer information), and a complete dataset of Project Gutenberg metadata that can be used to find works of interest. In this book, we will mostly use the function gutenberg_download() that downloads one or more works from Project Gutenberg by ID. The dataset gutenberg_metadata contains information about each work, pairing Gutenberg ID with title, author, language, etc: gutenberg_metadata #&gt; # A tibble: 51,997 x 8 #&gt; gutenberg_id title author gutenberg_autho~ language gutenberg_books~ rights #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 0 &lt;NA&gt; &lt;NA&gt; NA en &lt;NA&gt; Publi~ #&gt; 2 1 &quot;The~ Jeffe~ 1638 en United States L~ Publi~ #&gt; 3 2 &quot;The~ Unite~ 1 en American Revolu~ Publi~ #&gt; 4 3 &quot;Joh~ Kenne~ 1666 en &lt;NA&gt; Publi~ #&gt; 5 4 &quot;Lin~ Linco~ 3 en US Civil War Publi~ #&gt; 6 5 &quot;The~ Unite~ 1 en American Revolu~ Publi~ #&gt; # ... with 5.199e+04 more rows, and 1 more variable: has_text &lt;lgl&gt; For example, you could find the Gutenberg ID of Wuthering Heights by doing: gutenberg_metadata %&gt;% filter(title == &quot;Wuthering Heights&quot;) #&gt; # A tibble: 1 x 8 #&gt; gutenberg_id title author gutenberg_autho~ language gutenberg_books~ rights #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 768 Wuth~ Bront~ 405 en Gothic Fiction/~ Publi~ #&gt; # ... with 1 more variable: has_text &lt;lgl&gt; gutenberg_download(768) #&gt; # A tibble: 12,085 x 2 #&gt; gutenberg_id text #&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 768 &quot;WUTHERING HEIGHTS&quot; #&gt; 2 768 &quot;&quot; #&gt; 3 768 &quot;&quot; #&gt; 4 768 &quot;CHAPTER I&quot; #&gt; 5 768 &quot;&quot; #&gt; 6 768 &quot;&quot; #&gt; # ... with 1.208e+04 more rows In many analyses, you may want to filter just for English works, avoid duplicates, and include only books that have text that can be downloaded. The gutenberg_works() function does this pre-filtering. It also allows you to perform filtering as an argument: gutenberg_works(author == &quot;Austen, Jane&quot;) #&gt; # A tibble: 10 x 8 #&gt; gutenberg_id title author gutenberg_autho~ language gutenberg_books~ rights #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 105 Pers~ Auste~ 68 en &lt;NA&gt; Publi~ #&gt; 2 121 Nort~ Auste~ 68 en Gothic Fiction Publi~ #&gt; 3 141 Mans~ Auste~ 68 en &lt;NA&gt; Publi~ #&gt; 4 158 Emma Auste~ 68 en &lt;NA&gt; Publi~ #&gt; 5 161 Sens~ Auste~ 68 en &lt;NA&gt; Publi~ #&gt; 6 946 Lady~ Auste~ 68 en &lt;NA&gt; Publi~ #&gt; # ... with 4 more rows, and 1 more variable: has_text &lt;lgl&gt; "],
["compare-word-frequency.html", "1.3 Compare word frequency", " 1.3 Compare word frequency As a common task in text analysis, compariosn of word frequencies is often employed as a tool to extract linguistic characteristics. A rule of thumb is to compare word proportions instead of raw counts. In this example, we compare novels of Jane Austen, H.G. Wells, and the Bronte Sisters. austen &lt;- austen_books() %&gt;% select(-book) %&gt;% mutate(author = &quot;Jane Austen&quot;) bronte &lt;- gutenberg_download(c(1260, 768, 969, 9182, 767)) %&gt;% select(-gutenberg_id) %&gt;% mutate(author = &quot;Brontë Sisters&quot;) hgwells &lt;- gutenberg_download(c(35, 36, 5230, 159)) %&gt;% select(-gutenberg_id) %&gt;% mutate(author = &quot;H.G. Wells&quot;) tidy_book &lt;- function(author) { author %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) } books &lt;- bind_rows(tidy_book(austen), tidy_book(bronte), tidy_book(hgwells)) %&gt;% mutate(word = str_extract(word, &quot;[:alpha:]+&quot;)) %&gt;% count(author, word, sort = TRUE) books #&gt; # A tibble: 46,956 x 3 #&gt; author word n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Jane Austen miss 1860 #&gt; 2 Jane Austen time 1339 #&gt; 3 Brontë Sisters time 1065 #&gt; 4 Jane Austen fanny 977 #&gt; 5 Jane Austen emma 866 #&gt; 6 Jane Austen sister 865 #&gt; # ... with 4.695e+04 more rows Now, our goal is to use Jane Austen as a reference to which the other two authors are compared to in terms of word frequency. The data manipulation requires a bit trick, after computing proportions of word usage, we first pivot_wider three authors altogether, an then pivot_wider the other two authors back. comparison_df &lt;- books %&gt;% add_count(author, wt = n, name = &quot;total_word&quot;) %&gt;% mutate(proportion = n / total_word) %&gt;% select(-total_word, -n) %&gt;% pivot_wider(names_from = author, values_from = proportion, values_fill = list(proportion = 0)) %&gt;% pivot_longer(3:4, names_to = &quot;other&quot;, values_to = &quot;proportion&quot;) comparison_df #&gt; # A tibble: 56,002 x 4 #&gt; word `Jane Austen` other proportion #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 miss 0.00855 Brontë Sisters 0.00342 #&gt; 2 miss 0.00855 H.G. Wells 0.000120 #&gt; 3 time 0.00615 Brontë Sisters 0.00424 #&gt; 4 time 0.00615 H.G. Wells 0.00682 #&gt; 5 fanny 0.00449 Brontë Sisters 0.0000438 #&gt; 6 fanny 0.00449 H.G. Wells 0 #&gt; # ... with 5.6e+04 more rows library(scales) comparison_df %&gt;% filter(proportion &gt; 1 / 1e5) %&gt;% ggplot(aes(proportion, `Jane Austen`)) + geom_abline(color = &quot;gray40&quot;, lty = 2) + geom_jitter(aes(color = abs(`Jane Austen` - proportion)), alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) + geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) + scale_x_log10(labels = percent_format()) + scale_y_log10(labels = percent_format()) + scale_color_gradient(limits = c(0, 0.001), low = &quot;darkslategray4&quot;, high = &quot;gray75&quot;) + facet_wrap(~ other) + guides(color = FALSE) Words that are close to the line in these plots have similar frequencies in both sets of texts, for example, in both Austen and Brontë texts (“miss”, “time”, “day” at the upper frequency end) or in both Austen and Wells texts (“time”, “day”, “brother” at the high frequency end). Words that are far from the line are words that are found more in one set of texts than another. For example, in the Austen-Brontë panel, words like “elizabeth”, “emma”, and “fanny” (all proper nouns) are found in Austen’s texts but not much in the Brontë texts, while words like “arthur” and “dog” are found in the Brontë texts but not the Austen texts. In comparing H.G. Wells with Jane Austen, Wells uses words like “beast”, “guns”, “feet”, and “black” that Austen does not, while Austen uses words like “family”, “friend”, “letter”, and “dear” that Wells does not. Notice that the words in the Austen-Brontë panel are closer to the zero-slope line than in the Austen-Wells panel. Also notice that the words extend to lower frequencies in the Austen-Brontë panel; there is empty space in the Austen-Wells panel at low frequency. These characteristics indicate that Austen and the Brontë sisters use more similar words than Austen and H.G. Wells. Also, we see that not all the words are found in all three sets of texts and there are fewer data points in the panel for Austen and H.G. Wells. Furhter, we can conduct a simple correlation test cor.test(data = filter(comparison_df, other == &quot;Brontë Sisters&quot;), ~ proportion + `Jane Austen`) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: proportion and Jane Austen #&gt; t = 169, df = 27999, p-value &lt;0.0000000000000002 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.705 0.716 #&gt; sample estimates: #&gt; cor #&gt; 0.711 cor.test(data = filter(comparison_df, other == &quot;H.G. Wells&quot;), ~ proportion + `Jane Austen`) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: proportion and Jane Austen #&gt; t = 72, df = 27999, p-value &lt;0.0000000000000002 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.383 0.403 #&gt; sample estimates: #&gt; cor #&gt; 0.393 "],
["other-tokenization-methods.html", "1.4 Other tokenization methods", " 1.4 Other tokenization methods unnest_tokens supports other ways to split a column into tokens. text &lt;- c(&quot;This is, my bookdown book.&quot;, &quot;Chapter 1: Preface\\n&quot;, &quot;Thanks for \\n reading this book\\n&quot;, &quot;Chapter 2: Introduction\\n&quot;, &quot;Chapter 3: Methods\\n&quot;, &quot;I demonstrate all of the methods here,&quot;, &quot;well, not all actually.\\n\\n&quot;, &quot;Chapter 4: Discussion\\n&quot;, &quot;blablabla,&quot;, &quot;blablabla,&quot;, &quot;blablabla.&quot;) df &lt;- tibble(text = text) cat(df$text) #&gt; This is, my bookdown book. Chapter 1: Preface #&gt; Thanks for #&gt; reading this book #&gt; Chapter 2: Introduction #&gt; Chapter 3: Methods #&gt; I demonstrate all of the methods here, well, not all actually. #&gt; #&gt; Chapter 4: Discussion #&gt; blablabla, blablabla, blablabla. # lines df %&gt;% unnest_tokens(line, text, token = &quot;lines&quot;) #&gt; # A tibble: 12 x 1 #&gt; line #&gt; &lt;chr&gt; #&gt; 1 &quot;this is, my bookdown book.&quot; #&gt; 2 &quot;chapter 1: preface&quot; #&gt; 3 &quot;thanks for &quot; #&gt; 4 &quot; reading this book&quot; #&gt; 5 &quot;chapter 2: introduction&quot; #&gt; 6 &quot;chapter 3: methods&quot; #&gt; # ... with 6 more rows # sentences, split by period df %&gt;% unnest_tokens(sentences, text, token = &quot;sentences&quot;) #&gt; # A tibble: 3 x 1 #&gt; sentences #&gt; &lt;chr&gt; #&gt; 1 this is, my bookdown book. #&gt; 2 chapter 1: preface thanks for reading this book chapter 2: introduction ~ #&gt; 3 chapter 4: discussion blablabla, blablabla, blablabla. # paragraphs df %&gt;% unnest_tokens(paragraphs, text, token = &quot;paragraphs&quot;) #&gt; # A tibble: 7 x 1 #&gt; paragraphs #&gt; &lt;chr&gt; #&gt; 1 &quot;this is, my bookdown book. chapter 1: preface&quot; #&gt; 2 &quot;thanks for reading this book&quot; #&gt; 3 &quot;chapter 2: introduction&quot; #&gt; 4 &quot;chapter 3: methods&quot; #&gt; 5 &quot;i demonstrate all of the methods here, well, not all actually.&quot; #&gt; 6 &quot; chapter 4: discussion&quot; #&gt; # ... with 1 more row # split into characters or multiple characters df %&gt;% unnest_tokens(character, text, token = &quot;characters&quot;) #&gt; # A tibble: 188 x 1 #&gt; character #&gt; &lt;chr&gt; #&gt; 1 t #&gt; 2 h #&gt; 3 i #&gt; 4 s #&gt; 5 i #&gt; 6 s #&gt; # ... with 182 more rows df %&gt;% unnest_tokens(characters, text, token = &quot;character_shingles&quot;, n = 4) #&gt; # A tibble: 185 x 1 #&gt; characters #&gt; &lt;chr&gt; #&gt; 1 this #&gt; 2 hisi #&gt; 3 isis #&gt; 4 sism #&gt; 5 ismy #&gt; 6 smyb #&gt; # ... with 179 more rows # split by regex df %&gt;% unnest_tokens(chapter, text, token = &quot;regex&quot;, pattern = &quot;Chapter \\\\d:&quot;) #&gt; # A tibble: 5 x 1 #&gt; chapter #&gt; &lt;chr&gt; #&gt; 1 &quot;this is, my bookdown book.\\n&quot; #&gt; 2 &quot; preface\\n\\nthanks for \\n reading this book\\n\\n&quot; #&gt; 3 &quot; introduction\\n\\n&quot; #&gt; 4 &quot; methods\\n\\ni demonstrate all of the methods here,\\nwell, not all actually.\\~ #&gt; 5 &quot; discussion\\n\\nblablabla,\\nblablabla,\\nblablabla.&quot; "],
["sentiment-analysis-with-tidy-data.html", "Chapter 2 Sentiment analysis with tidy data", " Chapter 2 Sentiment analysis with tidy data One way to analyze the sentiment of a text is to consider the text as a combination of its individual words and the sentiment content of the whole text as the sum of the sentiment content of the individual words. This isn’t the only way to approach sentiment analysis, but it is an often-used approach, and an approach that naturally takes advantage of the tidy tool ecosystem. library(janeaustenr) "],
["the-sentiments-dataset.html", "2.1 The sentiments dataset", " 2.1 The sentiments dataset There are a variety of methods and dictionaries that exist for evaluating the opinion or emotion in text. The tidytext package contains several sentiment lexicons. Three general-purpose lexicons are AFINN from Finn Årup Nielsen bing from Bing Liu and collaborators nrc from Saif Mohammad and Peter Turney. loughran: he Loughran and McDonald dictionary of financial sentiment terms. This dictionary was developed based on analyses of financial reports, and intentionally avoids words like “share” and “fool”, as well as subtler terms like “liability” and “risk” that may not have a negative meaning in a financial context. All three of these lexicons are based on unigrams. These lexicons contain many English words and the words are assigned scores for positive / negative sentiment, and also possibly emotions like joy, anger, sadness, and so forth. The nrc lexicon categorizes words into classes of positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust. The bing lexicon categorizes words in a binary fashion into positive and negative categories. The AFINN lexicon assigns words with a score that runs between -5 and 5, with negative scores indicating negative sentiment and positive scores indicating positive sentiment. The loughran lexicon divided words into constraining, litigious, negative, positive, superfluous and uncertainty get_sentiments(&quot;nrc&quot;) #&gt; # A tibble: 13,901 x 2 #&gt; word sentiment #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 abacus trust #&gt; 2 abandon fear #&gt; 3 abandon negative #&gt; 4 abandon sadness #&gt; 5 abandoned anger #&gt; 6 abandoned fear #&gt; # ... with 1.39e+04 more rows # install.packages(&quot;textdata&quot;) get_sentiments(&quot;bing&quot;) #&gt; # A tibble: 6,786 x 2 #&gt; word sentiment #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2-faces negative #&gt; 2 abnormal negative #&gt; 3 abolish negative #&gt; 4 abominable negative #&gt; 5 abominably negative #&gt; 6 abominate negative #&gt; # ... with 6,780 more rows get_sentiments(&quot;afinn&quot;) #&gt; # A tibble: 2,477 x 2 #&gt; word value #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 abandon -2 #&gt; 2 abandoned -2 #&gt; 3 abandons -2 #&gt; 4 abducted -2 #&gt; 5 abduction -2 #&gt; 6 abductions -2 #&gt; # ... with 2,471 more rows get_sentiments(&quot;loughran&quot;) %&gt;% filter(sentiment == &quot;superfluous&quot;) #&gt; # A tibble: 21 x 2 #&gt; word sentiment #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 aegis superfluous #&gt; 2 amorphous superfluous #&gt; 3 anticipatory superfluous #&gt; 4 appertaining superfluous #&gt; 5 assimilate superfluous #&gt; 6 assimilating superfluous #&gt; # ... with 15 more rows Dictionary-based methods like the ones we are discussing find the total sentiment of a piece of text by adding up the individual sentiment scores for each word in the text. One caveat is that the size of the chunk of text that we use to add up unigram sentiment scores can have an effect on an analysis. A text the size of many paragraphs can often have positive and negative sentiment averaged out to about zero, while sentence-sized or paragraph-sized text often works better "],
["sentiment-analysis-with-inner-join.html", "2.2 Sentiment analysis with inner join", " 2.2 Sentiment analysis with inner join library(janeaustenr) tidy_books &lt;- austen_books() %&gt;% group_by(book) %&gt;% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE)))) %&gt;% ungroup() %&gt;% unnest_tokens(word, text) tidy_books #&gt; # A tibble: 725,055 x 4 #&gt; book linenumber chapter word #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensibility 1 0 sense #&gt; 2 Sense &amp; Sensibility 1 0 and #&gt; 3 Sense &amp; Sensibility 1 0 sensibility #&gt; 4 Sense &amp; Sensibility 3 0 by #&gt; 5 Sense &amp; Sensibility 3 0 jane #&gt; 6 Sense &amp; Sensibility 3 0 austen #&gt; # ... with 7.25e+05 more rows Because we name the count column word in unnest_tokens(), it’s convenient to join with the sentiment dataset: nrc_joy &lt;- get_sentiments(&quot;nrc&quot;) %&gt;% filter(sentiment == &quot;joy&quot;) tidy_books %&gt;% filter(book == &quot;Emma&quot;) %&gt;% inner_join(nrc_joy) %&gt;% count(word, sort = TRUE) #&gt; # A tibble: 303 x 2 #&gt; word n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 good 359 #&gt; 2 young 192 #&gt; 3 friend 166 #&gt; 4 hope 143 #&gt; 5 happy 125 #&gt; 6 love 117 #&gt; # ... with 297 more rows Next, we count up how many positive and negative words there are in defined sections of each book. We define an index here to keep track of where we are in the narrative; this index (using integer division) counts up sections of 80 lines of text. jane_austen_sentiment &lt;- tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% mutate(index = linenumber %/% 80) %&gt;% count(book, index, sentiment) %&gt;% pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %&gt;% mutate(sentiment = positive - negative) jane_austen_sentiment #&gt; # A tibble: 920 x 5 #&gt; book index negative positive sentiment #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Sense &amp; Sensibility 0 16 32 16 #&gt; 2 Sense &amp; Sensibility 1 19 53 34 #&gt; 3 Sense &amp; Sensibility 2 12 31 19 #&gt; 4 Sense &amp; Sensibility 3 15 31 16 #&gt; 5 Sense &amp; Sensibility 4 16 34 18 #&gt; 6 Sense &amp; Sensibility 5 16 51 35 #&gt; # ... with 914 more rows ggplot(jane_austen_sentiment) + geom_col(aes(index, sentiment, fill = book), show.legend = F) + facet_wrap( ~ book, ncol = 2, scales = &quot;free_x&quot;) "],
["comparing-3-different-dictionaries.html", "2.3 Comparing 3 different dictionaries", " 2.3 Comparing 3 different dictionaries pride_prejudice &lt;- tidy_books %&gt;% filter(book == &quot;Pride &amp; Prejudice&quot;) pride_prejudice #&gt; # A tibble: 122,204 x 4 #&gt; book linenumber chapter word #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Pride &amp; Prejudice 1 0 pride #&gt; 2 Pride &amp; Prejudice 1 0 and #&gt; 3 Pride &amp; Prejudice 1 0 prejudice #&gt; 4 Pride &amp; Prejudice 3 0 by #&gt; 5 Pride &amp; Prejudice 3 0 jane #&gt; 6 Pride &amp; Prejudice 3 0 austen #&gt; # ... with 1.222e+05 more rows afinn &lt;- pride_prejudice %&gt;% inner_join(get_sentiments(&quot;afinn&quot;)) %&gt;% mutate(index = linenumber %/% 80) %&gt;% count(book, index, wt = value, name = &quot;value&quot;) %&gt;% mutate(dict = &quot;afinn&quot;) %&gt;% select(index, value, dict) bing &lt;- pride_prejudice %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% mutate(index = linenumber %/% 80) %&gt;% count(index, sentiment) %&gt;% pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %&gt;% mutate(value = positive - negative, dict = &quot;bing&quot;) %&gt;% select(index, value, dict) nrc &lt;- pride_prejudice %&gt;% inner_join(get_sentiments(&quot;nrc&quot;)) %&gt;% filter(sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% mutate(index = linenumber %/% 80) %&gt;% count(index, sentiment) %&gt;% pivot_wider(names_from = sentiment, values_from = n, values_fill = list(n = 0)) %&gt;% mutate(value = positive - negative, dict = &quot;nrc&quot;) %&gt;% select(index, value, dict) bind_rows(afinn, bing, nrc) %&gt;% ggplot() + geom_col(aes(index, value, fill = dict), show.legend = FALSE) + facet_wrap(~ dict, nrow = 3) It is natural for score based on these 3 different dictionary to differ in some sense, because for the latter two we are just consider as the sentiment score the number of positive words minus that of negative words. But they shoud all have similar relative trajectories through the novel. Why is, for example, the result for the NRC lexicon biased so high in sentiment compared to the Bing et al. result? Let’s look briefly at how many positive and negative words are in these lexicons. get_sentiments(&quot;nrc&quot;) %&gt;% filter(sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% count(sentiment) #&gt; # A tibble: 2 x 2 #&gt; sentiment n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 negative 3324 #&gt; 2 positive 2312 get_sentiments(&quot;bing&quot;) %&gt;% count(sentiment) #&gt; # A tibble: 2 x 2 #&gt; sentiment n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 negative 4781 #&gt; 2 positive 2005 Both lexicons have more negative than positive words, but the ratio of negative to positive words is higher in the Bing lexicon than the NRC lexicon. This will contribute to the effect we see in the plot above, as will any systematic difference in word matches, e.g. if the negative words in the NRC lexicon do not match the words that Jane Austen uses very well.. Whatever the source of these differences, we see similar relative trajectories across the narrative arc, with similar changes in slope, but marked differences in absolute sentiment from lexicon to lexicon. This is all important context to keep in mind when choosing a sentiment lexicon for analysis. "],
["most-common-positive-and-negative-words.html", "2.4 Most common positive and negative words", " 2.4 Most common positive and negative words bing_word_counts &lt;- tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% count(word, sentiment, sort = TRUE) %&gt;% ungroup() bing_word_counts #&gt; # A tibble: 2,585 x 3 #&gt; word sentiment n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 miss negative 1855 #&gt; 2 well positive 1523 #&gt; 3 good positive 1380 #&gt; 4 great positive 981 #&gt; 5 like positive 725 #&gt; 6 better positive 639 #&gt; # ... with 2,579 more rows The word “miss” is coded as negative but it is used as a title for young, unmarried women in Jane Austen’s works. If it were appropriate for our purposes, we could easily add “miss” to a custom stop-words list using bind_rows(). We could implement that with a strategy such as this： custom_stop_words &lt;- tibble(word = c(&quot;miss&quot;), lexicon = c(&quot;custom&quot;)) %&gt;% bind_rows(stop_words) bing_word_counts &lt;- tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% anti_join(custom_stop_words) %&gt;% group_by(sentiment) %&gt;% count(word, sentiment, sort = T) %&gt;% ungroup() Then we can make a bar plot bing_word_counts %&gt;% group_by(sentiment) %&gt;% top_n(10) %&gt;% ungroup() %&gt;% facet_bar(y = word, x = n, by = sentiment, nrow = 1) + labs(title = &quot;Top 10 words of sentiment in Jane Austen&#39;s books&quot;) "],
["wordclouds.html", "2.5 Wordclouds", " 2.5 Wordclouds The ggwordcloud package adds wordcloud extension into the ggplot2 ecosystem. The geometry geom_text_wordcloud() has a similar sytax comparing to geom_text_repel: label for the word and size for the count. library(ggwordcloud) wordcloud_df &lt;-tidy_books %&gt;% anti_join(custom_stop_words) %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% count(sentiment, word, sort = T) %&gt;% top_n(200) wordcloud_df %&gt;% ggplot() + geom_text_wordcloud_area(aes(label = word, size = n)) + scale_size_area(max_size = 15) One particular issue with wordcloud plot is that they use font size porportional to the corresponding frequency, so that long words with smaller frequency can sometimes misleadingly encompass much ink area than short words with larger frequency. One solution is to use geom_texg_wordcloud, which aims to set the ink area, rather than font size, proportional to the frequency, so that our perception are not biased by number of letters. wordcloud_df %&gt;% ggplot() + geom_text_wordcloud_area(aes(label = word, size = n), shape = &quot;star&quot;) + scale_size_area(max_size = 15) In other functions, such as wordcloud::comparison.cloud(), you may need to turn the data frame into a matrix with reshape2’s acast(). Let’s do the sentiment analysis to tag positive and negative words using an inner join, then find the most common positive and negative words. Until the step where we need to send the data to comparison.cloud() library(wordcloud) tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% count(word, sentiment, sort = TRUE) %&gt;% reshape2::acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;% comparison.cloud(colors = c(&quot;gray20&quot;, &quot;gray80&quot;), max.words = 100) "],
["units-other-than-words.html", "2.6 Units other than words", " 2.6 Units other than words Some sentiment analysis algorithms look beyond only unigrams (i.e. single words) to try to understand the sentiment of a sentence as a whole. We may want to tokenize text into sentences, and it makes sense to use a new name for the output column in such a case. PandP_sentences &lt;- tibble(text = prideprejudice) %&gt;% unnest_tokens(sentence, text, token = &quot;sentences&quot;) PandP_sentences #&gt; # A tibble: 7,066 x 1 #&gt; sentence #&gt; &lt;chr&gt; #&gt; 1 &quot;pride and prejudice by jane austen chapter 1 it is a truth universally~ #&gt; 2 &quot;however little known the feelings or views of such a man may be on his first~ #&gt; 3 &quot;\\&quot;my dear mr.&quot; #&gt; 4 &quot;bennet,\\&quot; said his lady to him one day, \\&quot;have you heard that netherfield pa~ #&gt; 5 &quot;mr.&quot; #&gt; 6 &quot;bennet replied that he had not.&quot; #&gt; # ... with 7,060 more rows The sentence tokenizing does seem to have a bit of trouble with UTF-8 encoded text, especially with sections of dialogue; it does much better with punctuation in ASCII. One possibility, if this is important, is to try using iconv(), with something like iconv(text, to = 'latin1') in a mutate statement before unnesting. tibble(text = prideprejudice) %&gt;% mutate(text = iconv(text, to = &quot;ASCII&quot;)) %&gt;% unnest_tokens(sentence, text, token = &quot;sentences&quot;) #&gt; # A tibble: 7,066 x 1 #&gt; sentence #&gt; &lt;chr&gt; #&gt; 1 &quot;pride and prejudice by jane austen chapter 1 it is a truth universally~ #&gt; 2 &quot;however little known the feelings or views of such a man may be on his first~ #&gt; 3 &quot;\\&quot;my dear mr.&quot; #&gt; 4 &quot;bennet,\\&quot; said his lady to him one day, \\&quot;have you heard that netherfield pa~ #&gt; 5 &quot;mr.&quot; #&gt; 6 &quot;bennet replied that he had not.&quot; #&gt; # ... with 7,060 more rows Another option in unnest_tokens() is to split into tokens using a regex pattern. We could use this, for example, to split the text of Jane Austen’s novels into a data frame by chapter. austen_chapters &lt;- austen_books() %&gt;% group_by(book) %&gt;% unnest_tokens(chapter, text, token = &quot;regex&quot;, pattern = &quot;Chapter|CHAPTER [\\\\dIVXLC]&quot;) %&gt;% ungroup() # 275 rows austen_chapters #&gt; # A tibble: 275 x 2 #&gt; book chapter #&gt; &lt;fct&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensibi~ &quot;sense and sensibility\\n\\nby jane austen\\n\\n(1811)\\n\\n\\n\\n\\n&quot; #&gt; 2 Sense &amp; Sensibi~ &quot;\\n\\n\\nthe family of dashwood had long been settled in susse~ #&gt; 3 Sense &amp; Sensibi~ &quot;\\n\\n\\nmrs. john dashwood now installed herself mistress of ~ #&gt; 4 Sense &amp; Sensibi~ &quot;\\n\\n\\nmrs. dashwood remained at norland several months; not~ #&gt; 5 Sense &amp; Sensibi~ &quot;\\n\\n\\n\\&quot;what a pity it is, elinor,\\&quot; said marianne, \\&quot;that ~ #&gt; 6 Sense &amp; Sensibi~ &quot;\\n\\n\\nno sooner was her answer dispatched, than mrs. dashwo~ #&gt; # ... with 269 more rows # 275 rows tidy_books %&gt;% distinct(book, chapter) #&gt; # A tibble: 275 x 2 #&gt; book chapter #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Sense &amp; Sensibility 0 #&gt; 2 Sense &amp; Sensibility 1 #&gt; 3 Sense &amp; Sensibility 2 #&gt; 4 Sense &amp; Sensibility 3 #&gt; 5 Sense &amp; Sensibility 4 #&gt; 6 Sense &amp; Sensibility 5 #&gt; # ... with 269 more rows In the austen_chapters data frame, each row corresponds to one chapter. Near the beginning of this chapter, we used a similar regex to find where all the chapters were in Austen’s novels for a tidy data frame organized by one-word-per-row (Section 2.2). Using a regex as the token is somewhat similar to tidy_books %&gt;% group_by(book, chapter) %&gt;% summarize(str_c(word, collapse = &quot; &quot;)) #&gt; # A tibble: 275 x 3 #&gt; # Groups: book [6] #&gt; book chapter `str_c(word, collapse = &quot; &quot;)` #&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensi~ 0 sense and sensibility by jane austen 1811 #&gt; 2 Sense &amp; Sensi~ 1 chapter 1 the family of dashwood had long been settled~ #&gt; 3 Sense &amp; Sensi~ 2 chapter 2 mrs john dashwood now installed herself mist~ #&gt; 4 Sense &amp; Sensi~ 3 chapter 3 mrs dashwood remained at norland several mon~ #&gt; 5 Sense &amp; Sensi~ 4 chapter 4 what a pity it is elinor said marianne that ~ #&gt; 6 Sense &amp; Sensi~ 5 chapter 5 no sooner was her answer dispatched than mrs~ #&gt; # ... with 269 more rows We can use tidy text analysis to ask questions such as what are the most negative chapters in each of Jane Austen’s novels? First, let’s get the list of negative words from the Bing lexicon. Second, let’s make a data frame of how many words are in each chapter so we can normalize for the length of chapters. Then, let’s find the number of negative words in each chapter and divide by the total words in each chapter. For each book, which chapter has the highest proportion of negative words? bing_negative &lt;- get_sentiments(&quot;bing&quot;) %&gt;% filter(sentiment == &quot;negative&quot;) chapter_words &lt;- tidy_books %&gt;% count(book, chapter) tidy_books %&gt;% semi_join(bing_negative) %&gt;% count(book, chapter, name = &quot;negative_words&quot;) %&gt;% left_join(chapter_words) %&gt;% mutate(ratio = negative_words / n) %&gt;% filter(chapter != 0) %&gt;% group_by(book) %&gt;% top_n(1) #&gt; # A tibble: 6 x 5 #&gt; # Groups: book [6] #&gt; book chapter negative_words n ratio #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Sense &amp; Sensibility 43 161 3405 0.0473 #&gt; 2 Pride &amp; Prejudice 34 111 2104 0.0528 #&gt; 3 Mansfield Park 46 173 3685 0.0469 #&gt; 4 Emma 15 151 3340 0.0452 #&gt; 5 Northanger Abbey 21 149 2982 0.0500 #&gt; 6 Persuasion 4 62 1807 0.0343 "],
["analyzing-word-and-document-frequency.html", "Chapter 3 Analyzing word and document frequency", " Chapter 3 Analyzing word and document frequency A central question in text mining and natural language processing is how to quantify what a document is about. This chapter presents two approaches of measuring the “keywords” of a particular document amid other, tf-idf and weighted log odds ratio. library(patchwork) "],
["tf-idf.html", "3.1 tf-idf", " 3.1 tf-idf The logic of tf-idf is that the words containing the greatest information about a particular document are the words that appear many times in that document, but in relatively few others. Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common. It is widely used in document search and information retrieval tasks. 14 To the extent tf.idf reliably captures what is distinctive about a particular document, it could be interpreted as a feature evaluation technique. Let \\(w = 1, 2, ..., W\\) index words and \\(\\boldsymbol{y}\\) denots the W-vector of word counts in the corpus. Let \\(i \\in I\\) index documents in the corpus, let \\(\\boldsymbol{y^i}\\) denotes the W-vector of word counts of document \\(i\\)， \\(y_w^i\\) the count of word \\(w\\) in document \\(i\\), and \\(n^i\\) the total count of words in document \\(i\\). Term frequency (tf) of a word \\(w\\) in document \\(i\\) is defined as its proprotions \\[ f_{w}^{i} = \\frac{y_{w}^{i}}{n^{i}} \\] We can see that \\(\\text{tf}_{ij}\\) is essentially a scaling of term counts \\(n^{i}\\), so that the metric will not be biased against words in lengthy documents. .Inverse document frequency (idf) of word \\(w\\) in the corpus is defined as \\[ \\text{idf}_i = \\log{\\frac{|D|}{|{j:t_i \\in d_j}|}} \\] where \\(|D|\\) is the number of documents in the corpus, and \\(|{j:t_i \\in d_j}|\\) the number of documents containing word \\(i\\). We can let \\(df_w\\) denote the fraction of documents that contain word \\(w\\) at least once, then idf can be stated as \\[ \\text{idf}_i = \\log{\\frac{1}{df_{w}}} \\] and tf-idf, the production of term frequency and document frequency, as \\[ tf.idf_w^i = f_w^i \\log{\\frac{1}{df_{w}}} \\] 3.1.1 Term frequency in Jane Austen’s novels library(janeaustenr) book_words &lt;- austen_books() %&gt;% unnest_tokens(word, text) %&gt;% add_count(book, name = &quot;total_words&quot;) %&gt;% group_by(book, total_words) %&gt;% count(word, sort = TRUE) %&gt;% ungroup() book_words #&gt; # A tibble: 40,379 x 4 #&gt; book total_words word n #&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Mansfield Park 160460 the 6206 #&gt; 2 Mansfield Park 160460 to 5475 #&gt; 3 Mansfield Park 160460 and 5438 #&gt; 4 Emma 160996 to 5239 #&gt; 5 Emma 160996 the 5201 #&gt; 6 Emma 160996 and 4896 #&gt; # ... with 4.037e+04 more rows There is one row in this book_words data frame for each word-book combination; n is the number of times that word is used in that book and total_words is the total words in that book. The usual suspects are here with the highest n, “the”, “and”, “to”, and so forth. let’s look at the distribution of n / total for each novel, which is the predefined term frequency: ggplot(book_words) + geom_histogram(aes(n / total_words, fill = book), show.legend = FALSE) + xlim(NA, 0.0009) + facet_wrap(~ book, nrow = 3, scales = &quot;free_y&quot;) Figure 3.1: Term Frequency Distribution in Jane Austen’s Novels 3.1.2 Zipf’s law In Figure 3.1 we see the characteristic long-tailed distribution of term frequency. In fact, those types of long-tailed distributions are so common in any given corpus of natural language (like a book, or a lot of text from a website, or spoken words) that the relationship between the frequency that a word is used and its rank has been the subject of study; a classic version of this relationship is called Zipf’s law, after George Zipf, a 20th century American linguist, which can be stated as. \\[ \\text{word rank} \\times \\text{term frequency} = c \\] where \\(c\\) is a constant. freq_by_rank &lt;- book_words %&gt;% group_by(book) %&gt;% mutate(rank = row_number(), `term frequency` = n / total_words) freq_by_rank #&gt; # A tibble: 40,379 x 6 #&gt; # Groups: book [6] #&gt; book total_words word n rank `term frequency` #&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Mansfield Park 160460 the 6206 1 0.0387 #&gt; 2 Mansfield Park 160460 to 5475 2 0.0341 #&gt; 3 Mansfield Park 160460 and 5438 3 0.0339 #&gt; 4 Emma 160996 to 5239 1 0.0325 #&gt; 5 Emma 160996 the 5201 2 0.0323 #&gt; 6 Emma 160996 and 4896 3 0.0304 #&gt; # ... with 4.037e+04 more rows Zipf’s law is often visualized by plotting rank on the x-axis and term frequency on the y-axis, on logarithmic scales. Plotting this way, an inversely proportional relationship will have a constant, negative slope. \\[ \\lg{(\\text{term frequency})} = - \\lg{(\\text{term frequency})} + \\lg{c} \\] freq_by_rank %&gt;% ggplot(aes(rank, `term frequency`, color = book)) + geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + scale_x_log10() + scale_y_log10() The slope is not quite constant, though; perhaps we could view this as a broken power law with, say, three sections. Let’s see what the exponent of the power law is for the middle section of the rank range. rank_subset &lt;- freq_by_rank %&gt;% filter(rank &lt; 500, rank &gt; 10) rank_subset %&gt;% lm(log10(`term frequency`) ~ log10(rank), data = .) %&gt;% summary() #&gt; #&gt; Call: #&gt; lm(formula = log10(`term frequency`) ~ log10(rank), data = .) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.11814 -0.01011 -0.00217 0.00928 0.08181 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) -0.622569 0.002218 -281 &lt;0.0000000000000002 *** #&gt; log10(rank) -1.112522 0.000953 -1168 &lt;0.0000000000000002 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.0184 on 2932 degrees of freedom #&gt; Multiple R-squared: 0.998, Adjusted R-squared: 0.998 #&gt; F-statistic: 1.36e+06 on 1 and 2932 DF, p-value: &lt;0.0000000000000002 The \\(R^2\\) is approximately \\(1\\), so that we consider the relationship between log word rank and log tf to be \\(\\lg{\\text{tf}} = -1.11\\lg{\\text{rank}} - 0. 62\\). freq_by_rank %&gt;% ggplot(aes(rank, `term frequency`, color = book)) + geom_abline(intercept = -0.62, slope = -1.1, color = &quot;gray50&quot;, linetype = 2) + geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + scale_x_log10() + scale_y_log10() We have found a result close to the classic version of Zipf’s law for the corpus of Jane Austen’s novels. The deviations we see here at high rank are not uncommon for many kinds of language; a corpus of language often contains fewer rare words than predicted by a single power law. The deviations at low rank are more unusual. Jane Austen uses a lower percentage of the most common words than many collections of language. This kind of analysis could be extended to compare authors, or to compare any other collections of text; it can be implemented simply using tidy data principles. 3.1.3 Word rank slope chart Emil Hvitfeldt had a great blog post on how to make a word rank slope chart. This plot is generally designed to visualize the word rank difference of a set of paired words. If a writer is more comfortable using masculine words, then we could expect that “he” has a lower word rank than “she” (words are ranked in an descending order based on counts, as in book_words). In Jane Austen’s novels, suppose we decide to compare word rank on a set of words related to gender gender_words &lt;- tribble( ~Men, ~Women, &quot;he&quot;, &quot;she&quot;, &quot;his&quot;, &quot;her&quot;, &quot;man&quot;, &quot;woman&quot;, &quot;men&quot;, &quot;women&quot;, &quot;boy&quot;, &quot;girl&quot;, &quot;himself&quot;, &quot;herself&quot; ) We unnest 6 books into separate words as usual, and pull() them out as a vector. ordered_words &lt;- austen_books() %&gt;% unnest_tokens(word, text) %&gt;% count(word, sort = TRUE) %&gt;% pull(word) We then use match() to match individual words to its word rank. The trick is using the logged rank rather the rank itself, otherwise the y scale will be heavily extended by large word rank. scale_y_log10() is not the best option in this case, since we need scale_y_reverse() to put the most frequent words on the top of our plot, and labels on the y axis can be fixed by passing a function to label gender_words &lt;- gender_words %&gt;% mutate(male_rank_log10 = match(Men, ordered_words) %&gt;% log10(), female_rank_log10 = match(Women, ordered_words) %&gt;% log10(), rank_diff_log10 = male_rank_log10 - female_rank_log10) %&gt;% pivot_longer(male_rank_log10:female_rank_log10, names_to = &quot;index&quot;, values_to = &quot;rank&quot;) %&gt;% mutate(label = if_else(index == &quot;male_rank_log10&quot;, Men, Women)) %&gt;% mutate(index = fct_recode(index, &quot;male&quot; = &quot;male_rank_log10&quot;, &quot;female&quot; = &quot;female_rank_log10&quot;)) limits &lt;- max(abs(gender_words$rank_diff_log10)) * c(-1, 1) library(ggrepel) gender_words %&gt;% ggplot(aes(index, rank, group = Men)) + geom_line(aes(color = rank_diff_log10), show.legend = FALSE) + geom_text_repel(aes(label = label)) + scale_y_reverse(label = function(x) 10 ^ x, breaks = scales::breaks_pretty(n = 3)) + scale_color_fermenter(type = &quot;div&quot;, palette = &quot;Spectral&quot;, limits = limits) + theme_minimal() 3.1.4 The bind_tf_idf() function The bind_tf_idf() function in the tidytext package takes a tidy text dataset as input with one row per token (term), per document. One column (word here) contains the terms/tokens, one column contains the documents (book in this case), and the last necessary column contains the counts, how many times each document contains each term (n in this example). book_words &lt;- book_words %&gt;% select(-total_words) %&gt;% bind_tf_idf(term = word, document = book, n = n) book_words #&gt; # A tibble: 40,379 x 6 #&gt; book word n tf idf tf_idf #&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Mansfield Park the 6206 0.0387 0 0 #&gt; 2 Mansfield Park to 5475 0.0341 0 0 #&gt; 3 Mansfield Park and 5438 0.0339 0 0 #&gt; 4 Emma to 5239 0.0325 0 0 #&gt; 5 Emma the 5201 0.0323 0 0 #&gt; 6 Emma and 4896 0.0304 0 0 #&gt; # ... with 4.037e+04 more rows Notice that idf and thus tf-idf are zero for these extremely common words. These are all words that appear in all six of Jane Austen’s novels, so the idf term (which will then be the natural log of \\(1\\)) is zero. Although it is often not necessary to remove stopwords when extracting tf-idf on the ground that stop words will generally have zero idf, it is good practice, in most cases, to focus on non-stop words only (I do not anti-join here because I want to compare the results on common words between tf-idf and weighted log odds ratio). There are circumstances under which which some stop words could have a meaning worth capturing, e.g., “her” in abortion debates), and tf-idf is not a good option in such cases, see 3.2. Let’s look at terms with high tf-idf in Jane Austen’s works. book_words %&gt;% arrange(desc(tf_idf)) #&gt; # A tibble: 40,379 x 6 #&gt; book word n tf idf tf_idf #&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Sense &amp; Sensibility elinor 623 0.00519 1.79 0.00931 #&gt; 2 Sense &amp; Sensibility marianne 492 0.00410 1.79 0.00735 #&gt; 3 Mansfield Park crawford 493 0.00307 1.79 0.00551 #&gt; 4 Pride &amp; Prejudice darcy 373 0.00305 1.79 0.00547 #&gt; 5 Persuasion elliot 254 0.00304 1.79 0.00544 #&gt; 6 Emma emma 786 0.00488 1.10 0.00536 #&gt; # ... with 4.037e+04 more rows Proper nouns are often favoured by tf-idf, in this case names of important characters in each novel will generally have high tf-idf value. None of them occur in all of novels, and they are important, characteristic words for each text within the corpus of Jane Austen’s novels. book_words %&gt;% group_by(book) %&gt;% top_n(15) %&gt;% ungroup() %&gt;% facet_bar(y = word, x = tf_idf, by = book, nrow = 3) "],
["weighted-log-odds-ratio.html", "3.2 Weighted log odds ratio", " 3.2 Weighted log odds ratio This section is heavily based on Monroe, Colaresi, and Quinn(2008) and a medium post, titled I dare say you will never use tf-idf again. 3.2.1 Log odds ratio First, the log odds of word \\(w\\) in document \\(i\\) is defined as \\[ \\log{O_{w}^i} = \\log{\\frac{f_w^i}{1 - f_w^i}} \\] Logging the odds ratio provides a measure that is symmetric when comparing the usage of word \\(w\\) across different documents. Log odds ratio of word \\(w\\) between document \\(i\\) and \\(j\\) is \\[ \\log{\\frac{O_{w}^i}{O_w^j}} = \\log{\\frac{f_w^i}{1 - f_w^i} / \\frac{f_w^j}{1 - f_w^j}} = \\log{\\frac{f_w^i}{1 - f_w^i}} - log{\\frac{f_w^j}{1 - f_w^j}} \\] A problem is that, when some word \\(w\\) is only presented in document \\(i\\), among other documents in the corpus, odds ratio will have zero denominator and the metric goes to infinity. One solution is to “add a little bit to the zeroes”, in which smoothed word frequency is defined as \\(\\tilde{f_w^i} = f_w^i + \\varepsilon\\). Note that regardless of the zero treatment, words with hightest log odds ratio are often obscure ones. The problem is again the failure to account for sampling variability. With logodds ratios, the sampling variation goes down with increased frequency. So that different words are not comparable. A common response to this is to set some frequency “threshold” for features to ‘‘qualify’’ for consideration. For example, we only compute log odds ratio on words that appears at least 10 times. 3.2.2 Model-based approach: Weighted log odds ratio Monroe, Colaresi, and Quinn then proposed a model-basded approach where the choice of word \\(w\\) are modelled as a function oof document \\(P(w |j)\\). In general, the strategy is to first model word usage in the full collection of documents and to then investigate how subgroup-specific word usage diverges from that in the full collection of documents. First, the moel assumes that the W-vector \\(\\boldsymbol{y}\\) follows a multinomial distribution \\[ \\boldsymbol{y} \\sim \\text{Multinomial}(n, \\boldsymbol{\\pi}) \\] where \\(n = \\sum_{w=1}^Wy_w\\) and \\(\\boldsymbol{\\pi}\\) is W-vector of possibilities. And the the baseline log odds ratio between word \\(w\\) and the first word is \\[ \\beta_w = \\log{\\pi_w} - \\log{\\pi_1} \\;\\;\\; w=1, 2, ..., W \\] BTW, this is essentially a baseline logit model including only an intercept, which is an extention of logistic regression for dealing with response with W categories. Therefore, the likelihood function can be expressed in terms of \\(\\beta_w\\) \\[ L(\\boldsymbol{\\beta} | \\boldsymbol{y}) = \\prod_{w=1}^{W}{(\\frac{\\exp(\\beta_w)}{\\sum_{w=1}^{W}\\exp(\\beta_w)})^{y_w}} \\] Within any document, \\(i\\), the model to this point goes through with addition of subscripts \\[ \\boldsymbol{y^i} \\sim \\text{Multinomial}(n^i, \\boldsymbol{\\pi^i}) \\] The lack of covariates results in an immediately available analytical solution for the MLE of \\({\\beta^i_w}\\) . We calculate \\[ \\boldsymbol{\\hat{\\pi}}^\\text{MLE} = \\boldsymbol{y} / n \\] where \\(n = \\sum_{w = 1}^{W}y_w\\)and \\(\\boldsymbol{\\hat{\\beta}}^\\text{MLE}\\) follows after transforming. The paper proceeds with a Bayesian model, specifying the prior using the conjugate for the multinomial distribution, the Dirichlet: \\[ \\boldsymbol{\\pi} \\sim \\text{Dirichlet}(\\boldsymbol{\\alpha}) \\] where \\(\\boldsymbol{\\alpha}\\) is a W-vector of parameters with each element \\(\\alpha_w &gt; 0\\). There is a nice interpretation of \\(\\alpha_w\\), that is, use of any particular Dirichlet prior defined by \\(\\boldsymbol{\\alpha}\\) affects the posterior exactly as if we had observed in the data an additional \\(\\alpha_w – 1\\) instances of word \\(w\\). It follows this is a uninformative prior if all \\(\\alpha_w\\)s are identitcal. Due to the conjugacy, the full Bayesian estimate using the Dirichlet prior is also analytically available in analogous form: \\[ \\boldsymbol{\\hat{\\pi}} = \\frac{(\\boldsymbol{y} + \\boldsymbol{\\alpha})}{n + \\alpha_0} \\] where \\(\\alpha_0 = \\sum_{w=1}^{W}\\alpha_w\\) Our job, therefore, is to compare if the usage of word \\(w\\) in document \\(i\\), \\(\\pi_w^i\\), differs from \\(\\pi_w\\) overall or in some other document \\(\\pi^j_w\\). One of the advantages of the model-based approach is that we can measure the uncertainty in odds. Denote the odds (now with probabilistic meaning) of word w, relative to all others, as \\(\\Omega_w = \\pi_w / (1- \\pi_w)\\). We are interested in how the usage of a word by document \\(i\\) differs from usage of the word in all documents, which we can capture with the log-odds-ratio, which we will now define as \\(\\delta_w^i = \\log{\\Omega_w^i / \\Omega_w}\\). To compare between documents \\(i\\) and \\(j\\), log odds ratio of word \\(w\\) is defined as \\(\\delta_w^{i-j} = \\log{\\Omega_w^i / \\Omega_w^j}\\). To scale these two estimators, their point estimate and estimated variance are found \\[ \\begin{aligned} \\hat{\\delta}_{w}^{i-j} &amp;= \\log(\\frac{y_w^i + \\alpha_w}{n^i + \\alpha_0 - (y_w^i + \\alpha_w)}) - \\log(\\frac{y_w^j + \\alpha_w}{n^j + \\alpha_0 - (y_w^j + \\alpha_w)}) \\\\ \\sigma^2(\\hat{\\delta}_{w}^{i-j}) &amp;\\approx \\frac{1}{y_w^i + a_w} + \\frac{1}{y_w^j + a_w} \\end{aligned} \\] The final standardized statistic for a word \\(w\\) is then the z–score of its log–odds–ratio: \\[ \\frac{\\hat{\\delta}_{w}^{i-j}}{\\sigma^2(\\hat{\\delta}_{w}^{i-j})} \\] The Monroe, et al method then uses counts from a background corpus to provide a prior count for words, rather than the uninformative Dirichlet prior, essentially shrinking the counts toward to the prior frequency in a large background corpus to prevent overfitting. The general notion is to put a strong conservative prior (regularization) on the model, requiring the data to speak very loudly if such a difference is to be declared. I am not going to dive into that. But it is important to know that \\(\\alpha_0 = 1\\) means no shrinkage, and \\(\\alpha_0 \\rightarrow 0\\) or \\(\\alpha_0 \\rightarrow \\infty\\) mean strongest shrinkage. 3.2.3 Discussions The Monroe, modifies the commonly used log–odds ratio (introduced in Section 3.2.1) in two ways (Jurafsky et al. 2014) : It uses the z–scores of the log–odds–ratio, which controls for the amount of variance in a word’s frequency. So the score on different words are comparable. And the metric also faciliates interpretation, positive log odds means stronger tendency to use the word, and negative ones indicate otherwise. Also, \\(|\\hat{\\delta}^i_w| &gt; 1.96\\) should mean some sort of significance. Secondly, it uses counts from a background corpus to provide a prior count for words, essentially shrinking the counts toward to the prior frequency in a large background corpus. These features enable differences even in very frequent words to be detected; previous linguistic methods have all had problems with frequent words. Because function words like pronouns and auxiliary verbs are both extremely frequent and have been shown to be important cues to social and narrative meaning, this is a major limitation of these methods. For example, as an English reader/speaker, you won’t be surprised that all the authors you are trying to compare use “of the” and “said the” in their respective documents, and we want to know who used much more than others. tf-idf will not be able to detect this, because the idf of words appearing in every document will always be zero. 3.2.4 bind_log_odds() There is an issue suggesting that tidylo is still experimental. However, it did provide a ussful function bind_log_odds() that implemented the weighted log odds we dicussed above, and it seems that it currently uses the marginal distributions (i.e., distribution of words across all documents combined) to construct an informative Dirichlet prior. The data structure bind_log_odds() requires is the same with bind_tf_idf() library(tidylo) book_words %&gt;% bind_log_odds(set = book, feature = word, n = n) %&gt;% arrange(desc(log_odds)) #&gt; # A tibble: 40,379 x 7 #&gt; book word n tf idf tf_idf log_odds #&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Emma emma 786 0.00488 1.10 0.00536 24.5 #&gt; 2 Mansfield Park fanny 816 0.00509 0.693 0.00352 24.1 #&gt; 3 Sense &amp; Sensibility elinor 623 0.00519 1.79 0.00931 23.4 #&gt; 4 Pride &amp; Prejudice elizabeth 597 0.00489 0.693 0.00339 21.0 #&gt; 5 Sense &amp; Sensibility marianne 492 0.00410 1.79 0.00735 20.8 #&gt; 6 Persuasion anne 447 0.00534 0.182 0.000974 20.6 #&gt; # ... with 4.037e+04 more rows Now let’s compare the result between tf-idf and weighted log odds in a subset of book_words words_tf_idf &lt;- book_words %&gt;% filter(book %in% c(&quot;Emma&quot;, &quot;Pride &amp; Prejudice&quot;, &quot;Persuasion&quot;)) %&gt;% bind_tf_idf(term = word, document = book, n = n) %&gt;% group_by(book) %&gt;% top_n(10) %&gt;% ungroup() %&gt;% facet_bar(y = word, x = tf_idf, by = book, ncol = 3) + labs(title = &quot;Top 10 words picked tf-idf&quot;) words_wlo &lt;- book_words %&gt;% filter(book %in% c(&quot;Emma&quot;, &quot;Pride &amp; Prejudice&quot;, &quot;Persuasion&quot;)) %&gt;% bind_log_odds(feature = word, set = book, n = n) %&gt;% group_by(book) %&gt;% top_n(10) %&gt;% ungroup() %&gt;% facet_bar(y = word, x = log_odds, by = book, ncol = 3) + labs(title = &quot;Top 10 words picked by weighted log odds&quot;) words_tf_idf / words_wlo "],
["a-corpus-of-physics-texts.html", "3.3 A corpus of physics texts", " 3.3 A corpus of physics texts Let’s work with another corpus of documents, to see what terms are important in a different set of works. library(gutenbergr) physics &lt;- gutenberg_download(c(37729, 14725, 13476, 30155), meta_fields = &quot;author&quot;) physics #&gt; # A tibble: 15,410 x 3 #&gt; gutenberg_id text author #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 13476 &quot;EXPERIMENTS WITH ALTERNATE CURRENTS OF HIGH POTENTIA~ Tesla, Ni~ #&gt; 2 13476 &quot;&quot; Tesla, Ni~ #&gt; 3 13476 &quot;A Lecture Delivered before the Institution of Electr~ Tesla, Ni~ #&gt; 4 13476 &quot;&quot; Tesla, Ni~ #&gt; 5 13476 &quot;by&quot; Tesla, Ni~ #&gt; 6 13476 &quot;&quot; Tesla, Ni~ #&gt; # ... with 1.54e+04 more rows Count words as usual physics_words &lt;- physics %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% count(author, word, sort = TRUE) physics_words #&gt; # A tibble: 10,913 x 3 #&gt; author word n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Galilei, Galileo water 828 #&gt; 2 Galilei, Galileo gravity 240 #&gt; 3 Huygens, Christiaan refraction 218 #&gt; 4 Galilei, Galileo air 211 #&gt; 5 Galilei, Galileo mass 208 #&gt; 6 Huygens, Christiaan light 201 #&gt; # ... with 1.091e+04 more rows Visualize the highest log odds words (log odds is particularly useful in comparing wrting styles) plot_physics &lt;- physics_words %&gt;% bind_log_odds(word, author, n) %&gt;% mutate(word = fct_reorder(word, log_odds)) %&gt;% mutate(author = factor(author, levels = c(&quot;Galilei, Galileo&quot;, &quot;Huygens, Christiaan&quot;, &quot;Tesla, Nikola&quot;, &quot;Einstein, Albert&quot;))) plot_physics %&gt;% group_by(author) %&gt;% top_n(15, log_odds) %&gt;% ungroup() %&gt;% facet_bar(y = word, x = log_odds, by = author) Why there is _k and _x in Einstein’s text ? physics %&gt;% filter(author == &quot;Einstein, Albert&quot;, str_detect(text, &quot;_[kx]_?&quot;)) %&gt;% select(text) #&gt; # A tibble: 97 x 1 #&gt; text #&gt; &lt;chr&gt; #&gt; 1 co-ordinates (_x, y, z_) which can be dropped from the scene of the #&gt; 2 space with respect to _K_ by the three perpendiculars _x, y, z_ on the #&gt; 3 time by corresponding values _x&#39;, y&#39;, z&#39;, t&#39;_, which of course are not #&gt; 4 identical with _x, y, z, t_. It has already been set forth in detail #&gt; 5 manner. What are the values _x&#39;, y&#39;, z&#39;, t&#39;_, of an event with respect #&gt; 6 to _K&#39;_, when the magnitudes _x, y, z, t_, of the same event with #&gt; # ... with 91 more rows Some cleaning up of the text may be in demand. Also notice that there are separate “co” and “ordinate” items in the high tf-idf words for the Einstein text; the unnest_tokens() function separates around punctuation like hyphens by default. Notice that the tf-idf scores for “co” and “ordinate” are close to same! “AB”, “RC”, and so forth are names of rays, circles, angles, and so forth for Huygens. physics %&gt;% filter(str_detect(text, &quot;RC&quot;)) %&gt;% select(text) #&gt; # A tibble: 44 x 1 #&gt; text #&gt; &lt;chr&gt; #&gt; 1 line RC, parallel and equal to AB, to be a portion of a wave of light, #&gt; 2 represents the partial wave coming from the point A, after the wave RC #&gt; 3 be the propagation of the wave RC which fell on AB, and would be the #&gt; 4 transparent body; seeing that the wave RC, having come to the aperture #&gt; 5 incident rays. Let there be such a ray RC falling upon the surface #&gt; 6 CK. Make CO perpendicular to RC, and across the angle KCO adjust OK, #&gt; # ... with 38 more rows my_stop_words &lt;- tibble(word = c(&quot;eq&quot;, &quot;co&quot;, &quot;rc&quot;, &quot;ac&quot;, &quot;ak&quot;, &quot;bn&quot;, &quot;fig&quot;, &quot;file&quot;, &quot;cg&quot;, &quot;cb&quot;, &quot;cm&quot;, &quot;ab&quot;, &quot;_k&quot;, &quot;_k_&quot;, &quot;k&quot;, &quot;_x&quot;)) physics_words &lt;- anti_join(physics_words, my_stop_words, by = &quot;word&quot;) plot_physics &lt;- physics_words %&gt;% bind_log_odds(word, author, n) %&gt;% mutate(word = str_remove_all(word, &quot;_&quot;)) %&gt;% group_by(author) %&gt;% top_n(15, log_odds) %&gt;% ungroup() %&gt;% mutate(author = factor(author, levels = c(&quot;Galilei, Galileo&quot;, &quot;Huygens, Christiaan&quot;, &quot;Tesla, Nikola&quot;, &quot;Einstein, Albert&quot;))) facet_bar(plot_physics, y = word, x = log_odds, by = author) "],
["relationships-between-words-n-grams-and-correlations.html", "Chapter 4 Relationships between words: n-grams and correlations ", " Chapter 4 Relationships between words: n-grams and correlations "],
["tokenizing-by-n-gram.html", "4.1 Tokenizing by n-gram", " 4.1 Tokenizing by n-gram unnest_tokens() have been used to tokenize the text by word, or sometimes by sentence, which is useful for the kinds of sentiment and frequency analyses. But we can also use the function to tokenize into consecutive sequences of words of length n, called n-grams. We do this by adding the token = \"ngrams\" option to unnest_tokens(), and setting n to the number of words we wish to capture in each n-gram. When we set nto 2, we are examining pairs of two consecutive words, often called “bigrams”: library(janeaustenr) austen_bigrams &lt;- austen_books() %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) austen_bigrams %&gt;% count(bigram, sort = TRUE) #&gt; # A tibble: 211,236 x 2 #&gt; bigram n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 of the 3017 #&gt; 2 to be 2787 #&gt; 3 in the 2368 #&gt; 4 it was 1781 #&gt; 5 i am 1545 #&gt; 6 she had 1472 #&gt; # ... with 2.112e+05 more rows 4.1.1 Filtering n-grams As one might expect, a lot of the most common bigrams are pairs of common (uninteresting) words, such as of the and to be: what we call “stop-words” (see Chapter 1). This is a useful time to use tidyr::separate(), which splits a column into multiple based on a delimiter. This lets us separate it into two columns, filter out stop words separately, and then combine the results. austen_separated &lt;- austen_bigrams %&gt;% separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) austen_united &lt;- austen_separated %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% unite(bigram, c(word1, word2), sep = &quot; &quot;) austen_united %&gt;% count(bigram, sort = TRUE) #&gt; # A tibble: 33,421 x 2 #&gt; bigram n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 sir thomas 287 #&gt; 2 miss crawford 215 #&gt; 3 captain wentworth 170 #&gt; 4 miss woodhouse 162 #&gt; 5 frank churchill 132 #&gt; 6 lady russell 118 #&gt; # ... with 3.342e+04 more rows austen_bigrams &lt;- austen_bigrams %&gt;% separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word) %&gt;% filter(!word2 %in% stop_words$word) %&gt;% unite(bigram, c(word1, word2), sep = &quot; &quot;) austen_bigrams #&gt; # A tibble: 44,784 x 2 #&gt; book bigram #&gt; &lt;fct&gt; &lt;chr&gt; #&gt; 1 Sense &amp; Sensibility jane austen #&gt; 2 Sense &amp; Sensibility austen 1811 #&gt; 3 Sense &amp; Sensibility 1811 chapter #&gt; 4 Sense &amp; Sensibility chapter 1 #&gt; 5 Sense &amp; Sensibility norland park #&gt; 6 Sense &amp; Sensibility surrounding acquaintance #&gt; # ... with 4.478e+04 more rows 4.1.2 Analyzing bigrams The result of separating bigrams is helpful for exploratory analyses of the text. As a simple example, we might be interested in the most common “streets” mentioned in each book: austen_bigrams %&gt;% separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(word2 == &quot;street&quot;) %&gt;% count(street = str_c(word1, word2, sep = &quot; &quot;), sort = TRUE) #&gt; # A tibble: 28 x 2 #&gt; street n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 berkeley street 16 #&gt; 2 harley street 16 #&gt; 3 milsom street 16 #&gt; 4 pulteney street 15 #&gt; 5 wimpole street 10 #&gt; 6 bond street 9 #&gt; # ... with 22 more rows A bigram can also be treated as a term in a document in the same way that we treated individual words. For example, we can look at the weighted log odds (Section 3.2) of bigrams across Austen novels. library(tidylo) austen_bigrams %&gt;% count(book, bigram, sort = TRUE) %&gt;% bind_log_odds(set = book, feature = bigram, n = n) %&gt;% group_by(book) %&gt;% top_n(15) %&gt;% ungroup() %&gt;% facet_bar(y = bigram, x = log_odds, by = book, nrow = 3) 4.1.3 Using bigrams to provide context in sentiment analysis Context matters in sentiment analysis. For example, the words “happy” and “like” will be counted as positive, even in a sentence like “I’m not happy and I don’t like it!” Now that we have the data organized into bigrams, it’s easy to tell how often words are preceded by a word like “not”: austen_separated %&gt;% filter(word1 == &quot;not&quot;) %&gt;% filter(!word2 %in% stop_words$word) %&gt;% count(word1, word2, sort = TRUE) #&gt; # A tibble: 988 x 3 #&gt; word1 word2 n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 not hear 39 #&gt; 2 not speak 35 #&gt; 3 not expect 34 #&gt; 4 not bear 33 #&gt; 5 not imagine 26 #&gt; 6 not understand 26 #&gt; # ... with 982 more rows Let’s use the AFINN lexicon for sentiment analysis, which you may recall gives a numeric sentiment value for each word, with positive or negative numbers indicating the direction of the sentiment. not_words &lt;- austen_separated %&gt;% filter(word1 == &quot;not&quot;) %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = c(word2 = &quot;word&quot;)) %&gt;% count(word1, word2, value, sort = TRUE) not_words #&gt; # A tibble: 245 x 4 #&gt; word1 word2 value n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 not like 2 99 #&gt; 2 not help 2 82 #&gt; 3 not want 1 45 #&gt; 4 not wish 1 39 #&gt; 5 not allow 1 36 #&gt; 6 not care 2 23 #&gt; # ... with 239 more rows It’s worth asking which words contributed the most in the “wrong” direction. To compute that, we can multiply their value by the number of times they appear (so that a word with a value of +3 occurring 10 times has as much impact as a word with a sentiment value of +1 occurring 30 times). We visualize the result with a bar plot not_words %&gt;% mutate(contribution = n * value, sign = if_else(value &gt; 0, &quot;postive&quot;, &quot;negative&quot;)) %&gt;% top_n(20, abs(contribution)) %&gt;% mutate(word2 = fct_reorder(word2, contribution)) %&gt;% ggplot(aes(y = word2, x = contribution, fill = sign)) + geom_col() + labs(y = &#39;Words preceded by \\&quot;not\\&quot;&#39;, x = &quot;Sentiment value * number of occurrences&quot;) The bigrams “not like” and “not help” were overwhelmingly the largest causes of misidentification, making the text seem much more positive than it is. But we can see phrases like “not afraid” and “not fail” sometimes suggest text is more negative than it is. “Not” isn’t the only term that provides some context for the following word. We could pick four common words not, no, never and without that negate the subsequent term, and use the same joining and counting approach to examine all of them at once. negation_words &lt;- c(&quot;not&quot;, &quot;no&quot;, &quot;never&quot;, &quot;without&quot;) negated_words &lt;- austen_separated %&gt;% filter(word1 %in% negation_words) %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = c(word2 = &quot;word&quot;)) %&gt;% count(word1, word2, value, sort = TRUE) negated_words %&gt;% mutate(contribution = n * value, sign = if_else(value &gt; 0, &quot;postive&quot;, &quot;negative&quot;)) %&gt;% group_by(word1) %&gt;% top_n(20, abs(contribution)) %&gt;% ungroup() %&gt;% ggplot(aes(y = reorder_within(word2, contribution, word1), x = contribution, fill = sign)) + geom_col() + scale_y_reordered() + facet_wrap(~ word1, scales = &quot;free&quot;) + labs(y = &#39;Words proceeded by a negation term&#39;, x = &quot;Sentiment value * number of occurrences&quot;, title = &quot;The most common positive or negative words to follow negations such as &#39;never&#39;, &#39;no&#39;, &#39;not&#39;, and &#39;without&#39;&quot;) 4.1.4 Visualizing a network of bigrams with ggraph library(tidygraph) library(ggraph) bigram_counts &lt;- austen_separated %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% count(word1, word2, sort = TRUE) bigram_graph &lt;- bigram_counts %&gt;% filter(n &gt; 20) %&gt;% as_tbl_graph() bigram_graph #&gt; # A tbl_graph: 91 nodes and 77 edges #&gt; # #&gt; # A directed acyclic simple graph with 17 components #&gt; # #&gt; # Node Data: 91 x 1 (active) #&gt; name #&gt; &lt;chr&gt; #&gt; 1 sir #&gt; 2 miss #&gt; 3 captain #&gt; 4 frank #&gt; 5 lady #&gt; 6 colonel #&gt; # ... with 85 more rows #&gt; # #&gt; # Edge Data: 77 x 3 #&gt; from to n #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 28 287 #&gt; 2 2 29 215 #&gt; 3 3 30 170 #&gt; # ... with 74 more rows Note how tidygraph handles network data, the main tbl_graph object splits a network into two data frames: Node data and Edge data ggraph(bigram_graph, layout = &quot;fr&quot;) + geom_edge_link() + geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1) We see that salutations such as “miss”, “lady”, “sir”, “and”colonel\" are common centers of nodes, which are often followed by names. We also see pairs or triplets along the outside that form common short phrases (“half hour”, “thousand pounds”, or “short time/pause”). Note that this is a visualization of a Markov chain, a common model in text processing, where the choice of a word only depends on its previous word. In this case, a random generator following this model might spit out “dear”, then “sir”, then “william/walter/thomas/thomas’s”, by following each word to the most common words that follow it. A polished graph: arrow &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;)) ggraph(bigram_graph, layout = &quot;fr&quot;) + geom_edge_link(aes(alpha = n), show.legend = F, arrow = arrow, end_cap = circle(0.07, &quot;inches&quot;)) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1) 4.1.5 Visualizing “friends” Here I deviate from the original text, where Julia and David analyzed King James Version of the Bible. However, I have collected the transcripts of the famous TV series, friends (season 1). Let’s start a simple analysis first by loading the data friends &lt;- read_csv(&quot;data/friends_season_1.csv&quot;) %&gt;% select(-type) glimpse(friends) #&gt; Observations: 5,974 #&gt; Variables: 6 #&gt; $ episode &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,... #&gt; $ person &lt;chr&gt; &quot;monica&quot;, &quot;joey&quot;, &quot;chandler&quot;, &quot;phoebe&quot;, &quot;phoebe&quot;, &quot;monica&quot;,... #&gt; $ line &lt;chr&gt; &quot;there&#39;s nothing to tell! he&#39;s just some guyi work with!&quot;, ... #&gt; $ id &lt;chr&gt; &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;01... #&gt; $ title &lt;chr&gt; &quot;The One Where Monica Gets a New Roomate (The Pilot-The Unc... #&gt; $ season &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;,... Retrieve a clean data frame with word counts (bigrams did not work very well) friends_bigram &lt;- friends %&gt;% unnest_tokens(word, line, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(word, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% filter(! (is.na(word1) | is.na(word2))) friends_count &lt;- friends_bigram %&gt;% count(word1, word2, sort = TRUE) friends_count #&gt; # A tibble: 5,466 x 3 #&gt; word1 word2 n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 hey hey 36 #&gt; 2 ow ow 29 #&gt; 3 la la 27 #&gt; 4 yeah yeah 27 #&gt; 5 wait wait 17 #&gt; 6 uh huh 16 #&gt; # ... with 5,460 more rows Draw a network friends_count %&gt;% filter(n &gt; 3) %&gt;% as_tbl_graph() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(alpha = n), show.legend = FALSE, arrow = arrow, end_cap = circle(0.07, &quot;inches&quot;)) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), size = 4, vjust = 1, hjust = 1) "],
["counting-and-correlating-pairs-of-words-with-widyr.html", "4.2 Counting and correlating pairs of words with widyr", " 4.2 Counting and correlating pairs of words with widyr Tokenizing by n-gram is a useful way to explore pairs of adjacent words. However, we may also be interested in words that tend to co-occur within particular documents or particular chapters, even if they don’t occur next to each other. For this reason, it is sometimes necessary to “cast” a tidy dataset into a wide matrix (such as a co-occurrence matrix), performs an operation such as a correlation on it, then re-tidies the result. This is when widyr comes to the rescue, the workflow is shown in the book: 4.2.1 Counting and correlating among sections We devide the book “Pride and Prejudice” into 10-line sections , as we did for Section 2.2 (80 lines). We may be interested in what words tend to appear within the same section. austen_section_words &lt;- austen_books() %&gt;% filter(book == &quot;Pride &amp; Prejudice&quot;) %&gt;% mutate(section = row_number() %/% 10) %&gt;% filter(section &gt; 0) %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) austen_section_words #&gt; # A tibble: 37,240 x 3 #&gt; book section word #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Pride &amp; Prejudice 1 truth #&gt; 2 Pride &amp; Prejudice 1 universally #&gt; 3 Pride &amp; Prejudice 1 acknowledged #&gt; 4 Pride &amp; Prejudice 1 single #&gt; 5 Pride &amp; Prejudice 1 possession #&gt; 6 Pride &amp; Prejudice 1 fortune #&gt; # ... with 3.723e+04 more rows widyr::pairwise_counts() counts the number of times each pair of items appear together within a group defined by “feature”. In this case, it counts the number of times each pair of words appear together within a section, note it still returns a tidy data frame, although the underlying computation took place in a matrix form : library(widyr) austen_section_words %&gt;% pairwise_count(word, section, sort = TRUE) #&gt; # A tibble: 796,008 x 3 #&gt; item1 item2 n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 darcy elizabeth 144 #&gt; 2 elizabeth darcy 144 #&gt; 3 miss elizabeth 110 #&gt; 4 elizabeth miss 110 #&gt; 5 elizabeth jane 106 #&gt; 6 jane elizabeth 106 #&gt; # ... with 7.96e+05 more rows We can easily find the words that most often occur with Darcy. Since pairwise_count records both the counts of (word_A, word_B) and (word_B, word_B), it does not matter we filter at item1 or item2 austen_section_words %&gt;% pairwise_count(word, section, sort = TRUE) %&gt;% filter(item1 == &quot;darcy&quot;) #&gt; # A tibble: 2,930 x 3 #&gt; item1 item2 n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 darcy elizabeth 144 #&gt; 2 darcy miss 92 #&gt; 3 darcy bingley 86 #&gt; 4 darcy jane 46 #&gt; 5 darcy bennet 45 #&gt; 6 darcy sister 45 #&gt; # ... with 2,924 more rows 4.2.2 Pairwise correlation Pairs like “Elizabeth” and “Darcy” are the most common co-occurring words, but that’s not particularly meaningful since they’re also the most common individual words. We may instead want to examine correlation among words, which indicates how often they appear together relative to how often they appear separately. In particular, we compute the \\(\\phi\\) coefficient. Introduced by Karl Pearson, this measure is similar to the Pearson correlation coefficient in its interpretation. In fact, a Pearson correlation coefficient estimated for two binary variables will return the \\(\\phi\\) coefficient. The phi coefficient is related to the chi-squared statistic for a 2 × 2 contingency table \\[ \\phi = \\sqrt{\\frac{\\chi^2}{n}} \\] where \\(n\\) denotes sample size. In the case of pairwise counts, \\(\\phi\\) is calculated by \\[ \\phi = \\frac{n_{11}n_{00} - n_{10}n_{01}}{\\sqrt{n_{1·}n_{0·}n_{·1}n_{·0}}} \\] We see, from the above quation, that \\(\\phi\\) is “standarized” by individual counts, so various word pair with different individual frequency can be compared to each other: The computation of \\(\\phi\\) can be simply done by pairwise_cor (other choice of correlation coefficients specified by method). The procedure can be somewhat computationally expensive, so we filter out uncommon words word_cors &lt;- austen_section_words %&gt;% add_count(word) %&gt;% filter(n &gt;= 20) %&gt;% select(-n) %&gt;% pairwise_cor(word, section, sort = TRUE) word_cors #&gt; # A tibble: 154,842 x 3 #&gt; item1 item2 correlation #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 bourgh de 0.951 #&gt; 2 de bourgh 0.951 #&gt; 3 pounds thousand 0.701 #&gt; 4 thousand pounds 0.701 #&gt; 5 william sir 0.664 #&gt; 6 sir william 0.664 #&gt; # ... with 1.548e+05 more rows Which word is most correlated with “lady”? word_cors %&gt;% filter(item1 == &quot;lady&quot;) #&gt; # A tibble: 393 x 3 #&gt; item1 item2 correlation #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 lady catherine 0.663 #&gt; 2 lady de 0.283 #&gt; 3 lady bourgh 0.254 #&gt; 4 lady ladyship 0.227 #&gt; 5 lady lucas 0.198 #&gt; 6 lady collins 0.176 #&gt; # ... with 387 more rows This lets us pick particular interesting words and find the other words most associated with them word_cors %&gt;% filter(item1 %in% c(&quot;elizabeth&quot;, &quot;pounds&quot;, &quot;married&quot;, &quot;pride&quot;)) %&gt;% group_by(item1) %&gt;% top_n(6) %&gt;% ungroup() %&gt;% facet_bar(y = item2, x = correlation, by = item1) How about a network visualization to see the overall correlation pattern? word_cors %&gt;% filter(correlation &gt; .15) %&gt;% as_tbl_graph() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), repel = TRUE) Note that unlike the bigram analysis, the relationships here are symmetrical, rather than directional (there are no arrows). We can also see that while pairings of names and titles that dominated bigram pairings are common, such as “colonel/fitzwilliam”, we can also see pairings of words that appear close to each other, such as “walk” and “park”, or “dance” and “ball”. "],
["converting-to-and-from-non-tidy-formats.html", "Chapter 5 Converting to and from non-tidy formats", " Chapter 5 Converting to and from non-tidy formats Non-tidy data structures, in particular matrcies, is essential in topic modeling where other packages for NLP in R play a major role. The book has a diagram describing the “glue” part functions in this chapter play: As shown in the figure, a tidied DTM is typically equivalent with a one-token-per-row data frame after counting. "],
["tidying-a-document-term-matrix.html", "5.1 Tidying a document-term matrix", " 5.1 Tidying a document-term matrix A document-term matrix or term-document matrix is a mathematical matrix that describes the frequency of terms that occur in a collection of documents. This is a matrix where each row represents one document each column represents one term (word) each value (typically) contains the number of appearances of that term in that document Document-term matrices are often stored as a sparse matrix object. These objects can be treated as though they were matrices (for example, accessing particular rows and columns), but are stored in a more efficient format. tidytext provides ways of converting between these two formats: tidy() turns a document-term matrix into a tidy data frame (one-token-per-row) cast() turns a tidy data frame into a matrix.There are three variations of this verb corresponding to different classes of matricies : cast_sparse() (converting to a sparse matrix from the Matrix package), cast_dtm() (converting to a DocumentTermMatrix object from tm), and cast_dfm() (converting to a dfm object from quanteda) DocumentTermMatrix class is built into the tm package. Notice that this DTM is 99% sparse (99% of document-word pairs are zero). library(tm) library(topicmodels) data(&quot;AssociatedPress&quot;, package = &quot;topicmodels&quot;) AssociatedPress #&gt; &lt;&lt;DocumentTermMatrix (documents: 2246, terms: 10473)&gt;&gt; #&gt; Non-/sparse entries: 302031/23220327 #&gt; Sparsity : 99% #&gt; Maximal term length: 18 #&gt; Weighting : term frequency (tf) Terms() is a accessor function to extract the full distinct word vector Terms(AssociatedPress) %&gt;% head() #&gt; [1] &quot;aaron&quot; &quot;abandon&quot; &quot;abandoned&quot; &quot;abandoning&quot; &quot;abbott&quot; #&gt; [6] &quot;abboud&quot; tidy it to get a tidy data frame # convert to tidy data frames with counts ap_tidy &lt;- tidy(AssociatedPress) ap_tidy #&gt; # A tibble: 302,031 x 3 #&gt; document term count #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 adding 1 #&gt; 2 1 adult 2 #&gt; 3 1 ago 1 #&gt; 4 1 alcohol 1 #&gt; 5 1 allegedly 1 #&gt; 6 1 allen 1 #&gt; # ... with 3.02e+05 more rows quanteda uses dfm (document-feauture matrix) as a common data structure for text data. For example, the quanteda package comes with a corpus of presidential inauguration speeches, which can be converted to a dfm using the appropriate function. data(&quot;data_corpus_inaugural&quot;, package = &quot;quanteda&quot;) quanteda::dfm(data_corpus_inaugural) #&gt; Document-feature matrix of: 58 documents, 9,360 features (91.8% sparse) and 4 docvars. #&gt; features #&gt; docs fellow-citizens of the senate and house representatives : #&gt; 1789-Washington 1 71 116 1 48 2 2 1 #&gt; 1793-Washington 0 11 13 0 2 0 0 1 #&gt; 1797-Adams 3 140 163 1 130 0 2 0 #&gt; 1801-Jefferson 2 104 130 0 81 0 0 1 #&gt; 1805-Jefferson 0 101 143 0 93 0 0 0 #&gt; 1809-Madison 1 69 104 0 43 0 0 0 #&gt; features #&gt; docs among vicissitudes #&gt; 1789-Washington 1 1 #&gt; 1793-Washington 0 0 #&gt; 1797-Adams 4 0 #&gt; 1801-Jefferson 1 0 #&gt; 1805-Jefferson 7 0 #&gt; 1809-Madison 0 0 #&gt; [ reached max_ndoc ... 52 more documents, reached max_nfeat ... 9,350 more features ] We, of course, want to tidy it inaugural &lt;- quanteda::dfm(data_corpus_inaugural) %&gt;% tidy() inaugural #&gt; # A tibble: 44,710 x 3 #&gt; document term count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1789-Washington fellow-citizens 1 #&gt; 2 1797-Adams fellow-citizens 3 #&gt; 3 1801-Jefferson fellow-citizens 2 #&gt; 4 1809-Madison fellow-citizens 1 #&gt; 5 1813-Madison fellow-citizens 1 #&gt; 6 1817-Monroe fellow-citizens 5 #&gt; # ... with 4.47e+04 more rows Suppose we would like to see how the usage of some user specified words change over time. We start by complete() the data frame, and then total words per speech: year_term_counts &lt;- inaugural %&gt;% extract(document, into = &quot;year&quot;, regex = &quot;(\\\\d{4})&quot;, convert = TRUE) %&gt;% complete(year, term, fill = list(count = 0)) %&gt;% add_count(year, wt = count, name = &quot;year_total&quot;) year_term_counts #&gt; # A tibble: 542,880 x 4 #&gt; year term count year_total #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1789 &quot;&#39;&quot; 0 1537 #&gt; 2 1789 &quot;-&quot; 1 1537 #&gt; 3 1789 &quot;!&quot; 0 1537 #&gt; 4 1789 &quot;\\&quot;&quot; 2 1537 #&gt; 5 1789 &quot;$&quot; 0 1537 #&gt; 6 1789 &quot;(&quot; 1 1537 #&gt; # ... with 5.429e+05 more rows year_term_counts %&gt;% filter(term %in% c(&quot;god&quot;, &quot;america&quot;, &quot;foreign&quot;, &quot;union&quot;, &quot;constitution&quot;, &quot;freedom&quot;)) %&gt;% ggplot(aes(year, count / year_total)) + geom_point() + geom_smooth() + facet_wrap(~ term, scales = &quot;free_y&quot;) + scale_y_continuous(labels = scales::percent_format()) + labs(title = &quot;% frequency of word in inaugural address&quot;) "],
["casting-tidy-text-data-into-a-matrix.html", "5.2 Casting tidy text data into a matrix", " 5.2 Casting tidy text data into a matrix csat_ verbs convert a tidy data frame (counted) into a document-term matrix ap_tidy %&gt;% cast_dtm(document = document, term = term, value = count) #&gt; &lt;&lt;DocumentTermMatrix (documents: 2246, terms: 10473)&gt;&gt; #&gt; Non-/sparse entries: 302031/23220327 #&gt; Sparsity : 99% #&gt; Maximal term length: 18 #&gt; Weighting : term frequency (tf) Similarly, we could cast ap_tidy into a dfm object from quanteda’s docuemnt term matrix with cast_dfm() ap_tidy %&gt;% cast_dfm(document = document, term = term, value = count) #&gt; Document-feature matrix of: 2,246 documents, 10,473 features (98.7% sparse). #&gt; features #&gt; docs adding adult ago alcohol allegedly allen apparently appeared arrested #&gt; 1 1 2 1 1 1 1 2 1 1 #&gt; 2 0 0 0 0 0 0 0 1 0 #&gt; 3 0 0 1 0 0 0 0 1 0 #&gt; 4 0 0 3 0 0 0 0 0 0 #&gt; 5 0 0 0 0 0 0 0 0 0 #&gt; 6 0 0 2 0 0 0 0 0 0 #&gt; features #&gt; docs assault #&gt; 1 1 #&gt; 2 0 #&gt; 3 0 #&gt; 4 0 #&gt; 5 0 #&gt; 6 0 #&gt; [ reached max_ndoc ... 2,240 more documents, reached max_nfeat ... 10,463 more features ] cast_sparse returns a sparse matrix ap_tidy %&gt;% cast_sparse(row = document, column = term, value = count) #&gt; 2246 x 10473 sparse Matrix of class &quot;dgCMatrix&quot; #&gt; #&gt; 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 4 4 1 1 1 1 1 1 1 2 1 1 4 1 ...... #&gt; 2 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 3 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 4 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 6 . . 2 . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 13 . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 15 . . 2 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 16 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 18 . . . . . . 1 1 . . . . . . 2 . . . . . . . . . . . . . . . . 1 ...... #&gt; 19 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 20 . . 2 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 21 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 22 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 23 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 24 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 25 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 26 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 27 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 28 . . 1 . 1 . . . 2 . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 29 . . 1 . . . 1 . . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 30 . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 31 . . 1 . . . . . . . . . . . 1 . . . . 1 . . . . 1 . . . . . . . ...... #&gt; 32 . . . . . . . . . . . . . . 2 . 2 . . . 1 . . . . . . . . . . . ...... #&gt; 33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 34 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 35 1 . . . . . 1 . . . . . 2 . 1 . . 2 . . . . . . . . 1 . . . . . ...... #&gt; 36 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 37 . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 38 . . 1 . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . . . ...... #&gt; 39 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 40 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 41 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 42 . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . ...... #&gt; 43 . . 3 . . . . . . 3 . 2 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 44 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 45 . . . . . . 1 1 . . . . . . . . . . . . 1 . . . . . . . . . . 1 ...... #&gt; 46 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 47 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 48 . 4 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 49 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 50 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 51 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 52 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 53 . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . . . . . ...... #&gt; 54 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 55 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 56 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 57 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 58 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 59 . . . . . 1 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 60 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 61 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 62 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 63 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 3 . . . . . ...... #&gt; 64 . . . . . . . 1 . . . . . . . . 1 1 . . . . . . . . . . . . . . ...... #&gt; 65 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 66 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 67 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 68 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 69 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 70 . . . . . . . . 2 . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 71 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 72 1 . . . . 1 . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . ...... #&gt; 73 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 74 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 75 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 ...... #&gt; 76 . . 1 . 1 . . . . . . . . . 6 . . . . . . . . . . . . . . . . . ...... #&gt; 77 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 78 . . . . . . . . . . . . . . . . . . . . . . . 2 . 1 . . . . . . ...... #&gt; 79 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 80 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . 1 . . ...... #&gt; 81 . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . 9 . . . ...... #&gt; 82 . . . . . . . . . . . . . . . . . . . . . . . 1 2 . . . . . . . ...... #&gt; 83 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 84 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 85 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 86 . . . . . . . . . . . . . . . . . . . . . . . 1 2 . 1 . 1 . . . ...... #&gt; 87 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 88 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 89 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 90 . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . 1 . . ...... #&gt; 91 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 92 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 93 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 94 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 95 . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 96 . . . . . . . . 1 1 . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 97 . . 1 . 1 . . . . . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 98 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 99 . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 100 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 101 1 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . 4 . . 1 . . ...... #&gt; 102 . . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 103 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 104 . . . . . . 1 . 1 . . . 4 . . . . . . . 1 . 1 2 . . . . . . . . ...... #&gt; 105 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 106 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 107 . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . . . ...... #&gt; 108 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 109 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 110 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 111 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 112 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 113 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 114 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 115 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 116 . . . . . . . . . . . . . . . . . . . . . . . . . . 5 . . . . 1 ...... #&gt; 117 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 118 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 119 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 120 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 121 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 122 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 123 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 124 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 125 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 126 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 127 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 128 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 129 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 130 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 131 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 132 . . . . . . . . . . . . 1 . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 133 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 134 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 135 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 136 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 137 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 138 . . . . . . 1 . . . . 1 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 139 . . 2 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 140 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 141 . . . . 1 . . . 1 . . . 1 . . . . . . . . . . . 1 . 1 1 . . . . ...... #&gt; 142 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 143 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 144 . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 145 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 146 . . . . . . . . 1 . . . 1 . . . . . . . . . . . 1 . 2 . . . . 1 ...... #&gt; 147 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 148 . . . . . . . . . . . . 1 . . . . . 1 . . 1 . . . . 1 . . . . . ...... #&gt; 149 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 150 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 151 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 152 . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 153 . . . . . . . . 1 . . . . . . . . . 5 . . . . . 3 . . . . . . . ...... #&gt; 154 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 155 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 156 . . . . . . 1 . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 157 . . . . . . . . 1 . . . . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 158 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 159 . . . . 1 . . . 5 . . . . . . . . . . . . . . . . . 5 . . . . . ...... #&gt; 160 . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 161 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 162 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 163 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 164 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 165 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 166 . . . . . . . . . . . . 1 . . . . 1 . . . . . . . . . . 1 . . . ...... #&gt; 167 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 168 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 169 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 170 . . 1 . . . . 1 . . . . 3 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 171 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 172 . . 1 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 173 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 174 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 175 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 176 . . . . . . . . . . . . . . . . . . . . . 2 . . . . 1 . . . . . ...... #&gt; 177 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 178 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 179 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 180 . . . . . . . . 5 . . . . . . . . . . . 1 . . . 1 . 2 . . . . . ...... #&gt; 181 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 182 . . . 1 1 . . . 2 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 183 . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 184 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 185 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 186 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 187 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 188 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 189 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 190 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 191 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 192 . . . . . . . . . . . . . . 1 . 1 . . . 1 . . . . . . . . . . . ...... #&gt; 193 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 194 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 195 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . 1 . . . . ...... #&gt; 196 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 197 . . . . 1 . . . 1 . . . . . 1 . . . . . . . . . 2 . . . . . . . ...... #&gt; 198 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 199 . . . . . . . 1 . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 200 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 201 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 202 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 203 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 204 . . 1 . . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . ...... #&gt; 205 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 206 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 207 . . . . . . . . . . . . . . . . . 1 . . 1 . . . . . . . . . . 1 ...... #&gt; 208 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 209 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 210 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . ...... #&gt; 211 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 212 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 213 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 214 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 215 . . 1 . . . . . 1 . . . 1 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 216 . . 1 . . . . . 1 . . . 1 . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 217 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 218 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 219 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 220 . . . . 1 . . . . . . . . . . . . . . . . . . 2 . . . . . . . . ...... #&gt; 221 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 222 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 223 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 224 . . . . . . . 2 . . . . . . . . . 2 . . 1 . . . . . . . . . . 1 ...... #&gt; 225 . . . . . . . . 2 . . 2 1 . . . . . . . . . . . 4 1 . . . . . . ...... #&gt; 226 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 227 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 228 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 229 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 230 . . 2 . . . . . . . . . . . 1 . 1 . . . 3 . . . . . . . . 1 . 2 ...... #&gt; 231 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 232 . . . . . . . . . . . . . . . . 1 . . . . . . 1 . . . . . . . . ...... #&gt; 233 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 234 . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 235 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 236 . . 1 . . . 1 . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 237 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 238 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 239 . . . . . . 1 . . . . . . . . . . . 1 4 . . . . . . . . . . . 2 ...... #&gt; 240 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 241 . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 242 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 243 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 244 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 245 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 246 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 247 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 248 . . . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . 1 ...... #&gt; 249 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 250 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 251 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 252 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 253 . . . . 1 . . . 3 . . . 4 . . . . . . . . . . 2 . . . . . . . . ...... #&gt; 254 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 255 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 256 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 257 . . . . . . . . . . . . . . . . . . 2 1 . . . . . . . . . . . . ...... #&gt; 258 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 259 . . 1 . . . . 2 . . . . . . . . . . 2 . . . . . . . . . 1 . . . ...... #&gt; 260 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 261 . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 262 . . 1 . . . . . . . . . . 1 . . . . 1 . 1 . . . . . . . . . . . ...... #&gt; 263 . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 264 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 265 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 266 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 267 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 268 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 269 . . . . . . . . . . 1 . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 270 . . . . . . . . . . . . 1 . . . . 1 . . . . . . . . 2 . . . . . ...... #&gt; 271 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 272 . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 273 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 274 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 275 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 276 . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . ...... #&gt; 277 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 278 . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 279 . . . . . . . . . 1 . . 1 . . . . . . . . . . 2 1 . . . . . . . ...... #&gt; 280 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 281 . . . . . . . . . . . . 1 . . . . . 3 1 . . . . . . . . . . . . ...... #&gt; 282 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 283 . . . . . . . . 3 . . 1 4 . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 284 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 285 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 286 . . 1 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 287 . . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 288 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 289 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 290 . . . . . . 1 . 1 . . . 1 . . . . 2 . . . . . 1 2 . 5 . . . . . ...... #&gt; 291 . . . . . . . 1 . . . . . . . . . 1 . . 1 1 . . . 1 1 . . . . . ...... #&gt; 292 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 293 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 294 . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 295 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 296 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 297 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 298 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 299 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 300 . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . . . . . ...... #&gt; 301 . . . 1 . . . . . . . . . . . . 1 . . . . 1 . 2 . . . . . . . . ...... #&gt; 302 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 303 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 304 1 . . . . . . . . . . . . . . . . 3 . . . . . . . . 2 . . . . . ...... #&gt; 305 . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 306 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 307 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 308 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 309 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 310 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 311 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 ...... #&gt; 312 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 313 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 314 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 315 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 316 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 317 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 318 . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 319 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 320 . . . . . . . . . . . . 1 . 2 . . . . . . . . . . . 1 . . . . . ...... #&gt; 321 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 322 . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . . . ...... #&gt; 323 1 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 324 . . . . . . . . . . . . . . . . . . . . 4 . . . . . . . . . . . ...... #&gt; 325 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 326 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 327 . . . . . . . . . . 1 . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 328 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 329 . . 1 . . . . . . . . . 1 . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 330 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 331 . . 1 . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 332 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 333 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 334 . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . 1 1 . . . . ...... #&gt; 335 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 336 . . . . . . . 1 . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 337 . . 2 . . . . . . . . . 1 . . . . . . 1 1 . . . . . 2 . . . . . ...... #&gt; 338 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 339 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 340 . . . . . . . . . 1 . . . . . . . . . . 2 . . . 1 . 1 1 . . . . ...... #&gt; 341 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 342 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 343 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 344 . . . . . . . . 3 . . . 1 . . . . . . . . 1 . 1 3 . . . . . . . ...... #&gt; 345 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 346 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 347 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 348 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 349 . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . ...... #&gt; 350 . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 351 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 352 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 353 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 354 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 355 . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 356 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . 1 1 . ...... #&gt; 357 . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 358 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 359 . . . . . . 1 . . . . . . . . . . . 1 3 . . . . . . . . . . . . ...... #&gt; 360 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 361 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 362 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 363 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 364 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 365 . . . . . . . . 2 . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 366 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 367 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 368 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 369 . . 1 . . . 1 . . . . . . . . . 2 . . . . . 1 . . . . . . . . . ...... #&gt; 370 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 371 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 372 . . 1 . . . . . . . . . 2 . . . . . . . . . 1 . 2 . . . . . . . ...... #&gt; 373 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 374 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 375 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 376 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 377 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 378 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 379 . . . . . . . . . 2 . 1 . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 380 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 381 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 382 . . 1 . . . . . . . 1 . . . 1 . . . . . . . . . 3 . 1 . . . . . ...... #&gt; 383 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 384 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 385 . . . . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . ...... #&gt; 386 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 387 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 388 . . . . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 389 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 390 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 391 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 392 . . . . . . 1 1 . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 393 . . . . . . . 1 . . . . 2 . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 394 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 395 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 396 . . 1 . . . . . . 2 . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 397 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 398 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 399 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 400 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 401 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 402 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 403 . . . . 1 . . . . . . . . . . . . . . 2 . . . 1 1 . . . . . . . ...... #&gt; 404 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 405 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 406 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 407 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . ...... #&gt; 408 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 409 . . . . . 2 . . . . . . . . . . . . . 4 . . . . . . 1 . . . . . ...... #&gt; 410 . . . 1 . . . 1 . 1 . . . . . . . . . . . 2 . . 3 1 1 . . . . . ...... #&gt; 411 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 412 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 413 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 414 . . . . 1 . . . . . . . . . . . . . . . . . . 3 . . . . . . . . ...... #&gt; 415 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 416 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . 2 1 . . . ...... #&gt; 417 . . 1 . . 1 . . . . . . . . 2 . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 418 . . . . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 419 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 420 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 421 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 422 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 423 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 424 . . . . . . . . . . . . 1 . . . . . . . . . . . 1 1 . . . . . . ...... #&gt; 425 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 426 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 427 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 428 . . . . . . . . . . . . . . . . . . . . . . 1 2 . . . . . . . . ...... #&gt; 429 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 430 . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . ...... #&gt; 431 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 432 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 433 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 434 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 435 . . . . 1 . . . . . . . . . . . . . . . 2 . 1 . 2 . 1 . . . . . ...... #&gt; 436 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 437 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 438 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 7 . ...... #&gt; 439 . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 440 . . 1 . . . . . . . 1 . . . . . 1 . . . . . . . . . 2 . . . . . ...... #&gt; 441 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 442 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 443 . . . . . . . . 1 5 . . 2 . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 444 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 445 . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 446 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 447 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 448 1 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 449 . . . . . . . 1 . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 450 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 451 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 452 . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 453 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 454 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 455 . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 456 . . . 3 . . . 1 . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 457 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 458 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 459 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 460 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 461 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 462 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 463 . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 464 . . 2 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 465 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 466 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 467 . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . . . . . ...... #&gt; 468 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 469 . . . . . . . . . . . . . . . . 3 . . . . . . . 1 . 1 . . . . . ...... #&gt; 470 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 471 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . 6 . . . ...... #&gt; 472 . . . . . . . . . . . . 2 . 1 . . . . . . . . . . . . . . . . 1 ...... #&gt; 473 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 474 . . 1 . . . . . . . . 1 . . 1 . . . . . . . . . 1 . 2 1 . . . . ...... #&gt; 475 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 476 . . . . . . . . . . 2 . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 477 . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 478 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 479 . . . . . . . 1 . . . . 1 . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 480 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 481 . . 1 . . . . 1 . . . . . . 1 . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 482 . . . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 483 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 484 . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 485 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 486 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 487 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 488 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 489 . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 490 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . ...... #&gt; 491 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 492 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 493 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 494 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 495 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 496 . . 4 . . . . . . . . . . . . . . 1 . . 1 . . . . . . . . . . . ...... #&gt; 497 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . ...... #&gt; 498 . . . . . . . . . . . . . . 1 . . . . . . . . . 2 . 2 . . . . . ...... #&gt; 499 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 500 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 501 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 502 . . 1 . . . . 1 . . . . 2 . . . . . . . . . . . 4 . 1 . . . . . ...... #&gt; 503 . . . . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 504 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 505 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 506 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 507 . . 1 . . . 1 . 1 . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 508 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 509 . . . . . . 1 . . . . . 1 . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 510 . . . . . . 1 . . . . . 2 . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 511 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 512 . . . . . . . . . 1 . . . . . . . . . . . . 1 3 5 . . 1 . . . . ...... #&gt; 513 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 514 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 515 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 516 1 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 517 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 518 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 519 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 520 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 521 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 522 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . 2 . . . ...... #&gt; 523 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 524 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 525 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . ...... #&gt; 526 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 527 . . 1 . . . 2 . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 528 . . . . . . 1 . . . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 529 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 530 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 531 . . . . . . . . . . . . . . 1 . . . . . . . . . 2 . . . . . . . ...... #&gt; 532 . . . . . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . ...... #&gt; 533 . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 534 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 535 . . . . . . . . . . . 1 . . . . . . . . . . 2 2 . . 1 . . . . . ...... #&gt; 536 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 537 . . 1 . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 538 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 539 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 540 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 541 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 542 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . 2 . . . ...... #&gt; 543 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 544 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 545 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 546 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 547 . . . . . . . . . . . . 1 . . . . . . . 1 . . . 1 . . . . . . . ...... #&gt; 548 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 549 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 550 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 551 . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 552 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 553 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 554 . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 . . . . ...... #&gt; 555 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 556 . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 557 . . 1 . . . . . 1 3 . 1 1 . . . . . . . . . . 1 2 . . . . . . . ...... #&gt; 558 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 559 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 560 . . . . . . . 1 1 . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 561 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 562 . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 563 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 564 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 565 . . . . . . 1 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 566 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 567 . . . . 1 . 1 . . . . . 2 . 1 . . . . . . . 2 1 . . 1 . . . . . ...... #&gt; 568 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 569 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 570 . . . . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . 2 . . ...... #&gt; 571 . . . . 1 . . . 1 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 572 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 573 . . . . . . 1 . 2 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 574 . . 1 . . . . . 1 . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 575 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . 1 ...... #&gt; 576 . . 1 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 577 . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 578 . . . . . . 1 . . . . 2 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 579 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 580 . . . . 1 . . . . . . . 1 . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 581 . . . 2 . . . . . . . . . . . . . 2 1 . . . . . . . 1 . . . . . ...... #&gt; 582 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 583 . . 1 . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 584 . . . . . . . . . . . . 1 1 . . . . . 1 . . . . . 1 . 2 10 . . . ...... #&gt; 585 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 586 . . . . . . . . 1 . . . . . . . . 3 . . . . . . . . . . . 1 . . ...... #&gt; 587 . . . . . . 1 . . . . . 1 . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 588 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 589 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 590 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 591 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 592 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 593 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 594 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 595 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 596 . . . 1 . . . . 1 . . . 2 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 597 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . 4 . . . ...... #&gt; 598 . . . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 599 . . . . . . . . . . . . . . . . 1 1 . . . . . . . . . . . . . . ...... #&gt; 600 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 601 . . . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . . . . . ...... #&gt; 602 . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 603 . . . . . . . . 1 . . . 2 . . . . . . . . . . 1 . . 1 . . . . . ...... #&gt; 604 . . 1 . . . . . . . . . . . 1 . 3 . . . . . . . . . . . . . . . ...... #&gt; 605 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 606 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 607 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 608 . . . . . . . . . . . . . . . . . . . . . . . . . . 5 . . . . . ...... #&gt; 609 . . . . . . . . . . . . . . . . . . . . . 8 . . . . . . . . . . ...... #&gt; 610 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 611 . . . . . . . 2 . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 612 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 613 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 614 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 615 . . . . . . 1 . . . . . . . . . . 2 . . 3 . . . . . . . . . . . ...... #&gt; 616 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 ...... #&gt; 617 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 618 . . . . . . . . 1 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 619 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 620 . . . . . . . . 1 1 . 1 1 . . . . 1 . . . . . 1 . . 1 . . . . 5 ...... #&gt; 621 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 622 1 . . . . 1 . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 623 . . 2 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 624 . . . . . . . . . . . . . . . . . . . . 8 . . 1 . . 1 . . . . . ...... #&gt; 625 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 626 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 627 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 628 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 629 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 630 . . . . . . . . 2 . . 1 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 631 . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 632 . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 633 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 634 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 635 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 636 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 637 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 638 . . 1 . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 639 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 640 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 641 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 642 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 643 . . . . . . . . . . . . . . 1 . 3 . . . . . . . . . . . . . . . ...... #&gt; 644 . . . . . . . . . . . . . . . . . . . . . . . 1 3 . . . . . . . ...... #&gt; 645 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 646 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 647 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 648 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 649 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 650 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 651 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 652 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 653 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 654 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 655 . . . . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 656 . . . . . . . . 2 . . . 2 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 657 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 658 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 659 . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 660 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 661 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 662 . . 1 . 1 . . . 2 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 663 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 664 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 665 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 666 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 667 . . . . . . . . . . . . . . . . 1 2 . 1 . . . . . . . . . . . . ...... #&gt; 668 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . 1 . 1 . . . ...... #&gt; 669 . . . . . . . . 3 . . . 1 . . . . . . . . . . 3 1 . . . . . . . ...... #&gt; 670 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 671 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 672 . . . 4 . . . . . . . . . . . . . . 1 3 . . . . . . . . . . . . ...... #&gt; 673 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 674 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 675 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 676 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 677 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 678 . . 1 1 . . . . . . 2 . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 679 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 680 . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . ...... #&gt; 681 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 682 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 683 . . 1 . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 684 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 685 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . 1 ...... #&gt; 686 . . . . . . . . . . . . . . . . . . . . 7 . . . . . . . . . . . ...... #&gt; 687 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 688 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 689 . . . . 1 . . . 1 . . . . . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 690 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . 1 . . . . ...... #&gt; 691 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 692 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 693 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 694 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 695 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 696 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 697 . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 698 . . . . . . . . . . 2 . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 699 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 700 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 701 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 702 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 703 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 704 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 705 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 706 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 707 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . 1 . . . ...... #&gt; 708 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 709 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 710 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 711 . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . ...... #&gt; 712 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 713 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 714 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 715 1 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 716 . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 717 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 718 . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . 2 . . . . . ...... #&gt; 719 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 720 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 721 . . . . 2 . . . . . . . 5 . . . . . . . . . 1 . . . 1 1 . . . . ...... #&gt; 722 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 723 . . . . . . . 1 1 . . . . . 1 . . . . . . . . 1 1 . . . . . . . ...... #&gt; 724 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 725 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 726 . . 1 . . . . 1 . . . . 2 . . . . 2 . . . . . . 1 . . . . . . . ...... #&gt; 727 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 728 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 729 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 730 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 731 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 732 . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 733 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 734 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 735 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 736 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 737 . . 1 . . . . . . 1 . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 738 . . . . . . . . . . . . 1 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 739 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 740 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 741 . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 742 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 743 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 744 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 745 . . . . . . . 1 . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 746 . . 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 747 . . 1 . . . . . . . . . . . . . . . . . . . 1 1 . . . . 4 . . . ...... #&gt; 748 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 749 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . 3 . . . ...... #&gt; 750 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 751 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 752 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 753 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 754 . . 1 . . . 1 . . . . . . . . . . . . . . . . 1 . . 1 . . 5 . . ...... #&gt; 755 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 756 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 757 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 758 . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 759 . . 1 . 1 . . . 1 . . 1 . . 1 . . . . . 1 . . . 7 . . . . . . . ...... #&gt; 760 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2 . . . . ...... #&gt; 761 . . . . . . 1 . . . . . 1 . . . 1 . . . . . . . 1 . . . . . . . ...... #&gt; 762 . . . . . . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 763 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 764 . . . . . . . . 2 . . . . . . . . . . . . . . . 2 . 6 . . . . . ...... #&gt; 765 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 766 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 767 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 768 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 769 1 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 770 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 771 . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 772 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 773 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 774 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 775 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 776 . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . 1 . . ...... #&gt; 777 . . 1 . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . ...... #&gt; 778 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 779 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 780 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 781 . . . . . . . . . . . . . . . . . . . . . . . 4 2 . . . . . . . ...... #&gt; 782 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 783 . . . . . . . . . . . . . . . . . 4 . . . . . . . . . . . . . . ...... #&gt; 784 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . ...... #&gt; 785 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 786 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 787 . . . . . . . . 2 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 788 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 789 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 790 . . . . . . . 1 . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 791 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 792 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 793 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 794 . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . 2 . . . . . ...... #&gt; 795 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 796 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 797 . . . . . . . . . . . . . . . . 1 . . . . . . 1 1 . . . . . . . ...... #&gt; 798 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 799 . . . . . . . . . . . . . . 2 . . . . . . . . 1 . . . . 1 . . . ...... #&gt; 800 1 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 801 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 802 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 803 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 804 . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 805 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 806 1 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . 2 . . ...... #&gt; 807 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 808 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 809 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 810 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 811 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 812 . . . . . . . . . . . . . . . . . . . . 4 . . . . . . . . . . . ...... #&gt; 813 1 . . . . . . . . . . . . . 1 . . . . . 2 . . . . . . . . . . . ...... #&gt; 814 . 1 1 . . . . . . . . . . . . . . . . . . . . . . 1 1 . . 1 . . ...... #&gt; 815 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 816 . . . . . . . 3 . . . . . . . . . . . . . . . 1 . . 1 . . . . . ...... #&gt; 817 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 818 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 819 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 820 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 821 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 822 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 823 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 824 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 825 . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . 7 . . . ...... #&gt; 826 . . . . . . . . . . . . 1 . . . . . . . . . 1 2 1 . . . . . . . ...... #&gt; 827 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 828 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 829 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 830 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 831 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 832 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 833 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 834 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 835 . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 836 . . . . . 1 . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 837 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 838 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 839 . . . . . . . 1 1 . . . . . . . . . . . . . . . 2 . 1 . . . . . ...... #&gt; 840 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 841 . . . . . . 3 . 1 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 842 . . . . . . . . . 1 . . 1 . . . . . . . 1 . . . . . 2 . . . . . ...... #&gt; 843 . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 844 . . 1 . . . . . . . . . . . . . . . . . 1 1 . . . . . . . . . . ...... #&gt; 845 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 846 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 847 . . . . . 4 . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 848 . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 849 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 850 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 851 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 852 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 853 . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 854 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 855 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 856 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 857 . . . 1 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 858 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 859 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 860 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 861 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 862 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 863 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 864 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 865 . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 866 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 867 . . . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 868 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 869 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 870 . . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . . . ...... #&gt; 871 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 872 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 873 . . . . . 5 . . 2 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 874 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 875 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . 9 . . . ...... #&gt; 876 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 877 . . . . . . . 1 . . . . . . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 878 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 879 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 880 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 881 . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . . 5 1 . . . ...... #&gt; 882 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 883 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 884 . . . . . . . . . 3 . 1 . . . . . . . . . . . 4 1 . . . . . . . ...... #&gt; 885 . . . . . . . . . . . . . . . . . . . . . . . 2 1 . . . . . . . ...... #&gt; 886 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 887 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 888 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 889 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 890 . . . . . . . . 3 . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 891 . . . . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 892 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 893 . . . . . . . 1 . 1 . . . . . . . . . . . . . . 3 . . . 2 . . . ...... #&gt; 894 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 895 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 896 . . . . . . . 2 1 . . . 2 . . . . . . . . . . 1 . . . . . 1 . . ...... #&gt; 897 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 898 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 899 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 900 . . . . . . . . . . . . 2 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 901 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . . ...... #&gt; 902 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 903 . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 904 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 905 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 906 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 907 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 908 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 909 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 910 . . . . . . 2 . . 2 . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 911 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 912 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 913 . . . . . . . . 3 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 914 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 915 . . . . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 916 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 917 . . . . . . . . . . . . 1 . 1 . . . . . . . . 1 1 . . . . . . . ...... #&gt; 918 . . . . . . . . . . . . . . . . . . . . . . 1 . . . 2 . . . . . ...... #&gt; 919 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 920 . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 921 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 922 . . 1 . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 923 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 924 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 925 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 926 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 927 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 928 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 929 . . 1 . . . . . . . . . . . . . . 6 . . . . . . . . 2 . . . . . ...... #&gt; 930 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 931 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 932 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 933 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 934 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 935 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 936 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 937 . . 2 . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 938 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 939 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 940 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 941 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 942 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 943 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 944 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 945 2 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 946 . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . ...... #&gt; 947 . . . . . . . . . . . . . . . . . . . . . . . . 1 1 3 . . . . . ...... #&gt; 948 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 949 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 950 . . . . . . . . . . . . . . 1 . . . . . 1 . . . 1 1 . . . . . . ...... #&gt; 951 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 952 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 953 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 954 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 955 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 956 . . . . . . . . . . . . . 1 . . . 1 . . . . . . . . . . . 1 . . ...... #&gt; 957 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 958 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 959 . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . ...... #&gt; 960 . . . . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . . . ...... #&gt; 961 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 962 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 963 . . 1 . . . . . . . . . . . . . . . . . . 6 . . . 2 5 . . . . . ...... #&gt; 964 . . 1 . . . 1 . . . . . . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 965 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 966 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 967 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 968 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 969 . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 970 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 971 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 972 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 973 . . . . . . 2 . 1 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 974 . . . . . . . . . . . . . . . . . . . 4 . . . . . . . . . . . . ...... #&gt; 975 . . 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 976 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 977 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 978 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 979 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 980 . . . . . . . 1 . . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 981 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 982 . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 983 . . . . . . 1 . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 984 . . . . . . 1 . 1 1 . 1 . . . . . . . . . . . . . . . 5 . . . . ...... #&gt; 985 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 986 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 987 . . 1 . . . . . . . . . . 2 . 2 . 1 . . . . . . . . . 1 . . . . ...... #&gt; 988 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 989 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 990 . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 991 . . 1 . . . . . . . . . . 1 . . . . . . . . . . . . . . 2 1 . . ...... #&gt; 992 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 993 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 994 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . ...... #&gt; 995 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 996 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 997 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 998 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 999 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1000 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1001 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1002 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1003 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1004 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1005 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1006 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1007 . 1 . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 1008 . . . . 1 . . . . . . . . . . . . . . . . . . 2 . 1 . . . . . . ...... #&gt; 1009 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1010 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1011 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1012 . . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . 6 . . . ...... #&gt; 1013 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1014 . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . ...... #&gt; 1015 . . . . . . . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1016 . . . . 1 . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 1017 . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1018 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1019 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1020 . . . . . . . . . . . . 1 . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 1021 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1022 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1023 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1024 . . . . . . . 2 1 . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1025 . . . . . . . . 2 . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1026 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1027 . . 1 . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1028 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1029 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1030 . . . . . . . . 3 . . . 2 . . . . . . . . . . . 4 . . . . . . . ...... #&gt; 1031 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1032 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1033 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1034 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1035 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1036 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 1037 . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1038 . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1039 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1040 . . 1 . . . . . . . . . . . . . . . . 1 1 . . . . . . . . . . . ...... #&gt; 1041 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1042 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1043 . . . . . . . . . . . . . . . . . . . . . 1 . . . . 4 . . . . . ...... #&gt; 1044 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1045 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1046 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1047 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1048 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1049 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1050 . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . . ...... #&gt; 1051 . . . . . . 1 . . . . . 1 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1052 . . . . . . . . . . 2 . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1053 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1054 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1055 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . ...... #&gt; 1056 . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . ...... #&gt; 1057 . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . . 2 . . . . ...... #&gt; 1058 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1059 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1060 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1061 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 1062 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1063 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1064 . . . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . ...... #&gt; 1065 . . . . . . . . . . . . . . . . . . . . . . . 1 . . 2 . . . . . ...... #&gt; 1066 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1067 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1068 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1069 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1070 . . . . . . . . 1 . . . . . 1 . . . . . . . . . 1 . . . 1 1 . . ...... #&gt; 1071 . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . 1 . 1 . . . ...... #&gt; 1072 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 ...... #&gt; 1073 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1074 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1075 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1076 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1077 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1078 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1079 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1080 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1081 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 1082 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1083 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1084 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1085 . . . . . . . . 3 . . . 2 . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 1086 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1087 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1088 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1089 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1090 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1091 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1092 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1093 . . 1 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1094 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1095 . . . . . . . . . . . . . . . . . . . . 1 . . . . . 3 . . . . . ...... #&gt; 1096 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1097 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1098 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1099 . . . . . . . . . . . . . . . . . . . . . . . . . . 4 . . . . . ...... #&gt; 1100 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 1101 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1102 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1103 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1104 . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . ...... #&gt; 1105 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1106 . . . . . . . . 1 . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1107 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1108 . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1109 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1110 . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1111 . . 1 . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1112 . . . . . . 1 . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1113 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1114 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1115 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1116 . . 3 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1117 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1118 . 1 . . . . 1 . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1119 . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1120 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1121 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1122 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1123 . . . . 1 . . . 1 . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1124 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1125 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1126 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1127 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1128 . . 1 . . . . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 1129 . . . . . . . . 1 . . . 2 . . . . 1 . . . . . 1 3 . . . 1 . . . ...... #&gt; 1130 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1131 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1132 1 . 1 . . . . . 1 . . . . . . . . . . . . . . 2 . . . . . . . . ...... #&gt; 1133 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1134 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1135 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1136 . . 1 . . . . . . . . . 2 . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1137 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1138 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1139 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1140 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1141 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1142 . . . . . . . . 1 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1143 . . 1 . . . . . 1 . . . 1 . . . . . . . 2 . 1 1 . . . . . . . . ...... #&gt; 1144 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 ...... #&gt; 1145 . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . . . . . ...... #&gt; 1146 . . . . . . . . . . . . 2 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1147 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1148 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1149 . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . . ...... #&gt; 1150 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1151 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1152 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1153 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1154 . . 3 . . . . . . . . . . . . . . . . . . . . . . 4 . . . . . . ...... #&gt; 1155 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1156 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1157 . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 1158 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1159 . . 1 . . . . . . . . . 1 . . . . . . . . . . 1 1 . 2 . . 3 . . ...... #&gt; 1160 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1161 . . . . . . . . . . . . . . . . 1 . . . . . . . 4 . 1 . . . . . ...... #&gt; 1162 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1163 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1164 . . . 1 . . . . . . . . 2 . 1 . . . 1 1 . . . . . . . . . . . . ...... #&gt; 1165 . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 1166 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1167 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1168 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1169 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1170 . . . . 1 . 2 1 . . . . . . . . . 1 . . . . . . . 5 . . . 1 . . ...... #&gt; 1171 . . . . . . . . . . . . . . . . . . . . . . . 1 2 . . . . . . 2 ...... #&gt; 1172 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1173 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1174 . . 1 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1175 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1176 . . 1 . . . . . 2 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1177 . . . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 1178 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1179 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1180 . . . . . . . . 3 . . 1 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1181 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1182 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1183 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1184 . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1185 . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . 1 . . . . . ...... #&gt; 1186 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1187 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1188 . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 . . . . ...... #&gt; 1189 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1190 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1191 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1192 . . 1 . . . . . . . . . . . 1 . 1 . . . . . . . . 1 . . . . . . ...... #&gt; 1193 . . . . . . 1 . . . . . . . 2 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1194 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1195 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1196 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1197 . . 5 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1198 . . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . 1 . . . ...... #&gt; 1199 . . . . . . . 1 . . . . 5 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1200 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1201 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1202 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1203 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1204 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1205 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1206 . . . . . . . . 2 . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1207 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1208 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1209 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1210 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1211 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1212 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1213 . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1214 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1215 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1216 . . 1 . . . . . . . . 1 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1217 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . 5 2 . ...... #&gt; 1218 . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . ...... #&gt; 1219 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1220 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1221 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1222 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1223 . . . . . . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1224 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1225 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1226 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . ...... #&gt; 1227 . . . . . 7 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1228 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1229 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1230 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1231 . . . . . . . . 1 . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1232 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1233 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1234 . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . 1 . . . . . ...... #&gt; 1235 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1236 1 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1237 . . . . . . . . 1 . . . . . 1 . 1 . . . . . 1 . . . . . . . . . ...... #&gt; 1238 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1239 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1240 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1241 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1242 . . 1 . . . . . . . . . . . . . . 1 . . 1 . . . . . . . . . . . ...... #&gt; 1243 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1244 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1245 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1246 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1247 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1248 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1249 . . 1 . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1250 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 1251 . . . . . . . . . . . . . . . . . . . . . . 1 . . . 3 . . . . 1 ...... #&gt; 1252 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1253 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1254 . . 1 1 . . 1 . . . . . 2 . . . . . . . . . . . 4 . . . . . . . ...... #&gt; 1255 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1256 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1257 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1258 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1259 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1260 . . . . 1 . 2 . . . . . . . 1 . . . . . . . . . 2 . 1 . . . . . ...... #&gt; 1261 . . . . . . . . 2 . . . 1 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1262 . . . . . 1 2 . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1263 . . . . 1 . . 1 . . . . . . . . . 2 . . . . . . 1 . 1 . . 1 . . ...... #&gt; 1264 . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 1265 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1266 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1267 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . ...... #&gt; 1268 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1269 . . . . 1 . . . . . . . 1 . . . . . . . . . . 2 1 . . . . . . . ...... #&gt; 1270 . . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1271 . . . . . . . . . . . . . . . . 2 . . . . . 1 . . . . . . . . . ...... #&gt; 1272 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1273 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1274 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1275 . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1276 . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . . . ...... #&gt; 1277 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1278 . . 1 . . . . . . . . . 3 . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 1279 . . . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1280 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1281 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1282 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1283 . . . . . . . . . . . . 1 . . . . 3 . . . . . . 1 . . . . . . . ...... #&gt; 1284 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1285 . . . . . . . . . . 1 . 1 . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1286 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1287 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1288 . . . . . . . . . . . . . . . . . . . . . . . . 3 . 2 . . . . . ...... #&gt; 1289 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1290 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1291 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 ...... #&gt; 1292 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1293 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1294 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1295 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1296 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1297 . . . . . . . . . . . . 2 . . . . . . . . 1 . . . . . 1 . . . . ...... #&gt; 1298 . . . . . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1299 . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . ...... #&gt; 1300 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1301 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1302 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1303 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . 1 . . ...... #&gt; 1304 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1305 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1306 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1307 . . . . . . . . . . . . 1 . . . . . . . . 2 . . . . . . . . . . ...... #&gt; 1308 . . . . . . 1 . . . . . 1 . . . . . . . . . . . . 1 1 . . . . . ...... #&gt; 1309 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1310 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1311 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1312 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1313 . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1314 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1315 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1316 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1317 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . ...... #&gt; 1318 1 . . . . . . . . . . . . . . . . 1 . . . . . . 3 1 1 . . . . . ...... #&gt; 1319 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . 3 1 . . . ...... #&gt; 1320 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1321 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1322 . . . . . . 1 . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1323 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1324 . . . . . . . . . . . . . . 2 . . . . . . . . 1 . . . . . . . . ...... #&gt; 1325 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1326 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1327 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1328 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1329 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1330 . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1331 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1332 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 1333 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1334 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1335 . . . . 1 . . . 2 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1336 . . . . . . . 1 1 . . . . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 1337 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1338 . . 1 . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 1339 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1340 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1341 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1342 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1343 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . 1 ...... #&gt; 1344 . . . 2 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1345 . . 1 . . . . . . . . . 1 . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 1346 . . 2 . 1 . . . . . . . . . . . . 2 . . 1 . . . 1 . . . . . . . ...... #&gt; 1347 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1348 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1349 . . 2 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . 1 ...... #&gt; 1350 . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1351 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1352 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1353 . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1354 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1355 . . 1 . . . . . 3 . . . . . . . . . . . . . . 1 . . 1 . . . . . ...... #&gt; 1356 . . 1 . . . . . . . . . 1 . . . . 2 . . . . . . . . 1 . . . . . ...... #&gt; 1357 . . . . . . . 1 . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1358 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1359 . . . . . . . . . . . . . . . . . . . . 5 . . . . . . . . . . . ...... #&gt; 1360 . . . . . . 1 1 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1361 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1362 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1363 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1364 . . . 1 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 1365 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1366 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1367 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1368 . 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1369 . . 1 . . . . . 1 . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 1370 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1371 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . 2 . . . ...... #&gt; 1372 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1373 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1374 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1375 . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . . ...... #&gt; 1376 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1377 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1378 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 1379 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1380 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1381 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . 1 . . . . ...... #&gt; 1382 . . . . . . . . . . 1 . . . . . 1 . 1 1 . . . . . 1 . . . . . . ...... #&gt; 1383 . . 1 . . . 1 . . . . . 1 . 1 1 . . . 1 . . . . . . . . . . . . ...... #&gt; 1384 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1385 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1386 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1387 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1388 . . . . . . . . 4 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1389 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1390 . . . . . . . . . . . . 2 . 1 . . . . . . . . . . . . . 1 1 . . ...... #&gt; 1391 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1392 . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1393 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1394 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . ...... #&gt; 1395 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1396 . . . . . . . . 3 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1397 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1398 . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1399 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1400 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1401 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1402 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1403 . . . . . . . 1 1 . . . 1 . . . . . . . . . 1 2 1 . . . . . . . ...... #&gt; 1404 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . 6 . . . . ...... #&gt; 1405 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1406 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1407 . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1408 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1409 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1410 . . 1 . 1 . . . . . . . . . . . . 1 . . 9 . . . . . . . . . . . ...... #&gt; 1411 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1412 . . 1 . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1413 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1414 . . . . . . 1 . . . . . . . . . . . . . . . . 1 1 1 . . . . . . ...... #&gt; 1415 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1416 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 ...... #&gt; 1417 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . . . ...... #&gt; 1418 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1419 . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . . . 1 ...... #&gt; 1420 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1421 . . . . . . . . . . . . . . 1 . . . . . 1 . 1 . . . . . . . . 1 ...... #&gt; 1422 . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . ...... #&gt; 1423 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1424 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1425 . . 2 . . . . 1 . . . . . . . . 1 1 . . 1 . . . . . . . . . . . ...... #&gt; 1426 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1427 . . . . . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . ...... #&gt; 1428 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1429 . . . . . . . . . . . . 2 . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 1430 . . . . . . . . . . . . . 1 . . . 1 . . . . . . . . . . 4 . . . ...... #&gt; 1431 . . . . . . . . . . . . 3 . . . . . . . . . . . . . 1 1 . . . . ...... #&gt; 1432 . . . . . . . . . . . 1 . . . . . . . . 1 . . . 3 . . . 1 . . . ...... #&gt; 1433 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1434 . . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . 4 . . . ...... #&gt; 1435 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1436 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1437 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1438 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1439 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1440 . . . . 1 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1441 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1442 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1443 . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . 3 . . . . . ...... #&gt; 1444 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2 . ...... #&gt; 1445 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1446 . . . . . . . 1 . . . . . . . . . . . . . . . . . 1 1 . . . . . ...... #&gt; 1447 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1448 . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . 1 . 1 ...... #&gt; 1449 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1450 . . . . . . . . . . . . . . . . 2 . . 1 . . . . . . . . . . . . ...... #&gt; 1451 . . . . . . . . . . . 1 1 . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 1452 . . . . . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . ...... #&gt; 1453 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1454 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1455 . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1456 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1457 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1458 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1459 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1460 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1461 . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1462 . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . 1 . ...... #&gt; 1463 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1464 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1465 . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1466 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1467 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1468 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1469 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1470 . . . . . . . . . . 2 . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1471 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1472 . . . 1 . . . . 1 . . . . . . . . 2 . . . . 1 . . . . . . . . . ...... #&gt; 1473 . . 1 . . . . . . . . . . . . . 1 . . . . . . 1 . . . . 1 . . . ...... #&gt; 1474 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1475 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1476 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1477 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1478 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1479 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1480 . . . . . . . . . . . 2 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1481 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1482 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1483 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1484 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1485 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1486 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1487 . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . . . . ...... #&gt; 1488 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1489 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1490 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1491 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1492 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1493 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1494 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1495 . . . . . . . . . . . . . . 2 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1496 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 1497 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1498 . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1499 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1500 . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 ...... #&gt; 1501 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1502 . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 1503 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1504 . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1505 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1506 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1507 . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . . . . . . . ...... #&gt; 1508 . . . . . . . . . . . . 1 . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1509 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1510 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1511 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1512 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1513 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1514 . . . . . . . 1 . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1515 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1516 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1517 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1518 1 . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . . . ...... #&gt; 1519 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1520 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1521 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1522 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1523 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2 . ...... #&gt; 1524 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1525 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1526 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1527 . . . . . . 1 . . . . . . 1 1 . . . . . . . . 2 . . . . 2 . . . ...... #&gt; 1528 . . 2 . . . 1 . 4 . . . 5 . . . . . . . 3 . . . . . . . . . . . ...... #&gt; 1529 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1530 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1531 . . . . . . . 2 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1532 . . 1 5 . . . 2 . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1533 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1534 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1535 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1536 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1537 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1538 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1539 . . . . . . 1 1 . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1540 . . 1 . . . . . . . . . . . . . . . . . 5 . . . . . . . . . . . ...... #&gt; 1541 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1542 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1543 . . . . . . . . 1 . . . . . . . . . . . . . . . 3 . . . . . . . ...... #&gt; 1544 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . . ...... #&gt; 1545 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1546 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1547 . . . 1 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1548 . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1549 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1550 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1551 . . 1 . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 1552 . . 2 . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1553 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1554 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1555 . . . . . . . 1 . . . . . . . . . . . . . . . . . . 1 1 . . . . ...... #&gt; 1556 . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . 1 . . . ...... #&gt; 1557 . . . . . . . . . . . . . . . . . . . . . . . . 6 . . . . . . . ...... #&gt; 1558 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1559 . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . 1 3 1 . . 1 ...... #&gt; 1560 . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 1561 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1562 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1563 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1564 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1565 . . 1 . . . . 1 . . . . . . . . . 2 . . . . . . . . . . . . . . ...... #&gt; 1566 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1567 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1568 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1569 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1570 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1571 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1572 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1573 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1574 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1575 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1576 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1577 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1578 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . ...... #&gt; 1579 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1580 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1581 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1582 . . . . . . . 1 1 . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1583 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1584 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1585 1 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1586 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . 1 ...... #&gt; 1587 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1588 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1589 . . . . . . . . . . . . . . . . . . . . . . . . 4 . . . . . . . ...... #&gt; 1590 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 1591 . . . . . . . 1 . . . . . . 1 . . 1 . 1 . . . . . . . . . . . . ...... #&gt; 1592 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1593 . . . . . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1594 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1595 2 . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . . ...... #&gt; 1596 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1597 . . . . . . 1 . . . . . . . . . 1 . . . . . . . . 2 . . . . . . ...... #&gt; 1598 . . . . . . . . 4 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1599 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1600 . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1601 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1602 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1603 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1604 . . . . . . . . . . . 1 . . . . . . 3 . . . . . 1 . . . . . . . ...... #&gt; 1605 1 . 2 . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1606 . . . . 1 . . . . . . . . . 2 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1607 . . . . . . . . 1 . . . 1 . . . . . . . 2 . . 3 . . 1 . . . . . ...... #&gt; 1608 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1609 . . 1 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1610 . 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1611 . . . . . . . . . . . . . . . . 1 . . . . . . . . 2 . . . . . . ...... #&gt; 1612 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1613 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1614 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1615 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1616 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . 2 . . . ...... #&gt; 1617 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1618 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 1619 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1620 . . . . 2 . . . 1 . . . . . . . . . . . . . . 2 . . . . . . . . ...... #&gt; 1621 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1622 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1623 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1624 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 1625 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1626 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1627 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1628 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1629 . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1630 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1631 . . . . . . . 1 1 . . . 1 . . . . . 1 . 1 . . . . . . . . . . . ...... #&gt; 1632 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1633 . . . . . . 1 . . . . . 2 . . . . . . 1 . . . . . . . . . . . . ...... #&gt; 1634 . . . . . . . . . . . . . . 1 . 1 . . . . . . 1 . . 2 . . . . . ...... #&gt; 1635 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1636 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . ...... #&gt; 1637 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1638 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1639 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1640 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1641 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1642 . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 1643 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . ...... #&gt; 1644 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1645 . . . . . . . . . . . . . . 1 . . . . . . 2 . . . . . . . . . . ...... #&gt; 1646 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1647 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1648 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1649 . . 1 . . . . . 1 . . . . . . . . . . . . . . . 1 1 . . . . . . ...... #&gt; 1650 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1651 . . . . . . . . . . . . 1 . . . 1 2 . . . . . . . 1 . . . . . . ...... #&gt; 1652 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1653 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1654 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1655 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1656 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 3 . . . . . ...... #&gt; 1657 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1658 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1659 . . . . . . . 1 . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1660 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1661 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1662 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1663 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1664 . . . . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 1665 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1666 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1667 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1668 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1669 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1670 . . . . . . . . . . . . 2 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1671 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1672 . 1 . . . . 1 . . . . . . . 1 . 2 1 . . . . . . . . . . . . . . ...... #&gt; 1673 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1674 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1675 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1676 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1677 . . . . . . . . . . . . . . . . . . . . . . . 1 2 . . . . . . . ...... #&gt; 1678 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 ...... #&gt; 1679 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1680 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1681 1 . . . . . . . . . . . . . . . . . . 2 . 1 . . . . . . . . . . ...... #&gt; 1682 . . . . . 1 . . . . . . . . 2 . . . . . . . . . . . 3 . . . . . ...... #&gt; 1683 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1684 . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 1685 . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . ...... #&gt; 1686 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1687 . . . . 1 . . . 2 1 . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1688 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1689 . . . . . . . . . . . . . . 1 . . . . . 1 . . . . . . . . . . . ...... #&gt; 1690 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1691 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1692 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . ...... #&gt; 1693 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1694 . . . . . . . . . . . . 1 . . . 1 . . . . . . . . 1 . . . . . . ...... #&gt; 1695 . . . . . . 1 1 1 . . . 2 . . . . . 4 . . . . 2 . . . . . . . . ...... #&gt; 1696 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1697 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1698 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1699 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1700 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1701 . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . ...... #&gt; 1702 . . 2 . . . . . . . . . . . . . . . . . . . . 1 2 . 1 . . . . . ...... #&gt; 1703 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1704 . . . . . . 1 . 2 . . 1 . . . . . . . 1 . . . 1 1 . . . . . . . ...... #&gt; 1705 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1706 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1707 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . . ...... #&gt; 1708 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1709 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1710 . . 2 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1711 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1712 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1713 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1714 . . . . . . . 2 . . . . . . . . . . . . . . 1 . . . 1 . . . . . ...... #&gt; 1715 . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1716 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1717 . . 3 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1718 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1719 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1720 . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . 1 . . . . . ...... #&gt; 1721 . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . 1 . . ...... #&gt; 1722 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1723 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 2 . . . ...... #&gt; 1724 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1725 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1726 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1727 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1728 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1729 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1730 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1731 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1732 . . . . . . . . . . . 1 . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1733 . . . . . . . . . . . . . . . . . . . . . . . . . . 4 . . . . . ...... #&gt; 1734 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 1735 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . ...... #&gt; 1736 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1737 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1738 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1739 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1740 . . . . . . . . . . . . . . . . . . 1 1 . . . 1 . . 1 . . . . . ...... #&gt; 1741 . . . . . . . 1 . . . . . . 1 . . . . . . . . . . . . . 1 . . . ...... #&gt; 1742 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1743 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1744 . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 1745 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1746 . 1 . . . . . . . . . . . . . . 4 1 . . . . . . . . . . . . . . ...... #&gt; 1747 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1748 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1749 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1750 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1751 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1752 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1753 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1754 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1755 . . 1 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1756 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1757 . . . . . . . . 2 . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1758 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1759 . . . . . . . . . . . 1 . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1760 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1761 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1762 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1763 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1764 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1765 . . 1 . . . . . . . . . . . 1 . 1 . . . . . . . . . . . . . . . ...... #&gt; 1766 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1767 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1768 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1769 . . 1 . . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1770 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . 1 ...... #&gt; 1771 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1772 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1773 . . . . . . . . . . . . . . . . 1 1 . . . . . . . . . . . . . . ...... #&gt; 1774 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1775 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 1776 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1777 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . 7 . . . ...... #&gt; 1778 . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1779 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1780 . . . . . . . 1 . . . . . . . . . . 1 . . . . . . . . . . . . . ...... #&gt; 1781 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 1782 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1783 . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1784 1 . . . . . . 1 . . . . . . . . . . 1 1 . . . . . . . . . . . . ...... #&gt; 1785 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1786 . . . . . . . 1 . . . . . . . . . . . . . . . 3 1 . . . . . . 2 ...... #&gt; 1787 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1788 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . 1 . . . . ...... #&gt; 1789 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1790 . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1791 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1792 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1793 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1794 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1795 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1796 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1797 . . . 1 . . . . 1 . . . . . . . . . . . . . . 1 3 . . . . . . . ...... #&gt; 1798 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1799 . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1800 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1801 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1802 . . . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . . ...... #&gt; 1803 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1804 . . 1 . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 1805 . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . . 1 ...... #&gt; 1806 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1807 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1808 . . . . 2 . . . 2 . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1809 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1810 . . . . . . . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1811 . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1812 . . 1 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1813 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1814 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1815 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1816 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1817 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1818 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . 1 ...... #&gt; 1819 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1820 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . 1 . . . . . . ...... #&gt; 1821 . . . . . . . 1 . . . . . 1 . . . . . . . . . . . . 2 3 1 . . . ...... #&gt; 1822 1 . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 1823 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1824 . . . . . . 1 . 1 1 . . . . . . . . . . . . 2 . . . . . . . . . ...... #&gt; 1825 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . ...... #&gt; 1826 1 . . . . . . . 1 . . . . . . . . . 1 . . . . 1 . . . . . . . . ...... #&gt; 1827 . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1828 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1829 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1830 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1831 . . . . . . . 1 2 . . . . . . . . . . . 1 . . . 1 . . . . . . . ...... #&gt; 1832 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1833 . . . . . 1 . . . . . . . . 4 . . . . . . . . . . . 2 . . . . . ...... #&gt; 1834 . . . . . . . . . . . . . . . . 1 . . . . . . 2 . . 1 . . . . . ...... #&gt; 1835 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1836 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1837 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1838 . . . . . . . . . . . . . . . . . . . . . . . 1 3 . . . . . . . ...... #&gt; 1839 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1840 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1841 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1842 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1843 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1844 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1845 . . 2 . . . . . . . 2 . . . . . . . . . 12 . . . . . . . . . . 2 ...... #&gt; 1846 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1847 . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 1848 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; 1849 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 1850 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1851 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1852 . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1853 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1854 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1855 . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . 1 . . . ...... #&gt; 1856 . . 1 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1857 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1858 . . . . . . . . . . . . . . 1 . . . . . . . . . . . 1 . . . . . ...... #&gt; 1859 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1860 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1861 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1862 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1863 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1864 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1865 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1866 . . 1 . . . . . . . . . . . . . . . . . . . 1 . . . . 2 . . . . ...... #&gt; 1867 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1868 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1869 . . 3 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1870 . . . . . . . . . . . . . . . . . . . . 2 . . . . . 1 . . . . . ...... #&gt; 1871 . . 1 . . . . . 1 . . . . . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 1872 . . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1873 . . . . . . . . . . . . . . . . . . . . . 1 . . . . 1 1 . . . . ...... #&gt; 1874 . . 1 . 2 . 1 . . 4 . . . . . . . . . . . . . 1 4 . . . . 1 . . ...... #&gt; 1875 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1876 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . 3 . . . . . ...... #&gt; 1877 . . . . . . . . . . . 1 3 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1878 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1879 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1880 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1881 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1882 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1883 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1884 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1885 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1886 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1887 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1888 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1889 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1890 . . 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1891 . . 2 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1892 . . . . . . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1893 . . . . . . . 2 . . . . . . . . . 1 . . . . . . . . 1 . . . . . ...... #&gt; 1894 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1895 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1896 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 ...... #&gt; 1897 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1898 . . . . 1 . . . . . . . . . . . . . . . . 1 . 3 1 . . . . . . . ...... #&gt; 1899 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 1900 . . 1 . . . . . . . . . . . 1 . . . . . . . . . . . . . 2 . . . ...... #&gt; 1901 . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . . . ...... #&gt; 1902 . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 1 . . . ...... #&gt; 1903 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1904 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 1905 . . . . . . . . . . . . 3 . . . . . . . . . . 1 2 . . . . . . . ...... #&gt; 1906 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1907 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1908 . . . . . . . . . . . . 1 . 3 . . . . . . . . . . . . . . . . . ...... #&gt; 1909 . . . . 1 . . . . . . . . . 1 . . . . . 1 . . . . . 1 . . . . . ...... #&gt; 1910 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1911 . . 2 . 1 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1912 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1913 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1914 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1915 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1916 . . . . . . . . . . . . . . . . . . . . . . . . . 1 3 . . . . . ...... #&gt; 1917 . . . . . . 1 . . . . . . . 3 . . . . . . . . . 3 1 . . . . . . ...... #&gt; 1918 . . . . . . . . . . . . . . 1 . . . . . 3 . . . . . . . . . . . ...... #&gt; 1919 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1920 . . . . . . . . 2 . . . 2 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1921 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . 2 . . . . . ...... #&gt; 1922 . . . . . . . . . 1 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1923 . . . . . . . 1 . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 1924 . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 1925 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1926 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1927 . . . . 1 . . . . . . . . . 1 . . . . . . . . 2 3 . . . . . . . ...... #&gt; 1928 2 . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1929 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1930 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1931 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1932 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1933 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1934 . . 1 . . . . . . . . . 1 . . . . 2 . . . . 1 . . . . . . . . . ...... #&gt; 1935 . . . . . . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1936 . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1937 . . . . . . . . . . . . . . . . . . 2 . . . . . . . . 1 . . . . ...... #&gt; 1938 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 1939 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1940 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1941 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1942 . . . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1943 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1944 . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . ...... #&gt; 1945 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1946 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1947 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1948 . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 1949 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1950 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1951 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 1952 . . . . . . . . . . . . 2 . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 1953 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1954 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1955 . . . . . . 1 . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 1956 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1957 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 1958 . . 1 . . . . . . . . . . . . . . . . . . . 1 . . 1 . . . . . . ...... #&gt; 1959 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1960 . . . . . . . . . . . . . . . . 1 . . . 1 . . . . . . . 1 . . . ...... #&gt; 1961 . . . . . . . 2 2 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1962 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1963 . . . . . . . . . . . . 1 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1964 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1965 . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 1966 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1967 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1968 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1969 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1970 . . . . . . . . . . . . 1 . . . . . . . . . . . 3 . . . . . . . ...... #&gt; 1971 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1972 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 ...... #&gt; 1973 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 1974 1 . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 ...... #&gt; 1975 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1976 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1977 . . . . . . . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1978 . . 1 . . . . . . 1 . . . . . . 1 . . . 1 . . . . . 2 . . . . . ...... #&gt; 1979 . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . ...... #&gt; 1980 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1981 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 1982 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1983 . . . . . . . 2 . . . . 1 . . . . . . . . 2 . . 2 . . . . . . . ...... #&gt; 1984 . . 2 . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1985 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1986 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 1987 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1988 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 1989 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1990 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1991 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1992 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 1993 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1994 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 1995 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1996 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1997 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 1998 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 1999 . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 2000 . . . . . . . . . . . . 1 . . . . . . . . . 2 1 4 . . . . . . . ...... #&gt; 2001 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2002 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2003 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . . ...... #&gt; 2004 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2005 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2006 . . . . . 1 . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 2007 . 1 . . . . . . . . . . . . . . 1 4 . . . . 1 . 1 1 . . . . . . ...... #&gt; 2008 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2009 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2010 . . . . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2011 . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2012 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2013 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2014 . . . . 1 . 1 . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 2015 . . 1 . . . . . . . . . 1 . . . . . . . . . . . . . 2 . . . . 1 ...... #&gt; 2016 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 2017 . . . . . . . . 1 . . . . . . . . . . . . . . 3 . . . . . . . . ...... #&gt; 2018 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2019 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2020 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2021 . . 3 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2022 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2023 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2024 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2025 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 2026 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2027 . . . . . . . . . . . . . . 2 . 2 . . . . . . . . . . . . . . . ...... #&gt; 2028 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2029 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2030 . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 2031 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2032 . . 1 . . . . 2 1 . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2033 . . . . . . . . . . . . 2 . 1 . . 1 . . . . . . . . 1 . . . . . ...... #&gt; 2034 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2035 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2036 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2037 . . . . . . . . . . . . 2 . . . . 1 . . . . 1 . . . 3 . . . . . ...... #&gt; 2038 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 2039 . . . . . . . . 2 . . 1 . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2040 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2041 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 2042 . . 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2043 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2044 . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . 1 ...... #&gt; 2045 . . . . 1 . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2046 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . ...... #&gt; 2047 1 . 1 . . . . . . . . . . . . . . . . . 4 . . . . . . . . . . . ...... #&gt; 2048 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2049 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 2050 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2051 . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 2052 . . . . . . . . . . . . . . . . . . . . . . . 2 2 . . . 1 . . . ...... #&gt; 2053 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2054 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2055 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2056 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2057 . . . . . . . . . . . . . . . . . 1 . . . . . 1 . . . . 4 . . . ...... #&gt; 2058 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2059 . . . . . . . . . 1 . . . . 1 . . . . . 2 . 1 . . . . 1 3 . . . ...... #&gt; 2060 . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2061 . . . . . . . . . . . . . . . . . . . . . . . 2 1 1 . . . . . . ...... #&gt; 2062 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2063 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2064 . . . . . . . . 1 . . . . . . . . . 2 . . . . 2 . . . . . . . . ...... #&gt; 2065 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2066 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2067 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2068 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2069 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2070 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2071 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2072 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2073 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 4 . . . . . ...... #&gt; 2074 . . . . . . . 1 . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2075 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2076 . . . . . . . . . . 1 . . . 2 . . . . . . . . . . . . . . . . 1 ...... #&gt; 2077 . . 1 . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . 1 . . ...... #&gt; 2078 . . 3 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2079 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2080 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2081 . . . . . . . . . . . . . . . . . . . . . . . . 5 . . . . . . . ...... #&gt; 2082 . . . . . . . . 4 . . . 1 . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 2083 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2084 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2085 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 2086 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2087 . . . . . . . . . . . . . . . . . 2 . . 1 . . . . . 1 . . . . . ...... #&gt; 2088 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2089 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 2090 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2091 . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2092 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . ...... #&gt; 2093 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2094 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2095 1 . . . . . . . . . . . . . . . . . . . . . . . 2 . 1 . . . . . ...... #&gt; 2096 . . . . . . . . 1 . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2097 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2098 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2099 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2100 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2101 . . 1 . . . . . . . 1 . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 2102 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2103 . . 3 . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 2104 . . . . . . . . 1 . . . 1 . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2105 . . . . . . . . 1 . . . 2 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2106 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2107 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2108 . . . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2109 . . . . . . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2110 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2111 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2112 . . . . . 2 . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2113 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2114 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 2115 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2116 . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 2117 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2118 . . . . . . . . 3 . . . . . . . . . . . 1 . . 2 . . . . . . . . ...... #&gt; 2119 . . . . . . . . . . . . . . . . 1 . . . . . . . 1 . . . . . . . ...... #&gt; 2120 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . ...... #&gt; 2121 . . 1 . . . . . . . 1 . . . . . 3 . . . 1 . . . . . . . . . . . ...... #&gt; 2122 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . ...... #&gt; 2123 . . 1 . . . . . . . . . . . . . 2 . . . 1 . . . . . . . . . . . ...... #&gt; 2124 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2125 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 2126 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 2127 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2128 . . . . . . . . 1 . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2129 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2130 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2131 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2132 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2133 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2134 . . 1 . . . . . . . 2 . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2135 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 2136 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2137 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2138 . . . . . . 1 . . . . . . . . . . . . . . . 4 . . . . . . . . . ...... #&gt; 2139 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2140 . . 1 . . . . 1 . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2141 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . ...... #&gt; 2142 . . . . . . . . . 1 . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2143 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2144 . . . . . . . . . . . . . . 1 . . 1 1 . . . 1 . . . . . . . . . ...... #&gt; 2145 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2146 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2147 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2148 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2149 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2150 . . 3 . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . . . ...... #&gt; 2151 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2152 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2153 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2154 . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . ...... #&gt; 2155 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2156 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . 1 ...... #&gt; 2157 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2158 . . 1 . . . . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . ...... #&gt; 2159 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2160 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2161 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2162 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2163 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2164 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 2165 . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 2166 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2167 . . . . . . . 1 1 . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2168 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2169 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2170 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2171 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2172 . . . . . . . 1 . . . . . . 1 . . . . . . . . 1 . . . . . . . . ...... #&gt; 2173 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2174 . . . . 1 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2175 . . . . . . . . . . . . 1 . . . . . . . . 2 . . . . . . . . . . ...... #&gt; 2176 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2177 . . . . . 1 . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2178 . 1 . . . . . . . . . . . . . . . . . . . . . . . . 2 . . 1 . . ...... #&gt; 2179 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . ...... #&gt; 2180 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2181 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2182 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2183 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2184 . . . . . . . . . . . . . . . . . . . . 2 . . . . . 2 . . . . . ...... #&gt; 2185 . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . . 1 ...... #&gt; 2186 . . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2187 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 ...... #&gt; 2188 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2189 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2190 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2191 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2192 . . . . . . . . . . . . . . . . . . . . . . . . . 2 . . . . . . ...... #&gt; 2193 . . . . . . . . . . . . . . 1 . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 2194 . . . . . . . . . . . . 2 . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2195 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2196 . . 1 . . . . . . . . . . . . . 3 . . . . . . . . . . . . . . . ...... #&gt; 2197 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2198 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2199 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2200 . . . 3 . . . . . 1 . . 1 . . . . . . . . . . . . . . . 1 . . . ...... #&gt; 2201 . . 2 . . . . . . . . . . . . . . . . . . . . 1 . . . 1 . . . . ...... #&gt; 2202 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2203 . . . . . . . . . . . . 1 . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2204 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2205 . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . . ...... #&gt; 2206 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2207 . . . . 1 . . . . . . . 1 . . . . . . . . . . 1 3 . . . . . . . ...... #&gt; 2208 . . . . . . . 2 . . . . . . . . . . . . 2 . . . . . . . . . . . ...... #&gt; 2209 . . . . . . . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2210 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2211 . . . . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2212 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2213 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2214 . . 1 . . . . 1 . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2215 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2216 . . . . . . . 1 . . . . 2 2 . . . . . . 2 . . . . . . . 2 . . . ...... #&gt; 2217 . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . 1 . . . . . ...... #&gt; 2218 . . 2 . . . . . . . . . . . 1 . . . . . . . . . . . . . . 1 . 1 ...... #&gt; 2219 . . . . . . . 1 . . . . . . . . . . . . . . . . . . 1 . . . . . ...... #&gt; 2220 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2221 . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . ...... #&gt; 2222 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2223 . . . . . . . 1 . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2224 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2225 . . 1 . . . . 1 . . . . . . . . . . . . 1 . 1 . . . . . . . . . ...... #&gt; 2226 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2227 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2228 . . 1 . . . . . . 1 . . . . 1 . . . . . . . . . 1 . . . . . . . ...... #&gt; 2229 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2230 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2231 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2232 . . . . . . 1 . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 2233 . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . ...... #&gt; 2234 . . . . . . . . . . . . . . 1 . 2 . . . . . . . . . . . . . . . ...... #&gt; 2235 . . 1 . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2236 . . . . . . . 2 . . . . . . . . . . . . . . 1 . . . . . . . . . ...... #&gt; 2237 . . . . . . . . . . . . . . . . 2 . . . . . . . . . . . . . . . ...... #&gt; 2238 . . . . . . . . . . . . . . . . 1 . . . . . . . . . 1 . . . . . ...... #&gt; 2239 . . . . . . . . . . . . . . . . 1 . . . . . . . . . . . . . . . ...... #&gt; 2240 . . . . . . 1 . . . . 1 . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2241 . . 1 . . . . . 1 . . . 1 . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2242 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...... #&gt; 2243 . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . ...... #&gt; 2244 . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . . . . . ...... #&gt; 2245 . . . . . . . . . . . . . . . . . . . 3 . . . . . . . . . . . . ...... #&gt; 2246 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . ...... #&gt; #&gt; .....suppressing 10441 columns in show(); maybe adjust &#39;options(max.print= *, width = *)&#39; #&gt; .............................. "],
["tidying-corpus-objects-with-metadata.html", "5.3 Tidying corpus objects with metadata", " 5.3 Tidying corpus objects with metadata Notwithstanding discrepancies in their form, document term matrix and one-token-per-row data frame are exchangable for they both store the same information after tokenization. A corpus object, however, is a data structure for text data before tokenization. One common example is Corpus objects from the tm package. These store text alongside metadata, which may include an ID, date/time, title, or language for each document. The tm package comes with the acq corpus, containing 50 articles from the news service Reuters. data(&quot;acq&quot;) acq #&gt; &lt;&lt;VCorpus&gt;&gt; #&gt; Metadata: corpus specific: 0, document level (indexed): 0 #&gt; Content: documents: 50 A corpus object is structured like a list, with each item containing both text and metadata, wh. acq[[1]] #&gt; &lt;&lt;PlainTextDocument&gt;&gt; #&gt; Metadata: 15 #&gt; Content: chars: 1287 acq[[1]]$content #&gt; [1] &quot;Computer Terminal Systems Inc said\\nit has completed the sale of 200,000 shares of its common\\nstock, and warrants to acquire an additional one mln shares, to\\n&lt;Sedio N.V.&gt; of Lugano, Switzerland for 50,000 dlrs.\\n The company said the warrants are exercisable for five\\nyears at a purchase price of .125 dlrs per share.\\n Computer Terminal said Sedio also has the right to buy\\nadditional shares and increase its total holdings up to 40 pct\\nof the Computer Terminal&#39;s outstanding common stock under\\ncertain circumstances involving change of control at the\\ncompany.\\n The company said if the conditions occur the warrants would\\nbe exercisable at a price equal to 75 pct of its common stock&#39;s\\nmarket price at the time, not to exceed 1.50 dlrs per share.\\n Computer Terminal also said it sold the technolgy rights to\\nits Dot Matrix impact technology, including any future\\nimprovements, to &lt;Woodco Inc&gt; of Houston, Tex. for 200,000\\ndlrs. But, it said it would continue to be the exclusive\\nworldwide licensee of the technology for Woodco.\\n The company said the moves were part of its reorganization\\nplan and would help pay current operation costs and ensure\\nproduct delivery.\\n Computer Terminal makes computer generated labels, forms,\\ntags and ticket printers and terminals.\\n Reuter&quot; acq[[1]]$meta #&gt; author : character(0) #&gt; datetimestamp: 1987-02-26 15:18:06 #&gt; description : #&gt; heading : COMPUTER TERMINAL SYSTEMS &lt;CPML&gt; COMPLETES SALE #&gt; id : 10 #&gt; language : en #&gt; origin : Reuters-21578 XML #&gt; topics : YES #&gt; lewissplit : TRAIN #&gt; cgisplit : TRAINING-SET #&gt; oldid : 5553 #&gt; places : usa #&gt; people : character(0) #&gt; orgs : character(0) #&gt; exchanges : character(0) We can thus use the tidy() method to construct a table with one row per document, including the metadata acq_tidy &lt;- tidy(acq) acq_tidy #&gt; # A tibble: 50 x 16 #&gt; author datetimestamp description heading id language origin topics #&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 &lt;NA&gt; 1987-02-26 23:18:06 &quot;&quot; COMPUT~ 10 en Reute~ YES #&gt; 2 &lt;NA&gt; 1987-02-26 23:19:15 &quot;&quot; OHIO M~ 12 en Reute~ YES #&gt; 3 &lt;NA&gt; 1987-02-26 23:49:56 &quot;&quot; MCLEAN~ 44 en Reute~ YES #&gt; 4 By Ca~ 1987-02-26 23:51:17 &quot;&quot; CHEMLA~ 45 en Reute~ YES #&gt; 5 &lt;NA&gt; 1987-02-27 00:08:33 &quot;&quot; &lt;COFAB~ 68 en Reute~ YES #&gt; 6 &lt;NA&gt; 1987-02-27 00:32:37 &quot;&quot; INVEST~ 96 en Reute~ YES #&gt; # ... with 44 more rows, and 8 more variables: lewissplit &lt;chr&gt;, #&gt; # cgisplit &lt;chr&gt;, oldid &lt;chr&gt;, places &lt;named list&gt;, people &lt;lgl&gt;, orgs &lt;lgl&gt;, #&gt; # exchanges &lt;lgl&gt;, text &lt;chr&gt; "],
["topic-modeling.html", "Chapter 6 Topic modeling", " Chapter 6 Topic modeling A topic model is a type of statistical model for discovering the abstract “topics” that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The “topics” produced by topic modeling techniques are clusters of similar words. "],
["latent-dirichlet-allocation.html", "6.1 Latent Dirichlet Allocation", " 6.1 Latent Dirichlet Allocation Latent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. This allows documents to “overlap” each other in terms of content, rather than being separated into discrete groups, in a way that mirrors typical use of natural language. The LDA model is guided by two principles: Each document is a mixture of topics. In a 3 topic model we could assert that a document is 70% about topic A, 30 about topic B, and 0% about topic C. Every topic is a mixture of words. A topic is considered a probabilistic distribution over multiple words. Figure 6.1: Source: http://nlpx.net/wp/wp-content/uploads/2016/01/LDA_image2.jpg In particular, LDA is a imagined generative process, illustrated in the plate notation below: Figure 6.2: Source: Lee et al. (2018) \\(M\\) denotes the number of documents \\(N\\) is the number of words in a given document (document \\(i\\) has \\(N_i\\) words) \\(\\vec{\\theta_m}\\) is the expected topic proportion of document \\(m\\), which is generated by a Dirichlet distribution parameterized by \\(\\vec{\\alpha}\\) (e.g., in a two topic model \\(\\theta_m = [0.3, 0.7]\\) means document \\(m\\) is expected to have 30% topic 1 and 70% topic 2) \\(\\vec{\\phi_k}\\) is the word distribution of topic \\(k\\), which is generated by a Dirichlet distribution parameterized by \\(\\vec{\\beta}\\) \\(z_{m, n}\\) is the topic for the \\(n\\)th word in document \\(m\\), one word are assigned to one topic. \\(w_{m, n}\\) is the word in the \\(n\\)th position word of document \\(m\\) The only observed variable in this graphical probabilistic model is \\(w_{m, n}\\), so it is “latent”. To actually infer the topics in a corpus, we imagine the generative process as follows. LDA assumes the following generative process for a corpus \\(D\\) consisting of \\(M\\) M documents each of length \\(N_i\\): Generate \\(\\vec{\\theta_i} \\sim \\text{Dir}(\\vec{\\alpha})\\), where \\(i \\in \\{1, 2, ..., M\\}\\). \\(\\text{Dir}(\\vec{\\alpha})\\) is a Dirichlet distribution with symmetric parameter \\(\\vec{\\alpha}\\) where \\(\\vec{\\alpha}\\) is often sparse. Generate \\(\\vec{\\phi_k} \\sim \\text{Dir}(\\vec{\\beta})\\), where \\(k \\in \\{1, 2, ..., K\\}\\) and \\(\\vec{\\beta}\\) is typically sparse For the \\(n\\)th position in document \\(m\\), where \\(n \\in \\{1, 2, ..., N_m\\}\\) and \\(m \\in \\{1, 2, ..., M\\}\\) Choose a topic \\(z_{m, n}\\) for that position which is generated from \\(z_{m, n} \\sim \\text{Multinomial}(\\vec{\\theta_i})\\) Fill in that position with word \\(w_{m, n}\\) which is generated from the word distribution of the topic picked in the previous step \\(w_{i,j} \\sim \\text{Multinomial}(\\phi_{z_{m, n}})\\) 6.1.1 Example: Associated Press We come to the AssociatedPress document term matrix (the required data strcture for the modeling function) and fit a two topic LDA model with topicmodels::LDA() library(topicmodels) data(&quot;AssociatedPress&quot;) ap_lda &lt;- LDA(AssociatedPress, k = 2) ap_lda #&gt; A LDA_VEM topic model with 2 topics. For tidying model objects, tidy(model_object, matrix = \"beta\") (the default) access the topic-word probability vector (we denotes with \\(\\vec{\\phi_k}\\)) tidy(ap_lda) #&gt; # A tibble: 20,946 x 3 #&gt; topic term beta #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 aaron 0.00000513 #&gt; 2 2 aaron 0.0000403 #&gt; 3 1 abandon 0.0000499 #&gt; 4 2 abandon 0.0000193 #&gt; 5 1 abandoned 0.0000116 #&gt; 6 2 abandoned 0.000170 #&gt; # ... with 20,940 more rows Which words have a relateve higher probabiltity to appear in each topic? tidy(ap_lda) %&gt;% group_by(topic) %&gt;% top_n(10) %&gt;% ungroup() %&gt;% mutate(topic = str_c(&quot;topic&quot;, topic)) %&gt;% facet_bar(y = term, x = beta, by = topic) + labs(title = &quot;Words with highest probability in each topic&quot;) As an alternative, we could consider the terms that had the greatest difference in \\(\\vec{\\phi_k}\\) between topic 1 and topic 2. This can be estimated based on the log ratio of the two: \\(\\log_2(\\frac{\\phi_{1n}}{\\phi_{2n}})\\), \\(\\phi_{1n} / \\phi_{2n}\\) being the probability ratio of the sam e word \\(n\\) in two topics (a log ratio is useful because it makes the difference symmetrical) phi_ratio &lt;- tidy(ap_lda) %&gt;% mutate(topic = str_c(&quot;topic&quot;, topic)) %&gt;% pivot_wider(names_from = topic, values_from = beta) %&gt;% filter(topic1 &gt; .001 | topic2 &gt; .001) %&gt;% mutate(log_ratio = log2(topic2 / topic1)) This can answer a question like: which word is most representative of a topic? phi_ratio %&gt;% top_n(20, abs(log_ratio)) %&gt;% ggplot(aes(y = fct_reorder(term, log_ratio), x = log_ratio)) + geom_col() + labs(y = &quot;&quot;, x = &quot;log ratio of phi between topic 2 and topic 1 (base 2)&quot;) To extrac the word proportion vector \\(\\vec{\\theta_m}\\) for document \\(m\\), use matrix = \"gamma\" in tidy() tidy(ap_lda, matrix = &quot;gamma&quot;) #&gt; # A tibble: 4,492 x 3 #&gt; document topic gamma #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 1 0.552 #&gt; 2 2 1 0.623 #&gt; 3 3 1 0.491 #&gt; 4 4 1 0.464 #&gt; 5 5 1 0.517 #&gt; 6 6 1 0.482 #&gt; # ... with 4,486 more rows With this data frame, we want to knwo which document is most charateristic of each topic? library(reshape2) library(wordcloud) tidy(ap_lda, matrix = &quot;gamma&quot;) %&gt;% group_by(topic) %&gt;% top_n(15) %&gt;% mutate(document = as.character(document)) %&gt;% acast(document ~ topic, value.var = &quot;gamma&quot;, fill = 0) %&gt;% comparison.cloud(colors = c(&quot;gray20&quot;, &quot;gray80&quot;), scale = c(2, 8)) This plot would definitely be more insightful if we have document titles rather than an ID. "],
["example-the-great-library-heist.html", "6.2 Example: the great library heist", " 6.2 Example: the great library heist To evaluate our topic model, we first divided 4 books into chapters. If a topic model with \\(K = 4\\) performs well, then there should be a corresponding segmentation among those chpaters coming from those 4 different books. titles &lt;- c(&quot;Twenty Thousand Leagues under the Sea&quot;, &quot;The War of the Worlds&quot;, &quot;Pride and Prejudice&quot;, &quot;Great Expectations&quot;) library(gutenbergr) books &lt;- gutenberg_works(title %in% titles) %&gt;% gutenberg_download(meta_fields = &quot;title&quot;) # add a chapter column by_chapter &lt;- books %&gt;% group_by(title) %&gt;% mutate(chapter = cumsum(str_detect(text, regex(&quot;^chapter &quot;, ignore_case = TRUE)))) %&gt;% ungroup() %&gt;% filter(chapter &gt; 0) %&gt;% unite(document, title, chapter) # find document-word counts word_counts &lt;- by_chapter %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% rename(chapter = document) %&gt;% count(chapter, word, sort = TRUE) %&gt;% ungroup() word_counts #&gt; # A tibble: 104,722 x 3 #&gt; chapter word n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Great Expectations_57 joe 88 #&gt; 2 Great Expectations_7 joe 70 #&gt; 3 Great Expectations_17 biddy 63 #&gt; 4 Great Expectations_27 joe 58 #&gt; 5 Great Expectations_38 estella 58 #&gt; 6 Great Expectations_2 joe 56 #&gt; # ... with 104,716 more rows 6.2.1 LDA on chapters chapters_dtm &lt;- word_counts %&gt;% cast_dtm(document = chapter, term = word, value = n) chapters_lda &lt;- chapters_dtm %&gt;% LDA(k = 4) Much as we did on the Associated Press data, we can examine per-topic-per-word probabilities. chapter_topics &lt;- tidy(chapters_lda, matrix = &quot;beta&quot;) chapter_topics #&gt; # A tibble: 72,860 x 3 #&gt; topic term beta #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 joe 1.45e- 52 #&gt; 2 2 joe 1.44e- 2 #&gt; 3 3 joe 4.69e-118 #&gt; 4 4 joe 3.61e- 19 #&gt; 5 1 biddy 5.21e-181 #&gt; 6 2 biddy 4.75e- 3 #&gt; # ... with 72,854 more rows We can find top 5 terms within each topic. chapter_topics %&gt;% group_by(topic) %&gt;% top_n(5) %&gt;% ungroup() %&gt;% mutate(topic = str_c(&quot;topic&quot;, topic)) %&gt;% facet_bar(y = term, x = beta, by = topic) I am not an expert on the other 3 books aside from Pride &amp; Prejudice, but according to Julia, each topic did correspond to one book by and large! 6.2.2 Per-document classification We may want to how which topics are associated with each document, in particular, the majority of chapters in the same book should belong to the same topic (if we assign a chapter\\(_m\\) to a topic\\(_k\\) when the \\(k\\)th postion in \\(\\hat{\\theta}_m\\) is significantly higher). chapters_gamma &lt;- tidy(chapters_lda, matrix = &quot;gamma&quot;) %&gt;% separate(document, c(&quot;title&quot;, &quot;chapter&quot;), sep = &quot;_&quot;, convert = TRUE) %&gt;% mutate(topic = factor(topic) %&gt;% fct_inseq()) chapters_gamma #&gt; # A tibble: 772 x 4 #&gt; title chapter topic gamma #&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Great Expectations 57 1 0.0000150 #&gt; 2 Great Expectations 7 1 0.0000163 #&gt; 3 Great Expectations 17 1 0.0000234 #&gt; 4 Great Expectations 27 1 0.0000213 #&gt; 5 Great Expectations 38 1 0.0000142 #&gt; 6 Great Expectations 2 1 0.0000191 #&gt; # ... with 766 more rows ggplot(chapters_gamma) + geom_boxplot(aes(topic, gamma)) + facet_wrap(~ title) Ideally we would expect that in every book panel, there is one boxplot highly centered at 1 with the other 3 boxes at 0, since chapters in the same book are categorized in the same topic. It does look like some chapters from Great Expectations (which should be topic 4) were somewhat associated with other topics. Are there any cases where the topic most associated with a chapter belonged to another book? First we’d find the topic that was most associated with each chapter using top_n(), which is effectively the “classification” of that chapter. chapter_classifications &lt;- chapters_gamma %&gt;% group_by(title, chapter) %&gt;% top_n(1, gamma) %&gt;% ungroup() chapter_classifications #&gt; # A tibble: 193 x 4 #&gt; title chapter topic gamma #&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Pride and Prejudice 43 1 1.00 #&gt; 2 Pride and Prejudice 18 1 1.00 #&gt; 3 Pride and Prejudice 45 1 1.00 #&gt; 4 Pride and Prejudice 16 1 1.00 #&gt; 5 Pride and Prejudice 29 1 0.988 #&gt; 6 Pride and Prejudice 10 1 1.00 #&gt; # ... with 187 more rows We can then compare each to the “consensus” topic for each book (the most common topic among its chapters), and see which were most often misidentified. # identify which topic is most related to which book book_topics &lt;- chapter_classifications %&gt;% count(title, topic) %&gt;% group_by(title) %&gt;% top_n(1, n) %&gt;% ungroup() %&gt;% transmute(consensus = title, topic) # which chapter in misidentified chapter_classifications %&gt;% inner_join(book_topics) %&gt;% filter(consensus != title) #&gt; # A tibble: 5 x 5 #&gt; title chapter topic gamma consensus #&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Great Expectations 20 4 0.521 The War of the Worlds #&gt; 2 Great Expectations 37 4 0.451 The War of the Worlds #&gt; 3 Great Expectations 54 4 0.742 The War of the Worlds #&gt; 4 Great Expectations 45 4 0.556 The War of the Worlds #&gt; 5 Great Expectations 21 4 0.527 The War of the Worlds We see that one chapter in “Great Expectation” is misidentified as a member of topic 3, which is essentially “The War of the Worlds” 6.2.3 By word assignments: augment() One step of the LDA algorithm is assigning each word in each document to a topic \\(z_{m, n}\\). The more words in a document are assigned to that topic, generally, the more weight \\(\\theta_m\\) will go on that document-topic classification. We may want to take the original document-word pairs and find which words in each document were assigned to which topic. This is the job of the augment() function, which is to add information to each observation in the original data. assignments &lt;- augment(chapters_lda, data = chapters_dtm) %&gt;% rename(chapter = document) assignments #&gt; # A tibble: 104,722 x 4 #&gt; chapter term count .topic #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Great Expectations_57 joe 88 2 #&gt; 2 Great Expectations_7 joe 70 2 #&gt; 3 Great Expectations_17 joe 5 2 #&gt; 4 Great Expectations_27 joe 58 2 #&gt; 5 Great Expectations_2 joe 56 2 #&gt; 6 Great Expectations_23 joe 1 2 #&gt; # ... with 104,716 more rows To get a sense of how our model works, we can draw a bar plot of assigned topics in each book assignments %&gt;% separate(chapter, into = c(&quot;title&quot;, &quot;chapter&quot;), sep = &quot;_&quot;) %&gt;% count(title, .topic, wt = count) %&gt;% ggplot(aes(.topic, n)) + geom_col(width = 0.5) + facet_wrap(~ title) We can combine this assignments table with the consensus book titles to find which words were incorrectly classified by a coofusion matrix. assignments &lt;- assignments %&gt;% separate(chapter, c(&quot;title&quot;, &quot;chapter&quot;), sep = &quot;_&quot;, convert = TRUE) %&gt;% inner_join(book_topics, by = c(&quot;.topic&quot; = &quot;topic&quot;)) assignments #&gt; # A tibble: 104,722 x 6 #&gt; title chapter term count .topic consensus #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 Great Expectations 57 joe 88 2 Great Expectations #&gt; 2 Great Expectations 7 joe 70 2 Great Expectations #&gt; 3 Great Expectations 17 joe 5 2 Great Expectations #&gt; 4 Great Expectations 27 joe 58 2 Great Expectations #&gt; 5 Great Expectations 2 joe 56 2 Great Expectations #&gt; 6 Great Expectations 23 joe 1 2 Great Expectations #&gt; # ... with 104,716 more rows # confusion matrix assignments %&gt;% count(title, consensus, wt = count) %&gt;% group_by(title) %&gt;% mutate(percent = n / sum(n)) %&gt;% ungroup() %&gt;% ggplot(aes(consensus, title, fill = percent)) + geom_tile() + scale_fill_gradient2(high = &quot;red&quot;, label = scales::percent_format()) + scale_x_discrete(guide = guide_axis(n.dodge = 2)) + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs(x = &quot;Book words were assigned to&quot;, y = &quot;Book words came from&quot;, fill = &quot;% of assignments&quot;) What were the most commonly mistaken words? assignments %&gt;% filter(title != consensus) %&gt;% count(title, consensus, term, .wt = count) %&gt;% arrange(desc(n)) #&gt; # A tibble: 3,523 x 5 #&gt; title consensus term .wt n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 Great Expectations The War of the Worlds britain 1 11 #&gt; 2 Great Expectations The War of the Worlds yards 1 8 #&gt; 3 Great Expectations The War of the Worlds deep 1 7 #&gt; 4 Great Expectations The War of the Worlds direction 1 7 #&gt; 5 Great Expectations The War of the Worlds feet 1 7 #&gt; 6 Great Expectations The War of the Worlds london 1 7 #&gt; # ... with 3,517 more rows We can see that a number of words were often assigned to the Pride and Prejudice or War of the Worlds cluster even when they appeared in Great Expectations. For some of these words, such as “love” and “lady”, that’s because they’re more common in Pride and Prejudice (we could confirm that by examining the counts). It is possible that a word is assigned to a book, even though it never appears in that book. "],
["references.html", "References", " References Jurafsky, Dan, Victor Chahuneau, Bryan Routledge, and Noah Smith. 2014. “Narrative Framing of Consumer Sentiment in Online Restaurant Reviews.” First Monday 19 (April). https://doi.org/10.5210/fm.v19i4.4944. Lee, Junseok, Ji-Ho Kang, Sunghae Jun, Hyunwoong Lim, Dongsik Jang, and Sangsung Park. 2018. “Ensemble Modeling for Sustainable Technology Transfer.” Sustainability 10 (July): 2278. https://doi.org/10.3390/su10072278. Monroe, Burt L., Michael P. Colaresi, and Kevin M. Quinn. 2008. “Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict.” Political Analysis 16 (4): 372–403. https://doi.org/10.1093/pan/mpn018. Silge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. 1st ed. O’Reilly Media, Inc. "],
["reviews-on-regular-expressions.html", "A Reviews on regular expressions", " A Reviews on regular expressions References: Sams Teach Yourself Regular Expressions in 10 Minutes "],
["posix-character-classes.html", "A.1 POSIX Character Classes", " A.1 POSIX Character Classes class description [:alnum:] characters or numbers, equivalent to [A-Za-z0-9] [:alpha:] characters, equivalent to [A-Za-z] [:punct:] punctuations [:blank:] space or tab, equivalent to [\\t ] [:space:] any whitespace character including space [\\f\\n\\r\\t\\v ] [:print:] any printable character, a similar expression is [:graph:] which excludes space [:xdigit:] any hexadecimal digit, equivalent to [F-Aa-f0-9] "],
["greedy-and-lazy-quantifiers.html", "A.2 Greedy and lazy quantifiers", " A.2 Greedy and lazy quantifiers Greedy Lazy * *? + +? {n, } {n, }? , a common use case of lazy quantifiers is when we need to strip from html form text all its tags text &lt;- &quot;This offer is not available to customers living in &lt;B&gt;AK&lt;/B&gt; and &lt;B&gt;HI&lt;/B&gt;&quot; # lazy str_extract_all(text, &quot;&lt;[Bb]&gt;.+?&lt;/[Bb]&gt;&quot;) #&gt; [[1]] #&gt; [1] &quot;&lt;B&gt;AK&lt;/B&gt;&quot; &quot;&lt;B&gt;HI&lt;/B&gt;&quot; # greedy str_extract_all(text, &quot;&lt;[Bb]&gt;.+&lt;/[Bb]&gt;&quot;) #&gt; [[1]] #&gt; [1] &quot;&lt;B&gt;AK&lt;/B&gt; and &lt;B&gt;HI&lt;/B&gt;&quot; "],
["looking-ahead-and-back.html", "A.3 Looking ahead and back", " A.3 Looking ahead and back Lookahead specifies a pattern to be matched but not returned. A lookahead is actually a subexpression and is formatted as such. The syntax for a lookahead pattern is a subexpression preceded by ?=, and the text to match follows the = sign. Some refer to this behaviour as “match but not consume”, in the sense that lookhead and lookahead match a pattern after/before what we actually want to extract, but do not return it. In the following example, we only want to matcch “my homepage” that followed by a &lt;/title&gt;, and we do not want &lt;/title&gt; in the results text &lt;- c(&quot;&lt;title&gt;my homepage&lt;/title&gt;&quot;, &quot;&lt;p&gt;my homepage&lt;/p&gt;&quot;) str_extract(text, &quot;my homepage(?=&lt;/title&gt;)&quot;) #&gt; [1] &quot;my homepage&quot; NA # looking ahead (and back) must be used in subexpressions str_extract(text, &quot;my homepage?=&lt;/title&gt;&quot;) #&gt; [1] NA NA Similarly, ?&lt;= is interpreted as the lookback operator, which specifies a pattern before the text we actually want to extract. Following is an example. A database search lists products, and you need only the prices. Following is an example. A database search lists products, and you need only the prices. text &lt;- c(&quot;ABC01: $23.45&quot;, &quot;HGG42: $5.31&quot;, &quot;CFMX1: $899.00&quot;, &quot;XTC99: $69.96&quot;, &quot;Total items found: 4&quot;) str_extract(text, &quot;(?&lt;=\\\\$)[0-9]+&quot;) #&gt; [1] &quot;23&quot; &quot;5&quot; &quot;899&quot; &quot;69&quot; NA ookahead and lookbehind operations may be combined, as in the following example str_extract(&quot;&lt;title&gt;my homepage&lt;/title&gt;&quot;, &quot;(?&lt;=&lt;title&gt;)my homepage(?=&lt;/title&gt;)&quot;) #&gt; [1] &quot;my homepage&quot; Additionally, (?=) and (?&lt;=) are known as positive lookahead and lookback. A lesser used version is the negative form of those two operators, looking for text that does not match the specified pattern. class description (?=) positive lookahead (?!) negative lookahead (?&lt;=) positive lookbehind (?&lt;!) negative lookbehind Suppose we want to extract just the quantities but not the prices in the followin text: text &lt;- c(&quot;I paid $30 for 100 apples, 50 oranges, and 60 pears. I saved $5 on this order.&quot;) # without word boundary, 0 after 3 as in $30 will be included str_view_all(text, &quot;\\\\b(?&lt;!\\\\$)\\\\d+\\\\b&quot;) "],
["backreferences.html", "A.4 Backreferences", " A.4 Backreferences Backreferences are used to overcome the problem that one match has no knowledge of its previous match, appearing as a pair of a subexpression and a \\number referencing to that subexpression. Find all repeated words (often typos): text &lt;- &quot;This is a block of of text, several words here are are repeated, and and they should not be.&quot; str_view_all(text, &quot;(\\\\w+) \\\\1&quot;) Another example with html data where we want to match all normal header tags, note that the last pair &lt;h2&gt;...&lt;h3&gt; is invalid: text &lt;- &quot;&lt;BODY&gt; &lt;H1&gt;Welcome to my Homepage&lt;/H1&gt; Content is divided into two sections:&lt;BR&gt; &lt;H2&gt;ColdFusion&lt;/H2&gt; Information about Macromedia ColdFusion. &lt;H2&gt;Wireless&lt;/H2&gt; Information about Bluetooth, 802.11, and more. &lt;H2&gt;This is not valid HTML&lt;/H3&gt; &lt;/BODY&gt;&quot; str_extract_all(text, &quot;&lt;[Hh](\\\\d)&gt;.+&lt;/[Hh]\\\\1&gt;&quot;) #&gt; [[1]] #&gt; [1] &quot;&lt;H1&gt;Welcome to my Homepage&lt;/H1&gt;&quot; &quot;&lt;H2&gt;ColdFusion&lt;/H2&gt;&quot; #&gt; [3] &quot;&lt;H2&gt;Wireless&lt;/H2&gt;&quot; Backreferences is particularly useful when performing replace operations. text &lt;- &quot;user@gmail.com is my email address&quot; str_replace(text, &quot;(.+@.+\\\\.com)&quot;, &quot;&lt;a href: \\\\1&gt;\\\\1&lt;a&gt;&quot;) #&gt; [1] &quot;&lt;a href: user@gmail.com&gt;user@gmail.com&lt;a&gt; is my email address&quot; "],
["text-processing-examples-in-r.html", "B Text processing examples in R", " B Text processing examples in R A manual of problem-solving techniques in some common use cases dealing with text data, employing tools like stringr and textclean "],
["replacing-and-removing.html", "B.1 Replacing and removing", " B.1 Replacing and removing "],
["combining-and-splitting.html", "B.2 Combining and splitting", " B.2 Combining and splitting Combine multiple line tokens to one paragraph (with a defined length) and the other way around library(ggpage) tinderbox_line &lt;- head(tinderbox) tinderbox_paragraph &lt;- head(tinderbox_paragraph) # combine all six rows into a paragraph tinderbox_line %&gt;% summarize(paragraph = str_c(text, collapse = &quot; &quot;)) #&gt; # A tibble: 1 x 1 #&gt; paragraph #&gt; &lt;chr&gt; #&gt; 1 &quot;A soldier came marching along the high road: \\&quot;Left, right - left, right.\\&quot; ~ # split one paragraph into multiple rows # ggpage::nest_paragraphs() extends str_wrap() tinderbox_paragraph %&gt;% mutate(paragraph_length = str_length(text)) %&gt;% nest_paragraphs(text, width = 50) # no more than 50 characters per row #&gt; text paragraph_length #&gt; 1 A soldier came marching along the high road: 480 #&gt; 2 &quot;Left, right - left, right.&quot; He had his knapsack 480 #&gt; 3 on his back, and a sword at his side; he had been 480 #&gt; 4 to the wars, and was now returning home. As he 480 #&gt; 5 walked on, he met a very frightful-looking old 480 #&gt; 6 witch in the road. Her under-lip hung quite down 480 #&gt; 7 on her breast, and she stopped and said, &quot;Good 480 #&gt; 8 evening, soldier; you have a very fine sword, and 480 #&gt; 9 a large knapsack, and you are a real soldier; so 480 #&gt; 10 you shall have as much money as ever you like.&quot; 480 #&gt; 11 &quot;Thank you, old witch,&quot; said the soldier. &quot;Do you 2073 #&gt; 12 see that large tree,&quot; said the witch, pointing to 2073 #&gt; 13 a tree which stood beside them. &quot;Well, it is quite 2073 #&gt; 14 hollow inside, and you must climb to the top, 2073 #&gt; 15 when you will see a hole, through which you can 2073 #&gt; 16 let yourself down into the tree to a great depth. 2073 #&gt; 17 I will tie a rope round your body, so that I can 2073 #&gt; 18 pull you up again when you call out to me.&quot; &quot;But 2073 #&gt; 19 what am I to do, down there in the tree?&quot; asked 2073 #&gt; 20 the soldier. &quot;Get money,&quot; she replied; &quot;for you 2073 #&gt; 21 must know that when you reach the ground under 2073 #&gt; 22 the tree, you will find yourself in a large hall, 2073 #&gt; 23 lighted up by three hundred lamps; you will then 2073 #&gt; 24 see three doors, which can be easily opened, for 2073 #&gt; 25 the keys are in all the locks. On entering the 2073 #&gt; 26 first of the chambers, to which these doors lead, 2073 #&gt; 27 you will see a large chest, standing in the middle 2073 #&gt; 28 of the floor, and upon it a dog seated, with a 2073 #&gt; 29 pair of eyes as large as teacups. But you need 2073 #&gt; 30 not be at all afraid of him; I will give you my 2073 #&gt; 31 blue checked apron, which you must spread upon the 2073 #&gt; 32 floor, and then boldly seize hold of the dog, and 2073 #&gt; 33 place him upon it. You can then open the chest, 2073 #&gt; 34 and take from it as many pence as you please, they 2073 #&gt; 35 are only copper pence; but if you would rather 2073 #&gt; 36 have silver money, you must go into the second 2073 #&gt; 37 chamber. Here you will find another dog, with eyes 2073 #&gt; 38 as big as mill-wheels; but do not let that trouble 2073 #&gt; 39 you. Place him upon my apron, and then take what 2073 #&gt; 40 money you please. If, however, you like gold best, 2073 #&gt; 41 enter the third chamber, where there is another 2073 #&gt; 42 chest full of it. The dog who sits on this chest 2073 #&gt; 43 is very dreadful; his eyes are as big as a tower, 2073 #&gt; 44 but do not mind him. If he also is placed upon my 2073 #&gt; 45 apron, he cannot hurt you, and you may take from 2073 #&gt; 46 the chest what gold you will.&quot; &quot;This is not a bad 2073 #&gt; 47 story,&quot; said the soldier; &quot;but what am I to give 2073 #&gt; 48 you, you old witch? For, of course, you do not 2073 #&gt; 49 mean to tell me all this for nothing.&quot; &quot;No,&quot; said 2073 #&gt; 50 the witch; &quot;but I do not ask for a single penny. 2073 #&gt; 51 Only promise to bring me an old tinder-box, which 2073 #&gt; 52 my grandmother left behind the last time she went 2073 #&gt; 53 down there.&quot; 2073 #&gt; 54 &quot;Very well; I promise. Now tie the rope round my 798 #&gt; 55 body.&quot; &quot;Here it is,&quot; replied the witch; &quot;and here 798 #&gt; 56 is my blue checked apron.&quot; As soon as the rope 798 #&gt; 57 was tied, the soldier climbed up the tree, and 798 #&gt; 58 let himself down through the hollow to the ground 798 #&gt; 59 beneath; and here he found, as the witch had told 798 #&gt; 60 him, a large hall, in which many hundred lamps 798 #&gt; 61 were all burning. Then he opened the first door. 798 #&gt; 62 &quot;Ah!&quot; there sat the dog, with the eyes as large as 798 #&gt; 63 teacups, staring at him. &quot;You&#39;re a pretty fellow,&quot; 798 #&gt; 64 said the soldier, seizing him, and placing him 798 #&gt; 65 on the witch&#39;s apron, while he filled his pockets 798 #&gt; 66 from the chest with as many pieces as they would 798 #&gt; 67 hold. Then he closed the lid, seated the dog upon 798 #&gt; 68 it again, and walked into another chamber, and, 798 #&gt; 69 sure enough, there sat the dog with eyes as big as 798 #&gt; 70 mill-wheels. 798 #&gt; 71 &quot;You had better not look at me in that way,&quot; said 1797 #&gt; 72 the soldier; &quot;you will make your eyes water;&quot; and 1797 #&gt; 73 then he seated him also upon the apron, and opened 1797 #&gt; 74 the chest. But when he saw what a quantity of 1797 #&gt; 75 silver money it contained, he very quickly threw 1797 #&gt; 76 away all the coppers he had taken, and filled his 1797 #&gt; 77 pockets and his knapsack with nothing but silver. 1797 #&gt; 78 Then he went into the third room, and there the 1797 #&gt; 79 dog was really hideous; his eyes were, truly, as 1797 #&gt; 80 big as towers, and they turned round and round 1797 #&gt; 81 in his head like wheels. &quot;Good morning,&quot; said 1797 #&gt; 82 the soldier, touching his cap, for he had never 1797 #&gt; 83 seen such a dog in his life. But after looking 1797 #&gt; 84 at him more closely, he thought he had been civil 1797 #&gt; 85 enough, so he placed him on the floor, and opened 1797 #&gt; 86 the chest. Good gracious, what a quantity of gold 1797 #&gt; 87 there was! enough to buy all the sugar-sticks 1797 #&gt; 88 of the sweet-stuff women; all the tin soldiers, 1797 #&gt; 89 whips, and rocking-horses in the world, or even 1797 #&gt; 90 the whole town itself There was, indeed, an 1797 #&gt; 91 immense quantity. So the soldier now threw away 1797 #&gt; 92 all the silver money he had taken, and filled his 1797 #&gt; 93 pockets and his knapsack with gold instead; and 1797 #&gt; 94 not only his pockets and his knapsack, but even 1797 #&gt; 95 his cap and boots, so that he could scarcely walk. 1797 #&gt; 96 He was really rich now; so he replaced the dog on 1797 #&gt; 97 the chest, closed the door, and called up through 1797 #&gt; 98 the tree: &quot;Now pull me out, you old witch.&quot; &quot;Have 1797 #&gt; 99 you got the tinder-box?&quot; asked the witch. &quot;No; I 1797 #&gt; 100 declare I quite forgot it.&quot; So he went back and 1797 #&gt; 101 fetched the tinderbox, and then the witch drew him 1797 #&gt; 102 up out of the tree, and he stood again in the high 1797 #&gt; 103 road, with his pockets, his knapsack, his cap, and 1797 #&gt; 104 his boots full of gold. &quot;What are you going to do 1797 #&gt; 105 with the tinder-box?&quot; asked the soldier. &quot;That is 1797 #&gt; 106 nothing to you,&quot; replied the witch; &quot;you have the 1797 #&gt; 107 money, now give me the tinder-box.&quot; 1797 #&gt; 108 &quot;I tell you what,&quot; said the soldier, &quot;if you don&#39;t 2188 #&gt; 109 tell me what you are going to do with it, I will 2188 #&gt; 110 draw my sword and cut off your head.&quot; &quot;No,&quot; said 2188 #&gt; 111 the witch. The soldier immediately cut off her 2188 #&gt; 112 head, and there she lay on the ground. Then he 2188 #&gt; 113 tied up all his money in her apron, and slung it 2188 #&gt; 114 on his back like a bundle, put the tinderbox in 2188 #&gt; 115 his pocket, and walked off to the nearest town. 2188 #&gt; 116 It was a very nice town, and he put up at the best 2188 #&gt; 117 inn, and ordered a dinner of all his favourite 2188 #&gt; 118 dishes, for now he was rich and had plenty of 2188 #&gt; 119 money. The servant, who cleaned his boots, thought 2188 #&gt; 120 they certainly were a shabby pair to be worn by 2188 #&gt; 121 such a rich gentleman, for he had not yet bought 2188 #&gt; 122 any new ones. The next day, however, he procured 2188 #&gt; 123 some good clothes and proper boots, so that our 2188 #&gt; 124 soldier soon became known as a fine gentleman, 2188 #&gt; 125 and the people visited him, and told him all the 2188 #&gt; 126 wonders that were to be seen in the town, and 2188 #&gt; 127 of the king&#39;s beautiful daughter, the princess. 2188 #&gt; 128 &quot;Where can I see her?&quot; asked the soldier. &quot;She 2188 #&gt; 129 is not to be seen at all,&quot; they said; &quot;she lives 2188 #&gt; 130 in a large copper castle, surrounded by walls and 2188 #&gt; 131 towers. No one but the king himself can pass in 2188 #&gt; 132 or out, for there has been a prophecy that she 2188 #&gt; 133 will marry a common soldier, and the king cannot 2188 #&gt; 134 bear to think of such a marriage.&quot; &quot;I should like 2188 #&gt; 135 very much to see her,&quot; thought the soldier; but he 2188 #&gt; 136 could not obtain permission to do so. However, he 2188 #&gt; 137 passed a very pleasant time; went to the theatre, 2188 #&gt; 138 drove in the king&#39;s garden, and gave a great deal 2188 #&gt; 139 of money to the poor, which was very good of him; 2188 #&gt; 140 he remembered what it had been in olden times to 2188 #&gt; 141 be without a shilling. Now he was rich, had fine 2188 #&gt; 142 clothes, and many friends, who all declared he was 2188 #&gt; 143 a fine fellow and a real gentleman, and all this 2188 #&gt; 144 gratified him exceedingly. But his money would 2188 #&gt; 145 not last forever; and as he spent and gave away 2188 #&gt; 146 a great deal daily, and received none, he found 2188 #&gt; 147 himself at last with only two shillings left. So 2188 #&gt; 148 he was obliged to leave his elegant rooms, and 2188 #&gt; 149 live in a little garret under the roof, where he 2188 #&gt; 150 had to clean his own boots, and even mend them 2188 #&gt; 151 with a large needle. None of his friends came to 2188 #&gt; 152 see him, there were too many stairs to mount up. 2188 #&gt; 153 One dark evening, he had not even a penny to buy a 1191 #&gt; 154 candle; then all at once he remembered that there 1191 #&gt; 155 was a piece of candle stuck in the tinder-box, 1191 #&gt; 156 which he had brought from the old tree, into which 1191 #&gt; 157 the witch had helped him. He found the tinder- 1191 #&gt; 158 box, but no sooner had he struck a few sparks from 1191 #&gt; 159 the flint and steel, than the door flew open and 1191 #&gt; 160 the dog with eyes as big as teacups, whom he had 1191 #&gt; 161 seen while down in the tree, stood before him, 1191 #&gt; 162 and said, &quot;What orders, master?&quot; &quot;Hallo,&quot; said 1191 #&gt; 163 the soldier; &quot;well this is a pleasant tinderbox, 1191 #&gt; 164 if it brings me all I wish for.&quot; - &quot;Bring me 1191 #&gt; 165 some money,&quot; said he to the dog. He was gone in a 1191 #&gt; 166 moment, and presently returned, carrying a large 1191 #&gt; 167 bag of coppers in his month. The soldier very soon 1191 #&gt; 168 discovered after this the value of the tinder- 1191 #&gt; 169 box. If he struck the flint once, the dog who sat 1191 #&gt; 170 on the chest of copper money made his appearance; 1191 #&gt; 171 if twice, the dog came from the chest of silver; 1191 #&gt; 172 and if three times, the dog with eyes like towers, 1191 #&gt; 173 who watched over the gold. The soldier had now 1191 #&gt; 174 plenty of money; he returned to his elegant rooms, 1191 #&gt; 175 and reappeared in his fine clothes, so that his 1191 #&gt; 176 friends knew him again directly, and made as much 1191 #&gt; 177 of him as before. 1191 "],
["extracting-text-from-pdf-and-other-files.html", "B.3 Extracting text from pdf and other files", " B.3 Extracting text from pdf and other files library(pdftools) download.file(&quot;http://arxiv.org/pdf/1403.2805.pdf&quot;, &quot;data/1403.2805.pdf&quot;, mode = &quot;wb&quot;) txt &lt;- pdf_text(&quot;data/1403.2805.pdf&quot;) # all 29 pages length(txt) #&gt; [1] 29 cat(txt[[2]]) #&gt; JSON with R. We refer to Nolan and Temple Lang (2014) for a comprehensive introduction, or one of the #&gt; many tutorials available on the web. Instead we take a high level view and discuss how R data structures are #&gt; most naturally represented in JSON. This is not a trivial problem, particulary for complex or relational data #&gt; as they frequently appear in statistical applications. Several R packages implement toJSON and fromJSON #&gt; functions which directly convert R objects into JSON and vice versa. However, the exact mapping between #&gt; the various R data classes JSON structures is not self evident. Currently, there are no formal guidelines, #&gt; or even consensus between implementations on how R data should be represented in JSON. Furthermore, #&gt; upon closer inspection, even the most basic data structures in R actually do not perfectly map to their #&gt; JSON counterparts, and leave some ambiguity for edge cases. These problems have resulted in different #&gt; behavior between implementations, and can lead to unexpected output for certain special cases. To further #&gt; complicate things, best practices of representing data in JSON have been established outside the R community. #&gt; Incorporating these conventions where possible is important to maximize interoperability. #&gt; 1.1 Parsing and type safety #&gt; The JSON format specifies 4 primitive types (string, number, boolean, null) and two universal structures: #&gt; • A JSON object : an unordered collection of zero or more name/value pairs, where a name is a string and #&gt; a value is a string, number, boolean, null, object, or array. #&gt; • A JSON array: an ordered sequence of zero or more values. #&gt; Both these structures are heterogeneous; i.e. they are allowed to contain elements of different types. There- #&gt; fore, the native R realization of these structures is a named list for JSON objects, and unnamed list for #&gt; JSON arrays. However, in practice a list is an awkward, inefficient type to store and manipulate data in R. #&gt; Most statistical applications work with (homogeneous) vectors, matrices or data frames. In order to give #&gt; these data structures a JSON representation, we can define certain special cases of JSON structures which get #&gt; parsed into other, more specific R types. For example, one convention which all current implementations #&gt; have in common is that a homogeneous array of primitives gets parsed into an atomic vector instead of a #&gt; list. The RJSONIO documentation uses the term “simplify” for this, and we adopt this jargon. #&gt; txt &lt;- &quot;[12, 3, 7]&quot; #&gt; x &lt;- fromJSON(txt) #&gt; is(x) #&gt; [1] &quot;numeric&quot; &quot;vector&quot; #&gt; print(x) #&gt; [1] 12 3 7 #&gt; This seems very reasonable and it is the only practical solution to represent vectors in JSON. However the #&gt; price we pay is that automatic simplification can compromise type-safety in the context of dynamic data. #&gt; For example, suppose an R package uses fromJSON to pull data from a JSON API on the web, similar to #&gt; the example above. However, for some particular combination of parameters, the result includes a null #&gt; value, e.g: [12, null, 7]. This is actually quite common, many APIs use null for missing values or unset #&gt; fields. This case makes the behavior of parsers ambiguous, because the JSON array is technically no longer #&gt; 2 enframe(txt) %&gt;% rename(page = name) %&gt;% nest_paragraphs(input = value, width = 100) #&gt; text #&gt; 1 The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects Jeroen Ooms #&gt; 2 arXiv:1403.2805v1 [stat.CO] 12 Mar 2014 UCLA Department of Statistics Abstract A naive realization #&gt; 3 of JSON data in R maps JSON arrays to an unnamed list, and JSON objects to a named list. However, #&gt; 4 in practice a list is an awkward, inefficient type to store and manipulate data. Most statistical #&gt; 5 applications work with (homogeneous) vectors, matrices or data frames. Therefore JSON packages in #&gt; 6 R typically define certain special cases of JSON structures which map to simpler R types. Currently #&gt; 7 there exist no formal guidelines, or even consensus between implementations on how R data should #&gt; 8 be represented in JSON. Furthermore, upon closer inspection, even the most basic data structures #&gt; 9 in R actually do not perfectly map to their JSON counterparts and leave some ambiguity for edge #&gt; 10 cases. These problems have resulted in different behavior between implementations and can lead #&gt; 11 to unexpected output. This paper explicitly describes a mapping between R classes and JSON data, #&gt; 12 highlights potential problems, and proposes conventions that generalize the mapping to cover all #&gt; 13 common structures. We emphasize the importance of type consistency when using JSON to exchange #&gt; 14 dynamic data, and illustrate using examples and anecdotes. The jsonlite R package is used throughout #&gt; 15 the paper as a reference implementation. 1 Introduction JavaScript Object Notation (JSON) is a text #&gt; 16 format for the serialization of structured data (Crockford, 2006a). It is derived from the object #&gt; 17 literals of JavaScript, as defined in the ECMAScript Programming Language Standard, Third Edition #&gt; 18 (ECMA, 1999). Design of JSON is simple and concise in comparison with other text based formats, #&gt; 19 and it was originally proposed by Douglas Crockford as a “fat-free alternative to XML” (Crockford, #&gt; 20 2006b). The syntax is easy for humans to read and write, easy for machines to parse and generate #&gt; 21 and completely described in a single page at http://www.json.org. The character encoding of JSON #&gt; 22 text is always Unicode, using UTF-8 by default (Crockford, 2006a), making it naturally compatible #&gt; 23 with non- latin alphabets. Over the past years, JSON has become hugely popular on the internet as #&gt; 24 a general purpose data interchange format. High quality parsing libraries are available for almost #&gt; 25 any programming language, making it easy to implement systems and applications that exchange data #&gt; 26 over the network using JSON. For R (R Core Team, 2013), several packages that assist the user in #&gt; 27 generating, parsing and validating JSON are available through CRAN, including rjson (Couture-Beil, #&gt; 28 2013), RJSONIO (Lang, 2013), and jsonlite (Ooms et al., 2014). The emphasis of this paper is not on #&gt; 29 discussing the JSON format or any particular implementation for using 1 #&gt; 30 JSON with R. We refer to Nolan and Temple Lang (2014) for a comprehensive introduction, or one of #&gt; 31 the many tutorials available on the web. Instead we take a high level view and discuss how R data #&gt; 32 structures are most naturally represented in JSON. This is not a trivial problem, particulary for #&gt; 33 complex or relational data as they frequently appear in statistical applications. Several R packages #&gt; 34 implement toJSON and fromJSON functions which directly convert R objects into JSON and vice versa. #&gt; 35 However, the exact mapping between the various R data classes JSON structures is not self evident. #&gt; 36 Currently, there are no formal guidelines, or even consensus between implementations on how R #&gt; 37 data should be represented in JSON. Furthermore, upon closer inspection, even the most basic data #&gt; 38 structures in R actually do not perfectly map to their JSON counterparts, and leave some ambiguity #&gt; 39 for edge cases. These problems have resulted in different behavior between implementations, and can #&gt; 40 lead to unexpected output for certain special cases. To further complicate things, best practices #&gt; 41 of representing data in JSON have been established outside the R community. Incorporating these #&gt; 42 conventions where possible is important to maximize interoperability. 1.1 Parsing and type safety #&gt; 43 The JSON format specifies 4 primitive types (string, number, boolean, null) and two universal #&gt; 44 structures: • A JSON object : an unordered collection of zero or more name/value pairs, where #&gt; 45 a name is a string and a value is a string, number, boolean, null, object, or array. • A JSON #&gt; 46 array: an ordered sequence of zero or more values. Both these structures are heterogeneous; i.e. #&gt; 47 they are allowed to contain elements of different types. There- fore, the native R realization of #&gt; 48 these structures is a named list for JSON objects, and unnamed list for JSON arrays. However, in #&gt; 49 practice a list is an awkward, inefficient type to store and manipulate data in R. Most statistical #&gt; 50 applications work with (homogeneous) vectors, matrices or data frames. In order to give these #&gt; 51 data structures a JSON representation, we can define certain special cases of JSON structures #&gt; 52 which get parsed into other, more specific R types. For example, one convention which all current #&gt; 53 implementations have in common is that a homogeneous array of primitives gets parsed into an atomic #&gt; 54 vector instead of a list. The RJSONIO documentation uses the term “simplify” for this, and we adopt #&gt; 55 this jargon. txt &lt;- &quot;[12, 3, 7]&quot; x &lt;- fromJSON(txt) is(x) [1] &quot;numeric&quot; &quot;vector&quot; print(x) [1] 12 #&gt; 56 3 7 This seems very reasonable and it is the only practical solution to represent vectors in JSON. #&gt; 57 However the price we pay is that automatic simplification can compromise type-safety in the context #&gt; 58 of dynamic data. For example, suppose an R package uses fromJSON to pull data from a JSON API on #&gt; 59 the web, similar to the example above. However, for some particular combination of parameters, the #&gt; 60 result includes a null value, e.g: [12, null, 7]. This is actually quite common, many APIs use null #&gt; 61 for missing values or unset fields. This case makes the behavior of parsers ambiguous, because the #&gt; 62 JSON array is technically no longer 2 #&gt; 63 homogenous. And indeed, some implementations will now return a list instead of a vector. If the #&gt; 64 user had not anticipated this scenario and the script assumes a vector, the code is likely to #&gt; 65 run into type errors. The lesson here is that we need to be very specific and explicit about the #&gt; 66 mapping that is implemented to convert between JSON and R objects. When relying on JSON as a data #&gt; 67 interchange format, the behavior of the parser must be consistent and unambiguous. Clients relying #&gt; 68 on JSON to get data in and out of R must know exactly what to expect in order to facilitate reliable #&gt; 69 communication, even if the data themselves are dynamic. Similarly, R code using dynamic JSON data #&gt; 70 from an external source is only reliable when the conversion from JSON to R is consistent. Moreover #&gt; 71 a practical mapping must incorporate existing conventions and uses the most natural representation #&gt; 72 of certain structures in R. For example, we could argue that instead of falling back on a list, #&gt; 73 the array above is more naturally interpreted as a numeric vector where the null becomes a missing #&gt; 74 value (NA). These principles will extrapolate as we start discussing more complex JSON structures #&gt; 75 representing matrices and data frames. 1.2 Reference implementation: the jsonlite package The #&gt; 76 jsonlite package provides a reference implementation of the conventions proposed in this document. #&gt; 77 jsonlite is a fork of the RJSONIO package by Duncan Temple Lang, which again builds on libjson C++ #&gt; 78 library from Jonathan Wallace. The jsonlite package uses the parser from RJSONIO, but the R code has #&gt; 79 been rewritten from scratch. Both packages implement toJSON and fromJSON functions, but their output #&gt; 80 is quite different. Finally, the jsonlite package contains a large set of unit tests to validate #&gt; 81 that R objects are correctly converted to JSON and vice versa. These unit tests cover all classes #&gt; 82 and edge cases mentioned in this document, and could be used to validate if other implementations #&gt; 83 follow the same conventions. library(testthat) test_package(&quot;jsonlite&quot;) Note that even though JSON #&gt; 84 allows for inserting arbitrary white space and indentation, the unit tests assume that white space #&gt; 85 is trimmed. 1.3 Class-based versus type-based encoding The jsonlite package actually implements #&gt; 86 two systems for translating between R objects and JSON. This document focuses on the toJSON and #&gt; 87 fromJSON functions which use R’s class-based method dispatch. For all of the common classes in #&gt; 88 R, the jsonlite package implements toJSON methods as described in this doc- ument. Users in R #&gt; 89 can extend this system by implementing additional methods for other classes. However this also #&gt; 90 means that classes that do not have the toJSON method defined are not supported. Furthermore, the #&gt; 91 implementation of a specific toJSON method determines which data and metadata in the objects of this #&gt; 92 class gets encoded in its JSON representation, and how. In this respect, toJSON is similar to e.g. #&gt; 93 the print function, which also provides a certain representation of an object based on its class and #&gt; 94 option- ally some print parameters. This representation does not necessarily reflect all information #&gt; 95 stored in the object, and there is no guaranteed one-to-one correspondence between R objects and #&gt; 96 JSON. I.e. calling fromJSON(toJSON(object)) will return an object which only contains the data that #&gt; 97 was encoded by the toJSON method for this particular class, and which might even have a different #&gt; 98 class than the original. 3 #&gt; 99 The alternative to class-based method dispatch is to use type-based encoding, which jsonlite #&gt; 100 implements in the functions serializeJSON and unserializeJSON. All data structures in R get stored #&gt; 101 in memory using one of the internal SEXP storage types, and serializeJSON defines an encoding #&gt; 102 schema which captures the type, value, and attributes for each storage type. The result is JSON #&gt; 103 output which closely resembles the internal structure of the underlying C data types, and which #&gt; 104 can be perfectly restored to the original R object using unserializeJSON. This system is relatively #&gt; 105 straightforward to implement, however the disadvantage is that the resulting JSON is very verbose, #&gt; 106 hard to interpret, and cumbersome to generate in the context of another language or system. For #&gt; 107 most applications this is actually impractical because it requires the client/consumer to understand #&gt; 108 and manipulate R data types, which is difficult and reduces interoperability. Instead we can make #&gt; 109 data in R more accessible to third parties by defining sensible JSON representations that are #&gt; 110 natural for the class of an object, rather than its internal storage type. This document does not #&gt; 111 discuss the serializeJSON system in any further detail, and solely treats the class based system #&gt; 112 implemented in toJSON and fromJSON. However the reader that is interested in full serialization #&gt; 113 of R objects into JSON is encouraged to have a look at the respective manual pages. 1.4 Scope and #&gt; 114 limitations Before continuing, we want to stress some limitations of encoding R data structures in #&gt; 115 JSON. Most impor- tantly, there are the limitations to types of objects that can be represented. #&gt; 116 In general, temporary in-memory properties such as connections, file descriptors and (recursive) #&gt; 117 memory references are always difficult if not impossible to store in a sensible way, regardless #&gt; 118 of the language or serialization method. This document focuses on the common R classes that hold #&gt; 119 data, such as vectors, factors, lists, matrices and data frames. We do not treat language level #&gt; 120 constructs such as expressions, functions, promises, which hold little meaning outside the context #&gt; 121 of R. We also don’t treat special compound classes such as linear models or custom classes defined #&gt; 122 in contributed packages. When designing systems or protocols that interact with R, it is highly #&gt; 123 recommended to stick with the standard data structures for the interface input/output. Then there #&gt; 124 are limitations introduced by the format. Because JSON is a human readable, text-based format, it #&gt; 125 does not support binary data, and numbers are stored in their decimal notation. The latter leads to #&gt; 126 loss of precision for real numbers, depending on how many digits the user decides to print. Several #&gt; 127 dialects of JSON exists such as BSON (Chodorow, 2013) or MSGPACK (Furuhashi, 2014), which extend the #&gt; 128 format with various binary types. However, these formats are much less popular, less interoperable, #&gt; 129 and often impractical, precisely because they require binary parsing and abandon human readability. #&gt; 130 The simplicity of JSON is what makes it an accessible and widely applicable data interchange format. #&gt; 131 In cases where it is really needed to include some binary data in JSON, one can use something like #&gt; 132 base64 to encode it as a string. Finally, as mentioned earlier, fromJSON is not a perfect inverse #&gt; 133 function of toJSON, as would be the case for serialializeJSON and unserializeJSON. The class based #&gt; 134 mappings are designed for concise and practical encoding of the various common data structures. Our #&gt; 135 implementation of toJSON and fromJSON approxi- mates a reversible mapping between R objects and JSON #&gt; 136 for the standard data classes, but there are always limitations and edge cases. For example, the #&gt; 137 JSON representation of an empty vector, empty list or empty data frame are all the same: &quot;[ ]&quot;. Also #&gt; 138 some special vector types such as factors, dates or timestamps get coerced to strings, as they would #&gt; 139 in for example CSV. This is a quite typical and expected behavior among text based formats, but it #&gt; 140 does require some additional interpretation on the consumer side. 4 #&gt; 141 2 Converting between JSON and R classes This section lists examples of how the common R classes #&gt; 142 are represented in JSON. As explained before, the toJSON function relies on method dispatch, which #&gt; 143 means that objects get encoded according to their class. If an object has multiple class values, R #&gt; 144 uses the first occurring class which has a toJSON method. If none of the classes of an object has #&gt; 145 a toJSON method, an error is raised. 2.1 Atomic vectors The most basic data type in R is the atomic #&gt; 146 vector. The atomic vector holds an ordered set of homogeneous values of type &quot;logical&quot; (booleans), #&gt; 147 character (strings), &quot;raw&quot; (bytes), numeric (doubles), &quot;complex&quot; (complex numbers with a real and #&gt; 148 imaginary part), or integer. Because R is fully vectorized, there is no user level notion of a #&gt; 149 primitive: a scalar value is considered a vector of length 1. Atomic vectors map to JSON arrays: #&gt; 150 x &lt;- c(1, 2, pi) cat(toJSON(x)) [ 1, 2, 3.14 ] The JSON array is the only appropriate structure #&gt; 151 to encode a vector, however note that vectors in R are homogeneous, whereas the JSON array is #&gt; 152 actually heterogeneous, but JSON does not make this distinction. 2.1.1 Missing values A typical #&gt; 153 domain specific problem when working with statistical data is presented by missing values: a concept #&gt; 154 foreign to many other languages. Besides regular values, each vector type in R except for raw can #&gt; 155 hold NA as a value. Vectors of type double and complex define three additional types of non finite #&gt; 156 values: NaN, Inf and -Inf. The JSON format does not natively support any of these types; therefore #&gt; 157 such values values need to be encoded in some other way. There are two obvious approaches. The first #&gt; 158 one is to use the JSON null type. For example: x &lt;- c(TRUE, FALSE, NA) cat(toJSON(x)) [ true, false, #&gt; 159 null ] The other option is to encode missing values as strings by wrapping them in double quotes: x #&gt; 160 &lt;- c(1, 2, NA, NaN, Inf, 10) cat(toJSON(x)) [ 1, 2, &quot;NA&quot;, &quot;NaN&quot;, &quot;Inf&quot;, 10 ] Both methods result in #&gt; 161 valid JSON, but both have a limitation: the problem with the null type is that it is impossible to #&gt; 162 distinguish between different types of missing data, which could be a problem for numeric vectors. #&gt; 163 The values Inf, -Inf, NA and NaN carry different meanings, and these should not get lost in the 5 #&gt; 164 encoding. However, the problem with encoding missing values as strings is that this method can #&gt; 165 not be used for character vectors, because the consumer won’t be able to distinguish the actual #&gt; 166 string &quot;NA&quot; and the missing value NA. This would create a likely source of bugs, where clients #&gt; 167 mistakenly interpret &quot;NA&quot; as an actual value, which is a common problem with text-based formats #&gt; 168 such as CSV. For this reason, jsonlite uses the following defaults: • Missing values in non- #&gt; 169 numeric vectors (logical, character) are encoded as null. • Missing values in numeric vectors #&gt; 170 (double, integer, complex) are encoded as strings. We expect that these conventions are most #&gt; 171 likely to result in the correct interpretation of missing values. Some examples: cat(toJSON(c(TRUE, #&gt; 172 NA, NA, FALSE))) [ true, null, null, false ] cat(toJSON(c(&quot;FOO&quot;, &quot;BAR&quot;, NA, &quot;NA&quot;))) [ &quot;FOO&quot;, #&gt; 173 &quot;BAR&quot;, null, &quot;NA&quot; ] cat(toJSON(c(3.14, NA, NaN, 21, Inf, -Inf))) [ 3.14, &quot;NA&quot;, &quot;NaN&quot;, 21, &quot;Inf&quot;, #&gt; 174 &quot;-Inf&quot; ] cat(toJSON(c(3.14, NA, NaN, 21, Inf, -Inf), na = &quot;null&quot;)) [ 3.14, null, null, 21, #&gt; 175 null, null ] 2.1.2 Special vector types: dates, times, factor, complex Besides missing values, #&gt; 176 JSON also lacks native support for some of the basic vector types in R that frequently appear #&gt; 177 in data sets. These include vectors of class Date, POSIXt (timestamps), factors and complex #&gt; 178 vectors. By default, the jsonlite package coerces these types to strings (using as.character): #&gt; 179 cat(toJSON(Sys.time() + 1:3)) [ &quot;2014-03-11 21:16:05&quot;, &quot;2014-03-11 21:16:06&quot;, &quot;2014-03-11 #&gt; 180 21:16:07&quot; ] cat(toJSON(as.Date(Sys.time()) + 1:3)) [ &quot;2014-03-13&quot;, &quot;2014-03-14&quot;, &quot;2014-03-15&quot; ] #&gt; 181 cat(toJSON(factor(c(&quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;)))) [ &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot; ] cat(toJSON(complex(real = #&gt; 182 runif(3), imaginary = rnorm(3)))) [ &quot;0.5+1.7i&quot;, &quot;0-2i&quot;, &quot;0.37-0.13i&quot; ] When parsing such JSON #&gt; 183 strings, these values will appear as character vectors. In order to obtain the original types, the #&gt; 184 user needs to manually coerce them back to the desired type using the corresponding as function, #&gt; 185 e.g. as.POSIXct, as.Date, as.factor or as.complex. In this respect, JSON is subject to the same 6 #&gt; 186 limitations as text based formats such as CSV. 2.1.3 Special cases: vectors of length 0 or 1 Two #&gt; 187 edge cases deserve special attention: vectors of length 0 and vectors of length 1. In jsonlite #&gt; 188 these are encoded respectively as an empty array, and an array of length 1: # vectors of length #&gt; 189 0 and 1 cat(toJSON(vector())) [ ] cat(toJSON(pi)) [ 3.14 ] # vectors of length 0 and 1 in a named #&gt; 190 list cat(toJSON(list(foo = vector()))) { &quot;foo&quot; : [ ] } cat(toJSON(list(foo = pi))) { &quot;foo&quot; : #&gt; 191 [ 3.14 ] } # vectors of length 0 and 1 in an unnamed list cat(toJSON(list(vector()))) [ [ ] ] #&gt; 192 cat(toJSON(list(pi))) [ [ 3.14 ] ] This might seem obvious but these cases result in very different #&gt; 193 behavior between different JSON packages. This is probably caused by the fact that R does not have a #&gt; 194 scalar type, and some package authors decided to treat vectors of length 1 as if they were a scalar. #&gt; 195 For example, in the current implementations, both RJSONIO and rjson encode a vector of length #&gt; 196 one as a JSON primitive when it appears within a list: # Other packages make different choices: #&gt; 197 cat(rjson::toJSON(list(n = c(1)))) {&quot;n&quot;:1} cat(rjson::toJSON(list(n = c(1, 2)))) {&quot;n&quot;:[1,2]} When #&gt; 198 encoding a single dataset this seems harmless, but in the context of dynamic data this inconsistency #&gt; 199 is almost guaranteed to cause bugs. For example, imagine an R web service which lets the user fit #&gt; 200 a linear model and sends back the fitted parameter estimates as a JSON array. The client code then #&gt; 201 parses the JSON, and iterates over the array of coefficients to display them in a GUI. All goes #&gt; 202 well, until the user decides to fit a model with only one predictor. If the JSON encoder suddenly #&gt; 203 returns a primitive value where the client 7 #&gt; 204 is assuming an array, the application will likely break. Any consumer or client would need to be #&gt; 205 aware of the special case where the vector becomes a primitive, and explicitly take this exception #&gt; 206 into account when processing the result. When the client fails to do so and proceeds as usual, it #&gt; 207 will probably call an iterator or loop method on a primitive value, resulting in the obvious errors. #&gt; 208 For this reason jsonlite uses consistent encoding schemes which do not depend on variable object #&gt; 209 properties such as its length. Hence, a vector is always encoded as an array, even when it is of #&gt; 210 length 0 or 1. 2.2 Matrices Arguably one of the strongest sides of R is its ability to interface #&gt; 211 libraries for basic linear algebra subpro- grams (Lawson et al., 1979) such as LAPACK (Anderson #&gt; 212 et al., 1999). These libraries provide well tuned, high performance implementations of important #&gt; 213 linear algebra operations to calculate anything from inner products and eigen values to singular #&gt; 214 value decompositions. These are in turn the building blocks of statis- tical methods such as linear #&gt; 215 regression or principal component analysis. Linear algebra methods operate on matrices, making the #&gt; 216 matrix one of the most central data classes in R. Conceptually, a matrix consists of a 2 dimensional #&gt; 217 structure of homogeneous values. It is indexed using 2 numbers (or vectors), representing the row #&gt; 218 and column number of the matrix respectively. x &lt;- matrix(1:12, nrow = 3, ncol = 4) print(x) [,1] #&gt; 219 [,2] [,3] [,4] [1,] 1 4 7 10 [2,] 2 5 8 11 [3,] 3 6 9 12 print(x[2, 4]) [1] 11 A matrix is stored #&gt; 220 in memory as a single atomic vector with an attribute called &quot;dim&quot; defining the dimensions of the #&gt; 221 matrix. The product of the dimensions is equal to the length of the vector. attributes(volcano) $dim #&gt; 222 [1] 87 61 length(volcano) [1] 5307 Even though the matrix is stored as a single vector, the way it #&gt; 223 is printed and indexed makes it conceptually a 2 dimensional structure. In jsonlite a matrix maps to #&gt; 224 an array of equal-length subarrays: x &lt;- matrix(1:12, nrow = 3, ncol = 4) cat(toJSON(x)) [ [ 1, 4, #&gt; 225 7, 10 ], [ 2, 5, 8, 11 ], [ 3, 6, 9, 12 ] ] 8 #&gt; 226 We expect this representation will be the most intuitive to interpret, also within languages that #&gt; 227 do not have a native notion of a matrix. Note that even though R stores matrices in column major #&gt; 228 order, jsonlite encodes matrices in row major order. This is a more conventional and intuitive #&gt; 229 way to represent matrices and is consistent with the row-based encoding of data frames discussed #&gt; 230 in the next section. When the JSON string is properly indented (recall that white space and line #&gt; 231 breaks are optional in JSON), it looks very similar to the way R prints matrices: [ [ 1, 4, 7, 10 ], #&gt; 232 [ 2, 5, 8, 11 ], [ 3, 6, 9, 12 ] ] Because the matrix is implemented in R as an atomic vector, it #&gt; 233 automatically inherits the conventions mentioned earlier with respect to edge cases and missing #&gt; 234 values: x &lt;- matrix(c(1, 2, 4, NA), nrow = 2) cat(toJSON(x)) [ [ 1, 4 ], [ 2, &quot;NA&quot; ] ] cat(toJSON(x, #&gt; 235 na = &quot;null&quot;)) [ [ 1, 4 ], [ 2, null ] ] cat(toJSON(matrix(pi))) [ [ 3.14 ] ] 2.2.1 Matrix row and #&gt; 236 column names Besides the &quot;dim&quot; attribute, the matrix class has an additional, optional attribute: #&gt; 237 &quot;dimnames&quot;. This attribute holds names for the rows and columns in the matrix. However, we decided #&gt; 238 not to include this information in the default JSON mapping for matrices for several reasons. First #&gt; 239 of all, because this attribute is optional, often either row or column names or both are NULL. This #&gt; 240 makes it difficult to define a practical encoding that covers all cases with and without row and/ #&gt; 241 or column names. Secondly, the names in matrices are mostly there for annotation only; they are not #&gt; 242 actually used in calculations. The linear algebra subrou- tines mentioned before completely ignore #&gt; 243 them, and never include any names in their output. So there is often little purpose of setting names #&gt; 244 in the first place, other than annotation. When row or column names of a matrix seem to contain #&gt; 245 vital information, we might want to transform the data into a more appropriate structure. Wickham #&gt; 246 (2014) calls this “tidying” the data and outlines best practices on storing statistical data in #&gt; 247 its most appropriate form. He lists the issue where “column headers are values, not variable names” #&gt; 248 as the most common source of untidy data. This often happens when the structure is optimized for #&gt; 249 presentation (e.g. printing), rather than computation. In the following example taken from Wickham, #&gt; 250 the predictor variable (treatment) is stored in the column headers rather than the actual data. As #&gt; 251 a result, these values are not included in the JSON: x &lt;- matrix(c(NA, 1, 2, 5, NA, 3), nrow = 3) #&gt; 252 row.names(x) &lt;- c(&quot;Joe&quot;, &quot;Jane&quot;, &quot;Mary&quot;) 9 #&gt; 253 colnames(x) &lt;- c(&quot;Treatment A&quot;, &quot;Treatment B&quot;) print(x) Treatment A Treatment B Joe NA 5 Jane #&gt; 254 1 NA Mary 2 3 cat(toJSON(x)) [ [ &quot;NA&quot;, 5 ], [ 1, &quot;NA&quot; ], [ 2, 3 ] ] Wickham recommends that #&gt; 255 the data be melted into its tidy form. Once the data is tidy, the JSON encoding will naturally #&gt; 256 contain the treatment values: library(reshape2) y &lt;- melt(x, varnames = c(&quot;Subject&quot;, &quot;Treatment&quot;)) #&gt; 257 print(y) Subject Treatment value 1 Joe Treatment A NA 2 Jane Treatment A 1 3 Mary Treatment A #&gt; 258 2 4 Joe Treatment B 5 5 Jane Treatment B NA 6 Mary Treatment B 3 cat(toJSON(y, pretty = TRUE)) #&gt; 259 [ { &quot;Subject&quot; : &quot;Joe&quot;, &quot;Treatment&quot; : &quot;Treatment A&quot; }, { &quot;Subject&quot; : &quot;Jane&quot;, &quot;Treatment&quot; : &quot;Treatment #&gt; 260 A&quot;, &quot;value&quot; : 1 }, { &quot;Subject&quot; : &quot;Mary&quot;, &quot;Treatment&quot; : &quot;Treatment A&quot;, &quot;value&quot; : 2 }, { &quot;Subject&quot; : #&gt; 261 &quot;Joe&quot;, &quot;Treatment&quot; : &quot;Treatment B&quot;, 10 #&gt; 262 &quot;value&quot; : 5 }, { &quot;Subject&quot; : &quot;Jane&quot;, &quot;Treatment&quot; : &quot;Treatment B&quot; }, { &quot;Subject&quot; : &quot;Mary&quot;, #&gt; 263 &quot;Treatment&quot; : &quot;Treatment B&quot;, &quot;value&quot; : 3 } ] In some other cases, the column headers actually do #&gt; 264 contain variable names, and melting is inappropriate. For data sets with records consisting of a #&gt; 265 set of named columns (fields), R has more natural and flexible class: the data-frame. The toJSON #&gt; 266 method for data frames (described later) is more suitable when we want to refer to rows or fields #&gt; 267 by their name. Any matrix can easily be converted to a data-frame using the as.data.frame function: #&gt; 268 cat(toJSON(as.data.frame(x), pretty = TRUE)) [ { &quot;$row&quot; : &quot;Joe&quot;, &quot;Treatment B&quot; : 5 }, { &quot;$row&quot; : #&gt; 269 &quot;Jane&quot;, &quot;Treatment A&quot; : 1 }, { &quot;$row&quot; : &quot;Mary&quot;, &quot;Treatment A&quot; : 2, &quot;Treatment B&quot; : 3 } ] For some #&gt; 270 cases this results in the desired output, but in this example melting seems more appropriate. 2.3 #&gt; 271 Lists The list is the most general purpose data structure in R. It holds an ordered set of elements, #&gt; 272 including other lists, each of arbitrary type and size. Two types of lists are distinguished: named #&gt; 273 lists and unnamed lists. A list is considered a named list if it has an attribute called &quot;names&quot;. In #&gt; 274 practice, a named list is 11 #&gt; 275 any list for which we can access an element by its name, whereas elements of an unnamed lists can #&gt; 276 only be accessed using their index number: mylist1 &lt;- list(foo = 123, bar = 456) print(mylist1$bar) #&gt; 277 [1] 456 mylist2 &lt;- list(123, 456) print(mylist2[[2]]) [1] 456 2.3.1 Unnamed lists Just like vectors, #&gt; 278 an unnamed list maps to a JSON array: cat(toJSON(list(c(1, 2), &quot;test&quot;, TRUE, list(c(1, 2))))) [ [ 1, #&gt; 279 2 ], [ &quot;test&quot; ], [ true ], [ [ 1, 2 ] ] ] Note that even though both vectors and lists are encoded #&gt; 280 using JSON arrays, they can be distinguished from their contents: an R vector results in a JSON #&gt; 281 array containing only primitives, whereas a list results in a JSON array containing only objects #&gt; 282 and arrays. This allows the JSON parser to reconstruct the original type from encoded vectors and #&gt; 283 arrays: x &lt;- list(c(1, 2, NA), &quot;test&quot;, FALSE, list(foo = &quot;bar&quot;)) identical(fromJSON(toJSON(x)), #&gt; 284 x) [1] TRUE The only exception is the empty list and empty vector, which are both encoded as [ ] #&gt; 285 and therefore indistinguishable, but this is rarely a problem in practice. 2.3.2 Named lists A #&gt; 286 named list in R maps to a JSON object : cat(toJSON(list(foo = c(1, 2), bar = &quot;test&quot;))) { &quot;foo&quot; : #&gt; 287 [ 1, 2 ], &quot;bar&quot; : [ &quot;test&quot; ] } Because a list can contain other lists, this works recursively: #&gt; 288 cat(toJSON(list(foo=list(bar=list(baz=pi))))) { &quot;foo&quot; : { &quot;bar&quot; : { &quot;baz&quot; : [ 3.14 ] } } } Named #&gt; 289 lists map almost perfectly to JSON objects with one exception: list elements can have empty names: #&gt; 290 12 #&gt; 291 x &lt;- list(foo = 123, &quot;test&quot;, TRUE) attr(x, &quot;names&quot;) [1] &quot;foo&quot; &quot;&quot; &quot;&quot; x$foo [1] 123 x[[2]] [1] #&gt; 292 &quot;test&quot; In a JSON object, each element in an object must have a valid name. To ensure this property, #&gt; 293 jsonlite uses the same solution as the print method, which is to fall back on indices for elements #&gt; 294 that do not have a proper name: x &lt;- list(foo = 123, &quot;test&quot;, TRUE) print(x) $foo [1] 123 [[2]] [1] #&gt; 295 &quot;test&quot; [[3]] [1] TRUE cat(toJSON(x)) { &quot;foo&quot; : [ 123 ], &quot;2&quot; : [ &quot;test&quot; ], &quot;3&quot; : [ true ] } This #&gt; 296 behavior ensures that all generated JSON is valid, however named lists with empty names should #&gt; 297 be avoided where possible. When actually designing R objects that should be interoperable, it is #&gt; 298 recommended that each list element is given a proper name. 2.4 Data frame The data frame is perhaps #&gt; 299 the most central data structure in R from the user point of view. This class holds tabular data in #&gt; 300 which each column is named and (usually) homogeneous. Conceptually it is very similar to a table in #&gt; 301 relational data bases such as MySQL, where fields are referred to as column names, and records are #&gt; 302 called row names. Like a matrix, a data frame can be subsetted with two indices, to extract certain #&gt; 303 rows and columns of the data: is(iris) [1] &quot;data.frame&quot; &quot;list&quot; &quot;oldClass&quot; &quot;vector&quot; names(iris) 13 #&gt; 304 [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; [5] &quot;Species&quot; print(iris[1:3, c(1, #&gt; 305 5)]) Sepal.Length Species 1 5.1 setosa 2 4.9 setosa 3 4.7 setosa print(iris[1:3, c(&quot;Sepal.Width&quot;, #&gt; 306 &quot;Species&quot;)]) Sepal.Width Species 1 3.5 setosa 2 3.0 setosa 3 3.2 setosa For the previously discussed #&gt; 307 classes such as vectors and matrices, behavior of jsonlite is quite similar to the other available #&gt; 308 packages that implement toJSON and toJSON functions, with only minor differences for missing values #&gt; 309 and edge cases. But when it comes to data frames, jsonlite takes a completely different approach. #&gt; 310 The behavior of jsonlite is designed for compatibility with conventional ways of encoding table- #&gt; 311 like structures outside the R community. The implementation is more complex, but results in a #&gt; 312 powerful and more natural way of interfacing data frames through JSON and vice versa. 2.4.1 Column #&gt; 313 based versus row based tables Generally speaking, tabular data structures can be implemented in #&gt; 314 two different ways: in a column based, or row based fashion. A column based structure consists of a #&gt; 315 named collection of equal-length, homogeneous arrays representing the table columns. In a row-based #&gt; 316 structure on the other hand, the table is implemented as a set of heterogeneous associative arrays #&gt; 317 representing table rows with field values for each particular record. Even though most languages #&gt; 318 provide flexible and abstracted interfaces that hide such implementation details from the user, #&gt; 319 they can have huge implications for performance. A column based structure is efficient for inserting #&gt; 320 or extracting certain columns of the data, but it is inefficient for manipulating individual rows. #&gt; 321 For example to insert a single row somewhere in the middle, each of the columns has to be sliced #&gt; 322 and stitched back together. For row-based implementations, it is the exact other way around: we #&gt; 323 can easily manipulate a particular record, but to insert/extract a whole column we would need to #&gt; 324 iterate over all records in the table and read/modify the appropriate field in each of them. The #&gt; 325 data frame in R is implemented in a column based fashion: it constitutes of a named list of equal- #&gt; 326 length vectors. Thereby the columns in the data frame naturally inherit the properties from atomic #&gt; 327 vectors discussed before, such as homogeneity, missing values, etc. Another argument for column- #&gt; 328 based implementation is that statistical methods generally operate on columns. For example, the #&gt; 329 lm function fits a linear regression by extracting the columns from a data frame as specified by #&gt; 330 the formula argument. R simply binds the specified columns together into a matrix X and calls out #&gt; 331 to a highly optimized FORTRAN subroutine to calculate the OLS estimates ß^ = (X T X)X T y using #&gt; 332 the QR factorization of X. Many other statistical modeling functions follow similar steps, and are #&gt; 333 computationally efficient because of the column-based data storage 14 #&gt; 334 in R. However, unfortunately R is an exception in its preference for column-based storage: #&gt; 335 most languages, systems, databases, APIs, etc, are optimized for record based operations. For #&gt; 336 this reason, the conventional way to store and communicate tabular data in JSON seems to almost #&gt; 337 exclusively row based. This discrepancy presents various complications when converting between data #&gt; 338 frames and JSON. The remaining of this section discusses details and challenges of consistently #&gt; 339 mapping record based JSON data as frequently encountered on the web, into column-based data frames #&gt; 340 which are convenient for statistical computing. 2.4.2 Row based data frame encoding The encoding #&gt; 341 of data frames is one of the major differences between jsonlite and implementations from other #&gt; 342 currently available packages. Instead of using the column-based encoding also used for lists, #&gt; 343 jsonlite maps data frames by default to an array of records: cat(toJSON(iris[1:2, ], pretty #&gt; 344 = TRUE)) [ { &quot;Sepal.Length&quot; : 5.1, &quot;Sepal.Width&quot; : 3.5, &quot;Petal.Length&quot; : 1.4, &quot;Petal.Width&quot; : #&gt; 345 0.2, &quot;Species&quot; : &quot;setosa&quot; }, { &quot;Sepal.Length&quot; : 4.9, &quot;Sepal.Width&quot; : 3, &quot;Petal.Length&quot; : 1.4, #&gt; 346 &quot;Petal.Width&quot; : 0.2, &quot;Species&quot; : &quot;setosa&quot; } ] This output looks a bit like a list of named lists. #&gt; 347 However, there is one major difference: the individual records contain JSON primitives, whereas #&gt; 348 lists always contain JSON objects or arrays: cat(toJSON(list(list(Species = &quot;Foo&quot;, Width = 21)), #&gt; 349 pretty = TRUE)) [ { &quot;Species&quot; : [ &quot;Foo&quot; ], &quot;Width&quot; : [ 21 ] 15 #&gt; 350 } ] This leads to the following convention: when encoding R objects, JSON primitives only appear #&gt; 351 in vectors and data-frame rows. Primitive values within a JSON array indicate a vector, and JSON #&gt; 352 primitives appearing inside a JSON object indicate a data-frame row. A JSON encoded list, (named or #&gt; 353 unnamed) will never contain JSON primitives. This is a subtle but important convention that helps #&gt; 354 to distinguish between R classes from their JSON representation, without explicitly encoding any #&gt; 355 metadata. 2.4.3 Missing values in data frames The section on atomic vectors discussed two methods #&gt; 356 of encoding missing data appearing in a vector: either using strings or using the JSON null type. #&gt; 357 When a missing value appears in a data frame, there is a third option: simply not include this field #&gt; 358 in JSON record: x &lt;- data.frame(foo = c(FALSE, TRUE, NA, NA), bar = c(&quot;Aladdin&quot;, NA, NA, &quot;Mario&quot;)) #&gt; 359 print(x) foo bar 1 FALSE Aladdin 2 TRUE &lt;NA&gt; 3 NA &lt;NA&gt; 4 NA Mario cat(toJSON(x, pretty = TRUE)) #&gt; 360 [ { &quot;foo&quot; : false, &quot;bar&quot; : &quot;Aladdin&quot; }, { &quot;foo&quot; : true }, {}, { &quot;bar&quot; : &quot;Mario&quot; } ] The default #&gt; 361 behavior of jsonlite is to omit missing data from records in a data frame. This seems to be the #&gt; 362 most conventional method used on the web, and we expect this encoding will most likely lead to the #&gt; 363 correct interpretation of missingness, even in languages with no explicit notion of NA. 16 #&gt; 364 2.4.4 Relational data: nested records Nested datasets are somewhat unusual in R, but frequently #&gt; 365 encountered in JSON. Such structures do not really fit the vector based paradigm which makes #&gt; 366 them harder to manipulate in R. However, nested structures are too common in JSON to ignore, and #&gt; 367 with a little work most cases still map to a data frame quite nicely. The most common scenario #&gt; 368 is a dataset in which a certain field within each record contains a subrecord with additional #&gt; 369 fields. The jsonlite implementation maps these subrecords to a nested data frame. Whereas the #&gt; 370 data frame class usually consists of vectors, technically a column can also be list or another #&gt; 371 data frame with matching dimension (this stretches the meaning of the word “column” a bit): #&gt; 372 options(stringsAsFactors=FALSE) x &lt;- data.frame(driver = c(&quot;Bowser&quot;, &quot;Peach&quot;), occupation = #&gt; 373 c(&quot;Koopa&quot;, &quot;Princess&quot;)) x$vehicle &lt;- data.frame(model = c(&quot;Piranha Prowler&quot;, &quot;Royal Racer&quot;)) #&gt; 374 x$vehicle$stats &lt;- data.frame(speed = c(55, 34), weight = c(67, 24), drift = c(35, 32)) str(x) #&gt; 375 &#39;data.frame&#39;: 2 obs. of 3 variables: $ driver : chr &quot;Bowser&quot; &quot;Peach&quot; $ occupation: chr &quot;Koopa&quot; #&gt; 376 &quot;Princess&quot; $ vehicle :&#39;data.frame&#39;: 2 obs. of 2 variables: ..$ model: chr &quot;Piranha Prowler&quot; &quot;Royal #&gt; 377 Racer&quot; ..$ stats:&#39;data.frame&#39;: 2 obs. of 3 variables: .. ..$ speed : num 55 34 .. ..$ weight: num #&gt; 378 67 24 .. ..$ drift : num 35 32 cat(toJSON(x, pretty=TRUE)) [ { &quot;driver&quot; : &quot;Bowser&quot;, &quot;occupation&quot; : #&gt; 379 &quot;Koopa&quot;, &quot;vehicle&quot; : { &quot;model&quot; : &quot;Piranha Prowler&quot;, &quot;stats&quot; : { &quot;speed&quot; : 55, &quot;weight&quot; : 67, #&gt; 380 &quot;drift&quot; : 35 } } }, { &quot;driver&quot; : &quot;Peach&quot;, &quot;occupation&quot; : &quot;Princess&quot;, &quot;vehicle&quot; : { 17 #&gt; 381 &quot;model&quot; : &quot;Royal Racer&quot;, &quot;stats&quot; : { &quot;speed&quot; : 34, &quot;weight&quot; : 24, &quot;drift&quot; : 32 } } } ] myjson &lt;- #&gt; 382 toJSON(x) y &lt;- fromJSON(myjson) identical(x,y) [1] TRUE When encountering JSON data containing #&gt; 383 nested records on the web, chances are that these data were generated from relational database. #&gt; 384 The JSON field containing a subrecord represents a foreign key pointing to a record in an external #&gt; 385 table. For the purpose of encoding these into a single JSON structure, the tables were joined into #&gt; 386 a nested structure. The directly nested subrecord represents a one-to-one or many-to-one relation #&gt; 387 between the parent and child table, and is most naturally stored in R using a nested data frame. #&gt; 388 In the example above, the vehicle field points to a table of vehicles, which in turn contains a #&gt; 389 stats field pointing to a table of stats. When there is no more than one subrecord for each record, #&gt; 390 we easily flatten the structure into a single non-nested data frame. z &lt;- cbind(x[c(&quot;driver&quot;, #&gt; 391 &quot;occupation&quot;)], x$vehicle[&quot;model&quot;], x$vehicle$stats) str(z) &#39;data.frame&#39;: 2 obs. of 6 variables: $ #&gt; 392 driver : chr &quot;Bowser&quot; &quot;Peach&quot; $ occupation: chr &quot;Koopa&quot; &quot;Princess&quot; $ model : chr &quot;Piranha Prowler&quot; #&gt; 393 &quot;Royal Racer&quot; $ speed : num 55 34 $ weight : num 67 24 $ drift : num 35 32 2.4.5 Relational data: #&gt; 394 nested tables The one-to-one relation discussed above is relatively easy to store in R, because each #&gt; 395 record contains at most one subrecord. Therefore we can use either a nested data frame, or flatten #&gt; 396 the data frame. However, things get more difficult when JSON records contain a field with a nested #&gt; 397 array. Such a structure appears in relational data in case of a one-to-many relation. A standard #&gt; 398 textbook illustration is the relation between authors and titles. For example, a field can contain #&gt; 399 an array of values: 18 #&gt; 400 x &lt;- data.frame(author = c(&quot;Homer&quot;, &quot;Virgil&quot;, &quot;Jeroen&quot;)) x$poems &lt;- list(c(&quot;Iliad&quot;, &quot;Odyssey&quot;), #&gt; 401 c(&quot;Eclogues&quot;, &quot;Georgics&quot;, &quot;Aeneid&quot;), vector()); names(x) [1] &quot;author&quot; &quot;poems&quot; cat(toJSON(x, #&gt; 402 pretty = TRUE)) [ { &quot;author&quot; : &quot;Homer&quot;, &quot;poems&quot; : [ &quot;Iliad&quot;, &quot;Odyssey&quot; ] }, { &quot;author&quot; : &quot;Virgil&quot;, #&gt; 403 &quot;poems&quot; : [ &quot;Eclogues&quot;, &quot;Georgics&quot;, &quot;Aeneid&quot; ] }, { &quot;author&quot; : &quot;Jeroen&quot;, &quot;poems&quot; : [] } ] As #&gt; 404 can be seen from the example, the way to store this in a data frame is using a list of character #&gt; 405 vectors. This works, and although unconventional, we can still create and read such structures in R #&gt; 406 relatively easily. However, in practice the one-to-many relation is often more complex. It results #&gt; 407 in fields containing a set of records. In R, the only way to model this is as a column containing #&gt; 408 a list of data frames, one separate data frame for each row: x &lt;- data.frame(author = c(&quot;Homer&quot;, #&gt; 409 &quot;Virgil&quot;, &quot;Jeroen&quot;)) x$poems &lt;- list( data.frame(title=c(&quot;Iliad&quot;, &quot;Odyssey&quot;), year=c(-1194, -800)), #&gt; 410 data.frame(title=c(&quot;Eclogues&quot;, &quot;Georgics&quot;, &quot;Aeneid&quot;), year=c(-44, -29, -19)), data.frame() ) #&gt; 411 cat(toJSON(x, pretty=TRUE)) [ { 19 #&gt; 412 &quot;author&quot; : &quot;Homer&quot;, &quot;poems&quot; : [ { &quot;title&quot; : &quot;Iliad&quot;, &quot;year&quot; : -1194 }, { &quot;title&quot; : &quot;Odyssey&quot;, #&gt; 413 &quot;year&quot; : -800 } ] }, { &quot;author&quot; : &quot;Virgil&quot;, &quot;poems&quot; : [ { &quot;title&quot; : &quot;Eclogues&quot;, &quot;year&quot; : -44 }, #&gt; 414 { &quot;title&quot; : &quot;Georgics&quot;, &quot;year&quot; : -29 }, { &quot;title&quot; : &quot;Aeneid&quot;, &quot;year&quot; : -19 } ] }, { &quot;author&quot; : #&gt; 415 &quot;Jeroen&quot;, &quot;poems&quot; : [] } ] Because R doesn’t have native support for relational data, there is no #&gt; 416 natural class to store such structures. The best we can do is a column containing a list of sub- #&gt; 417 dataframes. This does the job, and allows the R user to access or generate nested JSON structures. #&gt; 418 However, a data frame like this cannot be flattened, and the class does not guarantee that each #&gt; 419 of the individual nested data frames contain the same fields, as would be the case in an actual #&gt; 420 relational data base. 20 #&gt; 421 3 Structural consistency and type safety in dynamic data Systems that automatically exchange #&gt; 422 information over some interface, protocol or API require well defined and unambiguous meaning #&gt; 423 and arrangement of data. In order to process and interpret input and output, contents must obey #&gt; 424 a steady structure. Such structures are usually described either informally in documenta- tion or #&gt; 425 more formally in a schema language. The previous section emphasized the importance of consistency #&gt; 426 in the mapping between JSON data and R classes. This section takes a higher level view and explains #&gt; 427 the importance of structure consistency for dynamic data. This topic can be a bit subtle because #&gt; 428 it refers to consistency among different instantiations of a JSON structure, rather than a single #&gt; 429 case. We try to clarify by breaking down the concept into two important parts, and illustrate #&gt; 430 with analogies and examples from R. 3.1 Classes, types and data Most object-oriented languages are #&gt; 431 designed with the idea that all objects of a certain class implement the same fields and methods. #&gt; 432 In strong-typed languages such as S4 or Java, names and types of the fields are formally declared in #&gt; 433 a class definition. In other languages such as S3 or JavaScript, the fields are not enforced by the #&gt; 434 language but rather at the discretion of the programmer. However one way or another they all assume #&gt; 435 that members of a certain class agree on field names and types, so that the same methods can be #&gt; 436 applied to any object of a particular class. This basic principle holds for dynamic data exactly the #&gt; 437 same way as for objects. Software that process dynamic data can only work reliably if the various #&gt; 438 elements of the data have consistent names and structure. Consensus must exist between the different #&gt; 439 parties on data that is exchanged as part an interface or protocol. This requires the structure to #&gt; 440 follow some sort of template that specifies which attributes can appear in the data, what they mean #&gt; 441 and how they are composed. Thereby each possible scenario can be accounted for in the software so #&gt; 442 that data gets interpreted/processed appropriately and no exceptions arise during run-time. Some #&gt; 443 data interchange formats such as XML or Protocol Buffers take a formal approach to this matter, #&gt; 444 and have well established schema languages and interface description languages. Using such a meta #&gt; 445 language it is possible to define the exact structure, properties and actions of data interchange #&gt; 446 in a formal arrange- ment. However, in JSON, such formal definitions are relatively uncommon. Some #&gt; 447 initiatives for JSON schema languages exist (Galiegue and Zyp, 2013), but they are not very well #&gt; 448 established and rarely seen in practice. One reason for this might be that defining and implementing #&gt; 449 formal schemas is complicated and a lot of work which defeats the purpose of using an lightweight #&gt; 450 format such as JSON in the first place. But another reason is that it is often simply not necessary #&gt; 451 to be overly formal. The JSON format is simple and intuitive, and under some general conventions, a #&gt; 452 well chosen example can suffice to characterize the structure. This section describes two important #&gt; 453 rules that are required to ensure that data exchange using JSON is type safe. 3.2 Rule 1: Fixed #&gt; 454 keys When using JSON without a schema, there are no restrictions on the keys (field names) that can #&gt; 455 appear in a particular object. However, an API that returns a different set of keys every time it #&gt; 456 is called makes it very difficult to write software to process these data. Hence, the first rule is #&gt; 457 to limit JSON interfaces to a finite set of keys that are known a priory by all parties. It can be #&gt; 458 helpful to think about this in analogy with for 21 #&gt; 459 example a relational database. Here, the database model separates the data from metadata. At run #&gt; 460 time, records can be inserted or deleted, and a certain query might return different data each time #&gt; 461 it is executed. But for a given query, each execution will return exactly the same field names; #&gt; 462 hence as long as the table definitions are unchanged, the structure of the output consistent. Client #&gt; 463 software needs this structure to validate input, optimize implementation, and process each part #&gt; 464 of the data appropriately. In JSON, data and metadata are not formally separated as in a database, #&gt; 465 but similar principles that hold for fields in a database, apply to keys in dynamic JSON data. #&gt; 466 A beautiful example of this in practice was given by Mike Dewar at the New York Open Statistical #&gt; 467 Program- ming Meetup on Jan. 12, 2012 (Dewar, 2012). In his talk he emphasizes to use JSON keys #&gt; 468 only for names, and not for data. He refers to this principle as the “golden rule”, and explains #&gt; 469 how he learned his lesson the hard way. In one of his early applications, timeseries data was #&gt; 470 encoded by using the epoch timestamp as the JSON key. Therefore the keys are different each time #&gt; 471 the query is executed: [ { &quot;1325344443&quot; : 124 }, { &quot;1325344456&quot; : 131 }, { &quot;1325344478&quot; : 137 }, ] #&gt; 472 Even though being valid JSON, dynamic keys as in the example above are likely to introduce trouble. #&gt; 473 Most software will have great difficulty processing these values if we can not specify the keys in #&gt; 474 the code. Moreover when documenting the API, either informally or formally using a schema language, #&gt; 475 we need to describe for each property in the data what the value means and is composed of. Thereby #&gt; 476 a client or consumer can implement code that interprets and process each element in the data in #&gt; 477 an appropriate manner. Both the documentation and interpretation of JSON data rely on fixed keys #&gt; 478 with well defined meaning. Also note that the structure is difficult to extend in the future. If #&gt; 479 we want to add an additional property to each observation, the entire structure needs to change. #&gt; 480 In his talk, Dewar explains that life gets much easier when we switch to the following encoding: #&gt; 481 [ { &quot;time&quot;: &quot;1325344443&quot; : &quot;price&quot;: 124 }, { &quot;time&quot;: &quot;1325344456&quot; : &quot;price&quot;: 131 }, { &quot;time&quot;: #&gt; 482 &quot;1325344478&quot; : &quot;price&quot;: 137 } ] This structure will play much nicer with existing software that #&gt; 483 assumes fixed keys. Moreover, the structure can easily be described in documentation, or captured #&gt; 484 in a schema. Even when we have no intention of writing documentation or a schema for a dynamic #&gt; 485 JSON source, it is still wise to design the structure in such away that it could be described by a #&gt; 486 schema. When the keys are fixed, a well chosen example can provide all the information required for #&gt; 487 the consumer to implement client code. Also note that the new structure is extensible: additional #&gt; 488 properties can be added to each observation without breaking backward compatibility. In the context #&gt; 489 of R, consistency of keys is closely related to Wikcham’s concept of tidy data discussed earlier. #&gt; 490 Wickham states that the most common reason for messy data are column headers containing values #&gt; 491 instead of variable names. Column headers in tabular datasets become keys when converted to JSON. #&gt; 492 Therefore, 22 #&gt; 493 when headers are actually values, JSON keys contain in fact data and can become unpredictable. #&gt; 494 The cure to inconsistent keys is almost always to tidy the data according to recommendations given #&gt; 495 by Wickham (2014). 3.3 Rule 2: Consistent types In a strong typed language, fields declare their #&gt; 496 class before any values are assigned. Thereby the type of a given field is identical in all objects #&gt; 497 of a particular class, and arrays only contain objects of a single type. The S3 system in R is #&gt; 498 weakly typed and puts no formal restrictions on the class of a certain properties, or the types of #&gt; 499 objects that can be combined into a collection. For example, the list below contains a character #&gt; 500 vector, a numeric vector and a list: # Heterogeneous lists are bad! x &lt;- list(&quot;FOO&quot;, 1:3, list(bar #&gt; 501 = pi)) cat(toJSON(x)) [ [ &quot;FOO&quot; ], [ 1, 2, 3 ], { &quot;bar&quot; : [ 3.14 ] } ] However even though it is #&gt; 502 possible to generate such JSON, it is bad practice. Fields or collections with ambiguous object #&gt; 503 types are difficult to describe, interpret and process in the context of inter-system commu- #&gt; 504 nication. When using JSON to exchange dynamic data, it is important that each property and array is #&gt; 505 type consistent. In dynamically typed languages, the programmer needs to make sure that properties #&gt; 506 are of the correct type before encoding into JSON. It also means that unnamed lists in R should #&gt; 507 generally be avoided when designing interoperable structures because this type is not homogeneous. #&gt; 508 Note that consistency is somewhat subjective as it refers to the meaning of the elements; they do #&gt; 509 not necessarily have precisely the same structure. What is important is to keep in mind that the #&gt; 510 consumer of the data can interpret and process each element identically, e.g. iterate over the #&gt; 511 elements in the collection and apply the same method to each of them. To illustrate this, lets #&gt; 512 take the example of the data frame: # conceptually homogenous array x &lt;- data.frame(name = c(&quot;Jay&quot;, #&gt; 513 &quot;Mary&quot;, NA, NA), gender = c(&quot;M&quot;, NA, NA, &quot;F&quot;)) cat(toJSON(x, pretty = TRUE)) [ { &quot;name&quot; : &quot;Jay&quot;, #&gt; 514 &quot;gender&quot; : &quot;M&quot; }, { &quot;name&quot; : &quot;Mary&quot; }, {}, { &quot;gender&quot; : &quot;F&quot; } ] 23 #&gt; 515 The JSON array above has 4 elements, each of which a JSON object. However, due to the NA values, #&gt; 516 not all elements have an identical structure: some records have more fields than others. But as long #&gt; 517 as they are conceptually the same type (e.g. a person), the consumer can iterate over the elements #&gt; 518 to process each person in the set according to a predefined action. For example each element could #&gt; 519 be used to construct a Person object. A collection of different object classes should be separated #&gt; 520 and organized using a named list: x &lt;- list( humans = data.frame(name = c(&quot;Jay&quot;, &quot;Mary&quot;), married #&gt; 521 = c(TRUE, FALSE)), horses = data.frame(name = c(&quot;Star&quot;, &quot;Dakota&quot;), price = c(5000, 30000)) ) #&gt; 522 cat(toJSON(x, pretty=TRUE)) { &quot;humans&quot; : [ { &quot;name&quot; : &quot;Jay&quot;, &quot;married&quot; : true }, { &quot;name&quot; : #&gt; 523 &quot;Mary&quot;, &quot;married&quot; : false } ], &quot;horses&quot; : [ { &quot;name&quot; : &quot;Star&quot;, &quot;price&quot; : 5000 }, { &quot;name&quot; : #&gt; 524 &quot;Dakota&quot;, &quot;price&quot; : 30000 } ] } This might seem obvious, but dynamic languages such as R can make #&gt; 525 it dangerously tempting to create data containing mixed-type properties or collections. We already #&gt; 526 mentioned the example of other JSON packages which encode an atomic vector either as JSON primitive #&gt; 527 or JSON array, depending on its length. Such inconsistent typing is very difficult for clients to #&gt; 528 predict and a likely source of nasty bugs. Using consistent field names/types and homogeneous JSON #&gt; 529 arrays is a strong convention among public JSON APIs, for good reasons. We recommend R users to #&gt; 530 respect these conventions when generating JSON data in R. 24 #&gt; 531 Appendices A Public JSON APIs This section lists some examples of public HTTP APIs that publish #&gt; 532 data in JSON format. These are great to get a sense of the complex structures that are encountered #&gt; 533 in real world JSON data. All services are free, but some require registration/authentication. #&gt; 534 Each example returns lots of data, therefore output is ommitted in this document. The reader is #&gt; 535 encouraged to run the examples in R and inspect the output manually. A.1 No authentication required #&gt; 536 The following APIs allow for (limited) use without any form of registration: Github Github is an #&gt; 537 online code repository and has APIs to get live data on almost all activity. Below some examples #&gt; 538 from a well known R package and author: hadley_orgs &lt;- fromJSON(&quot;https://api.github.com/users/ #&gt; 539 hadley/orgs&quot;) hadley_repos &lt;- fromJSON(&quot;https://api.github.com/users/hadley/repos&quot;) gg_issues &lt;- #&gt; 540 fromJSON(&quot;https://api.github.com/repos/hadley/ggplot2/issues&quot;) gg_commits &lt;- fromJSON(&quot;https:// #&gt; 541 api.github.com/repos/hadley/ggplot2/commits&quot;) CitiBike NYC A single public API that shows location, #&gt; 542 status and current availability for all stations in the New York City bike sharing initative. #&gt; 543 citibike &lt;- fromJSON(&quot;http://citibikenyc.com/stations/json&quot;) AngelList AngelList is a job listing #&gt; 544 directory for startups: res &lt;- fromJSON(&quot;http://api.angel.co/1/tags/59/startups&quot;) res$startups 25 #&gt; 545 Ergast The Ergast Developer API is an experimental web service which provides a historical record #&gt; 546 of motor racing data for non-commercial purposes. races &lt;- fromJSON(&quot;http://ergast.com/api/ #&gt; 547 f1/2012/1/results.json&quot;) races$RaceTable$Races$MRData$Results[[1]]$Driver A.2 Free registration #&gt; 548 required The following APIs require (free) registration of a key/token. In each case, registration #&gt; 549 is easy and a key will be emailed. This key has to be appended to the requests to query the APIs. #&gt; 550 The code below includes some example keys for illustration purposes. New York Times The New York #&gt; 551 Times has several free APIs that are part of the NYT developer network. These interface to data #&gt; 552 from various departments, such as news articles, book reviews, real estate, etc. # Register keys #&gt; 553 at http://developer.nytimes.com/docs/reference/keys # search for articles article_key = &quot;&amp;api- #&gt; 554 key=c2fede7bd9aea57c898f538e5ec0a1ee:6:68700045&quot; url = &quot;http://api.nytimes.com/svc/search/ #&gt; 555 v2/articlesearch.json?q=obamacare+socialism&quot; articles &lt;- fromJSON(paste0(url, article_key)) # #&gt; 556 search for best sellers bestseller_key = &quot;&amp;api-key=5e260a86a6301f55546c83a47d139b0d:3:68700045&quot; #&gt; 557 url = &quot;http://api.nytimes.com/svc/books/v2/lists/overview.json?published_date=2013-01-01&quot; #&gt; 558 bestsellers &lt;- fromJSON(paste0(url, bestseller_key)) # movie reviews movie_key = &quot;&amp;api- #&gt; 559 key=5a3daaeee6bbc6b9df16284bc575e5ba:0:68700045&quot; url = &quot;http://api.nytimes.com/svc/movies/v2/ #&gt; 560 reviews/dvd-picks.json?order=by-date&quot; reviews &lt;- fromJSON(paste0(url, movie_key)) CrunchBase #&gt; 561 CrunchBase is the free database of technology companies, people, and investors that anyone can edit. #&gt; 562 key &lt;- &quot;f6dv6cas5vw7arn5b9d7mdm3&quot; res &lt;- fromJSON(paste0(&quot;http://api.crunchbase.com/v/1/search.js? #&gt; 563 query=R&amp;api_key=&quot;, key)) str(res$results) 26 #&gt; 564 Sunlight Foundation The Sunlight Foundation is a non-profit that helps to make government #&gt; 565 transparent and accountable through data, tools, policy and journalism. #register key at http:// #&gt; 566 sunlightfoundation.com/api/accounts/register/ key &lt;- &quot;&amp;apikey=39c83d5a4acc42be993ee637e2e4ba3d&quot; #&gt; 567 #some queries drones &lt;- fromJSON(paste0(&quot;http://openstates.org/api/v1/bills/?q=drone&quot;, key)) #&gt; 568 word &lt;- fromJSON(paste0(&quot;http://capitolwords.org/api/1/dates.json?phrase=obamacare&quot;, key)) #&gt; 569 legislators &lt;- fromJSON(paste0(&quot;http://congress.api.sunlightfoundation.com/&quot;, &quot;legislators/locate? #&gt; 570 latitude=42.96&amp;longitude=-108.09&quot;, key)) A.3 OAuth2 authentication Twitter The twitter API requires #&gt; 571 a more elaborate authentication process based on the OAuth2 protocol. Some example code: #Create #&gt; 572 your own appication key at https://dev.twitter.com/apps consumer_key = &quot;EZRy5JzOH2QQmVAe9B4j2w&quot;; #&gt; 573 consumer_secret = &quot;OIDC4MdfZJ82nbwpZfoUO4WOLTYjoRhpHRAWj6JMec&quot;; #basic auth library(httr) secret &lt;- #&gt; 574 RCurl::base64(paste(consumer_key, consumer_secret, sep=&quot;:&quot;)); req &lt;- POST(&quot;https://api.twitter.com/ #&gt; 575 oauth2/token&quot;, config(httpheader = c( &quot;Authorization&quot; = paste(&quot;Basic&quot;, secret), &quot;Content-Type&quot; #&gt; 576 = &quot;application/x-www-form-urlencoded;charset=UTF-8&quot; )), body = &quot;grant_type=client_credentials&quot;, #&gt; 577 multipart = FALSE ); res &lt;- fromJSON(rawToChar(req$content)) token &lt;- paste(&quot;Bearer&quot;, #&gt; 578 res$access_token); #Actual API call url = &quot;https://api.twitter.com/1.1/statuses/user_timeline.json? #&gt; 579 count=10&amp;screen_name=UCLA&quot; call1 &lt;- GET(url, config(httpheader = c(&quot;Authorization&quot; = token))) obj1 #&gt; 580 &lt;- fromJSON(rawToChar(call1$content)) 27 #&gt; 581 B Simple JSON RPC with OpenCPU The jsonlite package is used by OpenCPU to convert between JSON data #&gt; 582 and R ojects. Thereby clients can retrieve R objects, or remotely call R functions using JSON where #&gt; 583 the function arguments as well as function return value are JSON objects. For example to download #&gt; 584 the Boston data from the MASS package: Command in R Example URL on OpenCPU toJSON(Boston, digits=4) #&gt; 585 https://cran.ocpu.io/MASS/data/Boston/json?digits=4 toJSON(Boston, dataframe=&quot;col&quot;) https:// #&gt; 586 cran.ocpu.io/MASS/data/Boston/json?dataframe=col toJSON(Boston, pretty=FALSE) https://cran.ocpu.io/ #&gt; 587 MASS/data/Boston/json?pretty=false To calculate the variance of some the numbers 1:9 in the command #&gt; 588 line using using curl: curl https://demo.ocpu.io/stats/R/var/json -d &#39;x=[1,2,3,4,5,6,7,8,9]&#39; Or #&gt; 589 equivalently post the entire body in JSON format: curl https://demo.ocpu.io/stats/R/var/json - #&gt; 590 H &quot;Content-Type: application/json&quot; \\\\ -d &#39;{&quot;x&quot;:[1,2,3,4,5,6,7,8,9]}&#39; Below an example where we call #&gt; 591 the melt function from the reshape2 package using some example rows from the airquality data. Here #&gt; 592 both input and output consist of a data frame. curl https://cran.ocpu.io/reshape2/R/melt/json -d #&gt; 593 &#39;id=[&quot;Month&quot;, &quot;Day&quot;]&amp;data=[ { &quot;Ozone&quot; : 41, &quot;Solar.R&quot; : 190, &quot;Wind&quot; : 7.4, &quot;Temp&quot; : 67, &quot;Month&quot; : 5, #&gt; 594 &quot;Day&quot; : 1 }, { &quot;Ozone&quot; : 36, &quot;Solar.R&quot; : 118, &quot;Wind&quot; : 8, &quot;Temp&quot; : 72, &quot;Month&quot; : 5, &quot;Day&quot; : 2 } ]&#39; #&gt; 595 Or equivalently: curl https://cran.ocpu.io/reshape2/R/melt/json -H &quot;Content-Type: application/json&quot; #&gt; 596 \\\\ -d &#39;{&quot;id&quot; : [&quot;Month&quot;, &quot;Day&quot;], &quot;data&quot; : [ { &quot;Ozone&quot; : 41, &quot;Solar.R&quot; : 190, &quot;Wind&quot; : 7.4, &quot;Temp&quot; : #&gt; 597 67, &quot;Month&quot; : 5, &quot;Day&quot; : 1 }, { &quot;Ozone&quot; : 36, &quot;Solar.R&quot; : 118, &quot;Wind&quot; : 8, &quot;Temp&quot; : 72, &quot;Month&quot; : 5, #&gt; 598 &quot;Day&quot; : 2 } ] }&#39; This request basically executes the following R code: mydata &lt;- airquality[1:2, ] y #&gt; 599 &lt;- reshape2::melt(data = mydata, id = c(&quot;Month&quot;, &quot;Day&quot;)) cat(toJSON(y)) 28 #&gt; 600 References Edward Anderson, Zhaojun Bai, Christian Bischof, Susan Blackford, James Demmel, Jack #&gt; 601 Dongarra, Jeremy Du Croz, Anne Greenbaum, S Hammerling, Alan McKenney, et al. LAPACK Users’ guide, #&gt; 602 volume 9. Siam, 1999. Kristina Chodorow. MongoDB: the definitive guide. O’Reilly Media, Inc., 2013. #&gt; 603 Alex Couture-Beil. rjson: JSON for R, 2013. URL http://CRAN.R-project.org/package=rjson. R package #&gt; 604 version 0.2.13. Douglas Crockford. The application/json media type for javascript object notation #&gt; 605 (json), 2006a. URL http://tools.ietf.org/html/rfc4627. Douglas Crockford. JSON: The fat-free #&gt; 606 alternative to XML. In Proc. of XML, volume 2006, 2006b. URL http://www.json.org/fatfree.html. Mike #&gt; 607 Dewar. First steps in data visualisation using d3.js, 2012. URL http://vimeo.com/35005701#t=7m17s. #&gt; 608 New York Open Statistical Programming Meetup on Jan. 12, 2012. ECMA. 262: ECMAScript Language #&gt; 609 Specification. European Association for Standardizing Information and Communication Systems, #&gt; 610 1999. URL http://www.ecma-international.org/publications/files/ ECMA-ST/Ecma-262.pdf. Sadayuki #&gt; 611 Furuhashi. MessagePack: It’s like JSON. but fast and small, 2014. URL http://msgpack.org/. F. #&gt; 612 Galiegue and K. Zyp. JSON Schema: core definitions and terminology. draft-zyp-json-schema-04 #&gt; 613 (work in progress), 2013. URL https://tools.ietf.org/html/draft-zyp-json-schema-04. Duncan Temple #&gt; 614 Lang. RJSONIO: Serialize R objects to JSON, JavaScript Object Notation, 2013. URL http://CRAN.R- #&gt; 615 project.org/package=RJSONIO. R package version 1.0-3. Chuck L Lawson, Richard J. Hanson, David R #&gt; 616 Kincaid, and Fred T. Krogh. Basic linear algebra subprograms for fortran usage. ACM Transactions #&gt; 617 on Mathematical Software (TOMS), 5(3):308–323, 1979. Deborah Nolan and Duncan Temple Lang. XML #&gt; 618 and Web Technologies for Data Sciences with R. Springer, 2014. URL http://link.springer.com/ #&gt; 619 book/10.1007/978-1-4614-7900-0. Jeroen Ooms, Duncan Temple Lang, and Jonathan Wallace. jsonlite: #&gt; 620 A smarter JSON encoder/decoder for R, 2014. URL http://github.com/jeroenooms/jsonlite#readme. R #&gt; 621 package version 0.9.4. R Core Team. R: A Language and Environment for Statistical Computing. R #&gt; 622 Foundation for Statistical Computing, Vienna, Austria, 2013. URL http://www.R-project.org/. Hadley #&gt; 623 Wickham. Tidy Data. Under review, 2014. URL http://vita.had.co.nz/papers/tidy-data.pdf. 29 #&gt; page #&gt; 1 1 #&gt; 2 1 #&gt; 3 1 #&gt; 4 1 #&gt; 5 1 #&gt; 6 1 #&gt; 7 1 #&gt; 8 1 #&gt; 9 1 #&gt; 10 1 #&gt; 11 1 #&gt; 12 1 #&gt; 13 1 #&gt; 14 1 #&gt; 15 1 #&gt; 16 1 #&gt; 17 1 #&gt; 18 1 #&gt; 19 1 #&gt; 20 1 #&gt; 21 1 #&gt; 22 1 #&gt; 23 1 #&gt; 24 1 #&gt; 25 1 #&gt; 26 1 #&gt; 27 1 #&gt; 28 1 #&gt; 29 1 #&gt; 30 2 #&gt; 31 2 #&gt; 32 2 #&gt; 33 2 #&gt; 34 2 #&gt; 35 2 #&gt; 36 2 #&gt; 37 2 #&gt; 38 2 #&gt; 39 2 #&gt; 40 2 #&gt; 41 2 #&gt; 42 2 #&gt; 43 2 #&gt; 44 2 #&gt; 45 2 #&gt; 46 2 #&gt; 47 2 #&gt; 48 2 #&gt; 49 2 #&gt; 50 2 #&gt; 51 2 #&gt; 52 2 #&gt; 53 2 #&gt; 54 2 #&gt; 55 2 #&gt; 56 2 #&gt; 57 2 #&gt; 58 2 #&gt; 59 2 #&gt; 60 2 #&gt; 61 2 #&gt; 62 2 #&gt; 63 3 #&gt; 64 3 #&gt; 65 3 #&gt; 66 3 #&gt; 67 3 #&gt; 68 3 #&gt; 69 3 #&gt; 70 3 #&gt; 71 3 #&gt; 72 3 #&gt; 73 3 #&gt; 74 3 #&gt; 75 3 #&gt; 76 3 #&gt; 77 3 #&gt; 78 3 #&gt; 79 3 #&gt; 80 3 #&gt; 81 3 #&gt; 82 3 #&gt; 83 3 #&gt; 84 3 #&gt; 85 3 #&gt; 86 3 #&gt; 87 3 #&gt; 88 3 #&gt; 89 3 #&gt; 90 3 #&gt; 91 3 #&gt; 92 3 #&gt; 93 3 #&gt; 94 3 #&gt; 95 3 #&gt; 96 3 #&gt; 97 3 #&gt; 98 3 #&gt; 99 4 #&gt; 100 4 #&gt; 101 4 #&gt; 102 4 #&gt; 103 4 #&gt; 104 4 #&gt; 105 4 #&gt; 106 4 #&gt; 107 4 #&gt; 108 4 #&gt; 109 4 #&gt; 110 4 #&gt; 111 4 #&gt; 112 4 #&gt; 113 4 #&gt; 114 4 #&gt; 115 4 #&gt; 116 4 #&gt; 117 4 #&gt; 118 4 #&gt; 119 4 #&gt; 120 4 #&gt; 121 4 #&gt; 122 4 #&gt; 123 4 #&gt; 124 4 #&gt; 125 4 #&gt; 126 4 #&gt; 127 4 #&gt; 128 4 #&gt; 129 4 #&gt; 130 4 #&gt; 131 4 #&gt; 132 4 #&gt; 133 4 #&gt; 134 4 #&gt; 135 4 #&gt; 136 4 #&gt; 137 4 #&gt; 138 4 #&gt; 139 4 #&gt; 140 4 #&gt; 141 5 #&gt; 142 5 #&gt; 143 5 #&gt; 144 5 #&gt; 145 5 #&gt; 146 5 #&gt; 147 5 #&gt; 148 5 #&gt; 149 5 #&gt; 150 5 #&gt; 151 5 #&gt; 152 5 #&gt; 153 5 #&gt; 154 5 #&gt; 155 5 #&gt; 156 5 #&gt; 157 5 #&gt; 158 5 #&gt; 159 5 #&gt; 160 5 #&gt; 161 5 #&gt; 162 5 #&gt; 163 5 #&gt; 164 6 #&gt; 165 6 #&gt; 166 6 #&gt; 167 6 #&gt; 168 6 #&gt; 169 6 #&gt; 170 6 #&gt; 171 6 #&gt; 172 6 #&gt; 173 6 #&gt; 174 6 #&gt; 175 6 #&gt; 176 6 #&gt; 177 6 #&gt; 178 6 #&gt; 179 6 #&gt; 180 6 #&gt; 181 6 #&gt; 182 6 #&gt; 183 6 #&gt; 184 6 #&gt; 185 6 #&gt; 186 7 #&gt; 187 7 #&gt; 188 7 #&gt; 189 7 #&gt; 190 7 #&gt; 191 7 #&gt; 192 7 #&gt; 193 7 #&gt; 194 7 #&gt; 195 7 #&gt; 196 7 #&gt; 197 7 #&gt; 198 7 #&gt; 199 7 #&gt; 200 7 #&gt; 201 7 #&gt; 202 7 #&gt; 203 7 #&gt; 204 8 #&gt; 205 8 #&gt; 206 8 #&gt; 207 8 #&gt; 208 8 #&gt; 209 8 #&gt; 210 8 #&gt; 211 8 #&gt; 212 8 #&gt; 213 8 #&gt; 214 8 #&gt; 215 8 #&gt; 216 8 #&gt; 217 8 #&gt; 218 8 #&gt; 219 8 #&gt; 220 8 #&gt; 221 8 #&gt; 222 8 #&gt; 223 8 #&gt; 224 8 #&gt; 225 8 #&gt; 226 9 #&gt; 227 9 #&gt; 228 9 #&gt; 229 9 #&gt; 230 9 #&gt; 231 9 #&gt; 232 9 #&gt; 233 9 #&gt; 234 9 #&gt; 235 9 #&gt; 236 9 #&gt; 237 9 #&gt; 238 9 #&gt; 239 9 #&gt; 240 9 #&gt; 241 9 #&gt; 242 9 #&gt; 243 9 #&gt; 244 9 #&gt; 245 9 #&gt; 246 9 #&gt; 247 9 #&gt; 248 9 #&gt; 249 9 #&gt; 250 9 #&gt; 251 9 #&gt; 252 9 #&gt; 253 10 #&gt; 254 10 #&gt; 255 10 #&gt; 256 10 #&gt; 257 10 #&gt; 258 10 #&gt; 259 10 #&gt; 260 10 #&gt; 261 10 #&gt; 262 11 #&gt; 263 11 #&gt; 264 11 #&gt; 265 11 #&gt; 266 11 #&gt; 267 11 #&gt; 268 11 #&gt; 269 11 #&gt; 270 11 #&gt; 271 11 #&gt; 272 11 #&gt; 273 11 #&gt; 274 11 #&gt; 275 12 #&gt; 276 12 #&gt; 277 12 #&gt; 278 12 #&gt; 279 12 #&gt; 280 12 #&gt; 281 12 #&gt; 282 12 #&gt; 283 12 #&gt; 284 12 #&gt; 285 12 #&gt; 286 12 #&gt; 287 12 #&gt; 288 12 #&gt; 289 12 #&gt; 290 12 #&gt; 291 13 #&gt; 292 13 #&gt; 293 13 #&gt; 294 13 #&gt; 295 13 #&gt; 296 13 #&gt; 297 13 #&gt; 298 13 #&gt; 299 13 #&gt; 300 13 #&gt; 301 13 #&gt; 302 13 #&gt; 303 13 #&gt; 304 14 #&gt; 305 14 #&gt; 306 14 #&gt; 307 14 #&gt; 308 14 #&gt; 309 14 #&gt; 310 14 #&gt; 311 14 #&gt; 312 14 #&gt; 313 14 #&gt; 314 14 #&gt; 315 14 #&gt; 316 14 #&gt; 317 14 #&gt; 318 14 #&gt; 319 14 #&gt; 320 14 #&gt; 321 14 #&gt; 322 14 #&gt; 323 14 #&gt; 324 14 #&gt; 325 14 #&gt; 326 14 #&gt; 327 14 #&gt; 328 14 #&gt; 329 14 #&gt; 330 14 #&gt; 331 14 #&gt; 332 14 #&gt; 333 14 #&gt; 334 15 #&gt; 335 15 #&gt; 336 15 #&gt; 337 15 #&gt; 338 15 #&gt; 339 15 #&gt; 340 15 #&gt; 341 15 #&gt; 342 15 #&gt; 343 15 #&gt; 344 15 #&gt; 345 15 #&gt; 346 15 #&gt; 347 15 #&gt; 348 15 #&gt; 349 15 #&gt; 350 16 #&gt; 351 16 #&gt; 352 16 #&gt; 353 16 #&gt; 354 16 #&gt; 355 16 #&gt; 356 16 #&gt; 357 16 #&gt; 358 16 #&gt; 359 16 #&gt; 360 16 #&gt; 361 16 #&gt; 362 16 #&gt; 363 16 #&gt; 364 17 #&gt; 365 17 #&gt; 366 17 #&gt; 367 17 #&gt; 368 17 #&gt; 369 17 #&gt; 370 17 #&gt; 371 17 #&gt; 372 17 #&gt; 373 17 #&gt; 374 17 #&gt; 375 17 #&gt; 376 17 #&gt; 377 17 #&gt; 378 17 #&gt; 379 17 #&gt; 380 17 #&gt; 381 18 #&gt; 382 18 #&gt; 383 18 #&gt; 384 18 #&gt; 385 18 #&gt; 386 18 #&gt; 387 18 #&gt; 388 18 #&gt; 389 18 #&gt; 390 18 #&gt; 391 18 #&gt; 392 18 #&gt; 393 18 #&gt; 394 18 #&gt; 395 18 #&gt; 396 18 #&gt; 397 18 #&gt; 398 18 #&gt; 399 18 #&gt; 400 19 #&gt; 401 19 #&gt; 402 19 #&gt; 403 19 #&gt; 404 19 #&gt; 405 19 #&gt; 406 19 #&gt; 407 19 #&gt; 408 19 #&gt; 409 19 #&gt; 410 19 #&gt; 411 19 #&gt; 412 20 #&gt; 413 20 #&gt; 414 20 #&gt; 415 20 #&gt; 416 20 #&gt; 417 20 #&gt; 418 20 #&gt; 419 20 #&gt; 420 20 #&gt; 421 21 #&gt; 422 21 #&gt; 423 21 #&gt; 424 21 #&gt; 425 21 #&gt; 426 21 #&gt; 427 21 #&gt; 428 21 #&gt; 429 21 #&gt; 430 21 #&gt; 431 21 #&gt; 432 21 #&gt; 433 21 #&gt; 434 21 #&gt; 435 21 #&gt; 436 21 #&gt; 437 21 #&gt; 438 21 #&gt; 439 21 #&gt; 440 21 #&gt; 441 21 #&gt; 442 21 #&gt; 443 21 #&gt; 444 21 #&gt; 445 21 #&gt; 446 21 #&gt; 447 21 #&gt; 448 21 #&gt; 449 21 #&gt; 450 21 #&gt; 451 21 #&gt; 452 21 #&gt; 453 21 #&gt; 454 21 #&gt; 455 21 #&gt; 456 21 #&gt; 457 21 #&gt; 458 21 #&gt; 459 22 #&gt; 460 22 #&gt; 461 22 #&gt; 462 22 #&gt; 463 22 #&gt; 464 22 #&gt; 465 22 #&gt; 466 22 #&gt; 467 22 #&gt; 468 22 #&gt; 469 22 #&gt; 470 22 #&gt; 471 22 #&gt; 472 22 #&gt; 473 22 #&gt; 474 22 #&gt; 475 22 #&gt; 476 22 #&gt; 477 22 #&gt; 478 22 #&gt; 479 22 #&gt; 480 22 #&gt; 481 22 #&gt; 482 22 #&gt; 483 22 #&gt; 484 22 #&gt; 485 22 #&gt; 486 22 #&gt; 487 22 #&gt; 488 22 #&gt; 489 22 #&gt; 490 22 #&gt; 491 22 #&gt; 492 22 #&gt; 493 23 #&gt; 494 23 #&gt; 495 23 #&gt; 496 23 #&gt; 497 23 #&gt; 498 23 #&gt; 499 23 #&gt; 500 23 #&gt; 501 23 #&gt; 502 23 #&gt; 503 23 #&gt; 504 23 #&gt; 505 23 #&gt; 506 23 #&gt; 507 23 #&gt; 508 23 #&gt; 509 23 #&gt; 510 23 #&gt; 511 23 #&gt; 512 23 #&gt; 513 23 #&gt; 514 23 #&gt; 515 24 #&gt; 516 24 #&gt; 517 24 #&gt; 518 24 #&gt; 519 24 #&gt; 520 24 #&gt; 521 24 #&gt; 522 24 #&gt; 523 24 #&gt; 524 24 #&gt; 525 24 #&gt; 526 24 #&gt; 527 24 #&gt; 528 24 #&gt; 529 24 #&gt; 530 24 #&gt; 531 25 #&gt; 532 25 #&gt; 533 25 #&gt; 534 25 #&gt; 535 25 #&gt; 536 25 #&gt; 537 25 #&gt; 538 25 #&gt; 539 25 #&gt; 540 25 #&gt; 541 25 #&gt; 542 25 #&gt; 543 25 #&gt; 544 25 #&gt; 545 26 #&gt; 546 26 #&gt; 547 26 #&gt; 548 26 #&gt; 549 26 #&gt; 550 26 #&gt; 551 26 #&gt; 552 26 #&gt; 553 26 #&gt; 554 26 #&gt; 555 26 #&gt; 556 26 #&gt; 557 26 #&gt; 558 26 #&gt; 559 26 #&gt; 560 26 #&gt; 561 26 #&gt; 562 26 #&gt; 563 26 #&gt; 564 27 #&gt; 565 27 #&gt; 566 27 #&gt; 567 27 #&gt; 568 27 #&gt; 569 27 #&gt; 570 27 #&gt; 571 27 #&gt; 572 27 #&gt; 573 27 #&gt; 574 27 #&gt; 575 27 #&gt; 576 27 #&gt; 577 27 #&gt; 578 27 #&gt; 579 27 #&gt; 580 27 #&gt; 581 28 #&gt; 582 28 #&gt; 583 28 #&gt; 584 28 #&gt; 585 28 #&gt; 586 28 #&gt; 587 28 #&gt; 588 28 #&gt; 589 28 #&gt; 590 28 #&gt; 591 28 #&gt; 592 28 #&gt; 593 28 #&gt; 594 28 #&gt; 595 28 #&gt; 596 28 #&gt; 597 28 #&gt; 598 28 #&gt; 599 28 #&gt; 600 29 #&gt; 601 29 #&gt; 602 29 #&gt; 603 29 #&gt; 604 29 #&gt; 605 29 #&gt; 606 29 #&gt; 607 29 #&gt; 608 29 #&gt; 609 29 #&gt; 610 29 #&gt; 611 29 #&gt; 612 29 #&gt; 613 29 #&gt; 614 29 #&gt; 615 29 #&gt; 616 29 #&gt; 617 29 #&gt; 618 29 #&gt; 619 29 #&gt; 620 29 #&gt; 621 29 #&gt; 622 29 #&gt; 623 29 B.3.1 Office documents B.3.2 Images "]
]
